{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video pre-annotate",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KtaoDc_sntA"
      },
      "source": [
        "# Install package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uk3kpdcsSRr",
        "outputId": "3450c60f-05f2-4923-fb40-fa7e18c69bf8"
      },
      "source": [
        "# clone darknet repo\r\n",
        "!git clone https://github.com/AlexeyAB/darknet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'darknet'...\n",
            "remote: Enumerating objects: 14665, done.\u001b[K\n",
            "remote: Total 14665 (delta 0), reused 0 (delta 0), pack-reused 14665\u001b[K\n",
            "Receiving objects: 100% (14665/14665), 13.24 MiB | 21.48 MiB/s, done.\n",
            "Resolving deltas: 100% (9982/9982), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Owvhchsvyn",
        "outputId": "910c3652-a45c-4bd3-cb13-d70ac8758d8c"
      },
      "source": [
        "# change makefile to have GPU and OPENCV enabled\r\n",
        "%cd darknet\r\n",
        "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\r\n",
        "!sed -i 's/GPU=0/GPU=1/' Makefile\r\n",
        "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\r\n",
        "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/darknet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtZ5rCLssxhH",
        "outputId": "8b6524e3-ae4d-4dae-ac47-a22a517d49b0"
      },
      "source": [
        "# make darknet (builds darknet so that you can then use the darknet executable file to run or train object detectors)\r\n",
        "!make"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir -p ./obj/\n",
            "mkdir -p backup\n",
            "chmod +x *.sh\n",
            "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/image_opencv.cpp -o obj/image_opencv.o\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid draw_detections_cv_v3(void**, detection*, int, float, char**, image**, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:926:23:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Krgb\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "                 float \u001b[01;35m\u001b[Krgb\u001b[m\u001b[K[3];\n",
            "                       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid draw_train_loss(char*, void**, int, float, float, int, int, float, int, char*, float, int, int, double)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1127:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "             \u001b[01;35m\u001b[Kif\u001b[m\u001b[K (iteration_old == 0)\n",
            "             \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1130:10:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "          \u001b[01;36m\u001b[Kif\u001b[m\u001b[K (iteration_old != 0){\n",
            "          \u001b[01;36m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid cv_draw_object(image, float*, int, int, int*, float*, int*, int, char**)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1424:14:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbuff\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         char \u001b[01;35m\u001b[Kbuff\u001b[m\u001b[K[100];\n",
            "              \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1400:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kit_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kit_tb_res\u001b[m\u001b[K = cv::createTrackbar(it_trackbar_name, window_name, &it_trackbar_value, 1000);\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1404:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Klr_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Klr_tb_res\u001b[m\u001b[K = cv::createTrackbar(lr_trackbar_name, window_name, &lr_trackbar_value, 20);\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1408:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kcl_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kcl_tb_res\u001b[m\u001b[K = cv::createTrackbar(cl_trackbar_name, window_name, &cl_trackbar_value, classes-1);\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/image_opencv.cpp:1411:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbo_tb_res\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kbo_tb_res\u001b[m\u001b[K = cv::createTrackbar(bo_trackbar_name, window_name, boxonly, 1);\n",
            "         \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/http_stream.cpp -o obj/http_stream.o\n",
            "In file included from \u001b[01m\u001b[K./src/http_stream.cpp:580:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K./src/httplib.h:129:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K\"INVALID_SOCKET\" redefined\n",
            " #define INVALID_SOCKET (-1)\n",
            " \n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:73:0:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kthis is the location of the previous definition\n",
            " #define INVALID_SOCKET -1\n",
            " \n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool JSON_sender::write(const char*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:249:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                 int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = _write(client, outputbuf, outlen);\n",
            "                     \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In member function ‘\u001b[01m\u001b[Kbool MJPG_sender::write(const cv::Mat&)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:507:113:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%zu\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Ksize_t\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "                 sprintf(head, \"--mjpegstream\\r\\nContent-Type: image/jpeg\\r\\nContent-Length: %zu\\r\\n\\r\\n\", outlen\u001b[01;35m\u001b[K)\u001b[m\u001b[K;\n",
            "                                                                                                                 \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid set_track_id(detection*, int, float, float, float, int, int, int)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:863:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "         for (int i = 0; \u001b[01;35m\u001b[Ki < v.size()\u001b[m\u001b[K; ++i) {\n",
            "                         \u001b[01;35m\u001b[K~~^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:871:33:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     for (int old_id = 0; \u001b[01;35m\u001b[Kold_id < old_dets.size()\u001b[m\u001b[K; ++old_id) {\n",
            "                          \u001b[01;35m\u001b[K~~~~~~~^~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:890:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     for (int index = 0; \u001b[01;35m\u001b[Kindex < new_dets_num*old_dets.size()\u001b[m\u001b[K; ++index) {\n",
            "                         \u001b[01;35m\u001b[K~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/http_stream.cpp:926:28:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     if (\u001b[01;35m\u001b[Kold_dets_dq.size() > deque_size\u001b[m\u001b[K) old_dets_dq.pop_front();\n",
            "         \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/gemm.c -o obj/gemm.o\n",
            "\u001b[01m\u001b[K./src/gemm.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kconvolution_2d\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gemm.c:2038:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     const int \u001b[01;35m\u001b[Kout_w\u001b[m\u001b[K = (w + 2 * pad - ksize) / stride + 1;    // output_width=input_width for stride=1 and pad=1\n",
            "               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gemm.c:2037:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     const int \u001b[01;35m\u001b[Kout_h\u001b[m\u001b[K = (h + 2 * pad - ksize) / stride + 1;    // output_height=input_height for stride=1 and pad=1\n",
            "               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/utils.c -o obj/utils.o\n",
            "\u001b[01m\u001b[K./src/utils.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcustom_hash\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/utils.c:1045:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest parentheses around assignment used as truth value [\u001b[01;35m\u001b[K-Wparentheses\u001b[m\u001b[K]\n",
            "     while (\u001b[01;35m\u001b[Kc\u001b[m\u001b[K = *str++)\n",
            "            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/dark_cuda.c -o obj/dark_cuda.o\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcudnn_check_error_extended\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:224:20:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between ‘\u001b[01m\u001b[KcudaError_t {aka enum cudaError}\u001b[m\u001b[K’ and ‘\u001b[01m\u001b[Kenum <anonymous>\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wenum-compare\u001b[m\u001b[K]\n",
            "         if (status \u001b[01;35m\u001b[K!=\u001b[m\u001b[K CUDNN_STATUS_SUCCESS)\n",
            "                    \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpre_allocate_pinned_memory\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:276:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%u\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\"pre_allocate: size = \u001b[01;35m\u001b[K%Iu\u001b[m\u001b[K MB, num_of_blocks = %Iu, block_size = %Iu MB \\n\",\n",
            "                                      \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "                                      \u001b[32m\u001b[K%Ilu\u001b[m\u001b[K\n",
            "             \u001b[32m\u001b[Ksize / (1024*1024)\u001b[m\u001b[K, num_of_blocks, pinned_block_size / (1024 * 1024));\n",
            "             \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K          \n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:276:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%u\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka const long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\"pre_allocate: size = %Iu MB, num_of_blocks = \u001b[01;35m\u001b[K%Iu\u001b[m\u001b[K, block_size = %Iu MB \\n\",\n",
            "                                                              \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "                                                              \u001b[32m\u001b[K%Ilu\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:276:82:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%u\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kunsigned int\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\"pre_allocate: size = %Iu MB, num_of_blocks = %Iu, block_size = \u001b[01;35m\u001b[K%Iu\u001b[m\u001b[K MB \\n\",\n",
            "                                                                                \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "                                                                                \u001b[32m\u001b[K%Ilu\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:286:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka const long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "                 printf(\" Allocated \u001b[01;35m\u001b[K%d\u001b[m\u001b[K pinned block \\n\", pinned_block_size);\n",
            "                                    \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                    \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kcuda_make_array_pinned_preallocated\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:307:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "             printf(\"\\n Pinned block_id = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, filled = %f %% \\n\", pinned_block_id, filled);\n",
            "                                          \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                          \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:322:64:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "             printf(\"Try to allocate new pinned memory, size = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K MB \\n\", \u001b[32m\u001b[Ksize / (1024 * 1024)\u001b[m\u001b[K);\n",
            "                                                               \u001b[01;35m\u001b[K~^\u001b[m\u001b[K         \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "                                                               \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/dark_cuda.c:328:63:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Klong unsigned int\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "             printf(\"Try to allocate new pinned BLOCK, size = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K MB \\n\", \u001b[32m\u001b[Ksize / (1024 * 1024)\u001b[m\u001b[K);\n",
            "                                                              \u001b[01;35m\u001b[K~^\u001b[m\u001b[K         \u001b[32m\u001b[K~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "                                                              \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/convolutional_layer.c -o obj/convolutional_layer.o\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_convolutional_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/convolutional_layer.c:1341:32:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kt_intput_size\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                         size_t \u001b[01;35m\u001b[Kt_intput_size\u001b[m\u001b[K = binary_transpose_align_input(k, n, state.workspace, &l.t_bit_input, ldb_align, l.bit_align);\n",
            "                                \u001b[01;35m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/list.c -o obj/list.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/image.c -o obj/image.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/activations.c -o obj/activations.o\n",
            "\u001b[01m\u001b[K./src/activations.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kactivate\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KRELU6\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(a){\n",
            "     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KSWISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KHARD_MISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN_SOFTMAX\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:79:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KNORM_CHAN_SOFTMAX_MAXVAL\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kgradient\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/activations.c:310:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KSWISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(a){\n",
            "     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/activations.c:310:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "\u001b[01m\u001b[K./src/activations.c:310:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KHARD_MISH\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/im2col.c -o obj/im2col.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/col2im.c -o obj/col2im.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/blas.c -o obj/blas.o\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kbackward_shortcut_multilayer_cpu\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:207:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kout_index\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                 int \u001b[01;35m\u001b[Kout_index\u001b[m\u001b[K = id;\n",
            "                     \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfind_sim\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:597:59:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_sim(): sim isn't found: i = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, j = %d, z = %d \\n\", i, j, z);\n",
            "                                                          \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                          \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:597:67:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_sim(): sim isn't found: i = %d, j = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, z = %d \\n\", i, j, z);\n",
            "                                                                  \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                  \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:597:75:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_sim(): sim isn't found: i = %d, j = %d, z = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K \\n\", i, j, z);\n",
            "                                                                          \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                          \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfind_P_constrastive\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:611:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_P_constrastive(): P isn't found: i = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, j = %d, z = %d \\n\", i, j, z);\n",
            "                                                                   \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                   \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:611:76:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_P_constrastive(): P isn't found: i = %d, j = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, z = %d \\n\", i, j, z);\n",
            "                                                                           \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                           \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:611:84:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         printf(\" Error: find_P_constrastive(): P isn't found: i = %d, j = %d, z = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K \\n\", i, j, z);\n",
            "                                                                                   \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                                   \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KP_constrastive_f\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:651:79:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         fprintf(stderr, \" Error: in P_constrastive must be i != l, while i = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, l = %d \\n\", i, l);\n",
            "                                                                              \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                              \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:651:87:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         fprintf(stderr, \" Error: in P_constrastive must be i != l, while i = %d, l = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K \\n\", i, l);\n",
            "                                                                                      \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                                      \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KP_constrastive\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas.c:785:79:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 3 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         fprintf(stderr, \" Error: in P_constrastive must be i != l, while i = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K, l = %d \\n\", i, l);\n",
            "                                                                              \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                              \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/blas.c:785:87:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 4 has type ‘\u001b[01m\u001b[Ksize_t {aka long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "         fprintf(stderr, \" Error: in P_constrastive must be i != l, while i = %d, l = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K \\n\", i, l);\n",
            "                                                                                      \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                                      \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/crop_layer.c -o obj/crop_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/dropout_layer.c -o obj/dropout_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/maxpool_layer.c -o obj/maxpool_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/softmax_layer.c -o obj/softmax_layer.o\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_contrastive_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:203:101:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 9 has type ‘\u001b[01m\u001b[Ksize_t {aka const long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "     fprintf(stderr, \"contrastive %4d x%4d x%4d x emb_size %4d x batch: %4d  classes = %4d, step = \u001b[01;35m\u001b[K%4d\u001b[m\u001b[K \\n\", w, h, l.n, l.embedding_size, batch, l.classes, step);\n",
            "                                                                                                   \u001b[01;35m\u001b[K~~^\u001b[m\u001b[K\n",
            "                                                                                                   \u001b[32m\u001b[K%4ld\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_contrastive_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:244:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kmax_truth\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "                     float \u001b[01;35m\u001b[Kmax_truth\u001b[m\u001b[K = 0;\n",
            "                           \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/softmax_layer.c:423:71:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat ‘\u001b[01m\u001b[K%d\u001b[m\u001b[K’ expects argument of type ‘\u001b[01m\u001b[Kint\u001b[m\u001b[K’, but argument 2 has type ‘\u001b[01m\u001b[Ksize_t {aka const long unsigned int}\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wformat=\u001b[m\u001b[K]\n",
            "             printf(\" Error: too large number of bboxes: contr_size = \u001b[01;35m\u001b[K%d\u001b[m\u001b[K > max_contr_size  = %d \\n\", contr_size, max_contr_size);\n",
            "                                                                      \u001b[01;35m\u001b[K~^\u001b[m\u001b[K\n",
            "                                                                      \u001b[32m\u001b[K%ld\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/data.c -o obj/data.o\n",
            "\u001b[01m\u001b[K./src/data.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kload_data_detection\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/data.c:1297:24:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kx\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                 int k, \u001b[01;35m\u001b[Kx\u001b[m\u001b[K, y;\n",
            "                        \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/data.c:1090:43:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kr_scale\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "     float r1 = 0, r2 = 0, r3 = 0, r4 = 0, \u001b[01;35m\u001b[Kr_scale\u001b[m\u001b[K = 0;\n",
            "                                           \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/matrix.c -o obj/matrix.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/network.c -o obj/network.o\n",
            "\u001b[01m\u001b[K./src/network.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ktrain_network_waitkey\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/network.c:433:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kema_period\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         int \u001b[01;35m\u001b[Kema_period\u001b[m\u001b[K = (net.max_batches - ema_start_point - 1000) * (1.0 - net.ema_alpha);\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/network.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_network\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/network.c:658:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Knet->input_pinned_cpu, size * sizeof(float), cudaHostRegisterMapped))\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/network.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/connected_layer.c -o obj/connected_layer.o\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_connected_layer_gpu\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:346:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kone\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Kone\u001b[m\u001b[K = 1;    // alpha[0], beta[0]\n",
            "           \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:344:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kc\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float * \u001b[01;35m\u001b[Kc\u001b[m\u001b[K = l.output_gpu;\n",
            "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:343:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kb\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float * \u001b[01;35m\u001b[Kb\u001b[m\u001b[K = l.weights_gpu;\n",
            "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:342:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ka\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float * \u001b[01;35m\u001b[Ka\u001b[m\u001b[K = state.input;\n",
            "             \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:341:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kn\u001b[m\u001b[K = l.outputs;\n",
            "         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:340:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kk\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kk\u001b[m\u001b[K = l.inputs;\n",
            "         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/connected_layer.c:339:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Km\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Km\u001b[m\u001b[K = l.batch;\n",
            "         \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/cost_layer.c -o obj/cost_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/parser.c -o obj/parser.o\n",
            "\u001b[01m\u001b[K./src/parser.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kparse_network_cfg_custom\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/parser.c:1680:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Knet.input_pinned_cpu, size * sizeof(float), cudaHostRegisterMapped)) net.input_pinned_cpu_flag = 1;\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activation_layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/parser.c:6\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/parser.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kget_classes_multipliers\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/parser.c:428:29:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kargument 1 range [18446744071562067968, 18446744073709551615] exceeds maximum object size 9223372036854775807 [\u001b[01;35m\u001b[K-Walloc-size-larger-than=\u001b[m\u001b[K]\n",
            "         \u001b[01;35m\u001b[Kclasses_multipliers = (float *)calloc(classes_counters, sizeof(float))\u001b[m\u001b[K;\n",
            "         \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K./src/parser.c:3:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/include/stdlib.h:541:14:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kin a call to allocation function ‘\u001b[01m\u001b[Kcalloc\u001b[m\u001b[K’ declared here\n",
            " extern void *\u001b[01;36m\u001b[Kcalloc\u001b[m\u001b[K (size_t __nmemb, size_t __size)\n",
            "              \u001b[01;36m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/option_list.c -o obj/option_list.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/darknet.c -o obj/darknet.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/detection_layer.c -o obj/detection_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/captcha.c -o obj/captcha.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/route_layer.c -o obj/route_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/writing.c -o obj/writing.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/box.c -o obj/box.o\n",
            "\u001b[01m\u001b[K./src/box.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kbox_iou_kind\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/box.c:154:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kenumeration value ‘\u001b[01m\u001b[KMSE\u001b[m\u001b[K’ not handled in switch [\u001b[01;35m\u001b[K-Wswitch\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kswitch\u001b[m\u001b[K(iou_kind) {\n",
            "     \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/box.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdiounms_sort\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/box.c:898:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbeta_prob\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                     float \u001b[01;35m\u001b[Kbeta_prob\u001b[m\u001b[K = pow(dets[j].prob[k], 2) / sum_prob;\n",
            "                           \u001b[01;35m\u001b[K^~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/box.c:897:27:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kalpha_prob\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "                     float \u001b[01;35m\u001b[Kalpha_prob\u001b[m\u001b[K = pow(dets[i].prob[k], 2) / sum_prob;\n",
            "                           \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/nightmare.c -o obj/nightmare.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/normalization_layer.c -o obj/normalization_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/avgpool_layer.c -o obj/avgpool_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/coco.c -o obj/coco.o\n",
            "\u001b[01m\u001b[K./src/coco.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_coco_recall\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/coco.c:248:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kbase\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     char *\u001b[01;35m\u001b[Kbase\u001b[m\u001b[K = \"results/comp4_det_test_\";\n",
            "           \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/dice.c -o obj/dice.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/yolo.c -o obj/yolo.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/detector.c -o obj/detector.o\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ktrain_detector\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:386:72:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest parentheses around ‘\u001b[01m\u001b[K&&\u001b[m\u001b[K’ within ‘\u001b[01m\u001b[K||\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wparentheses\u001b[m\u001b[K]\n",
            "             \u001b[01;35m\u001b[K(iteration >= (iter_save + 1000) || iteration % 1000 == 0) && net.max_batches < 10000\u001b[m\u001b[K)\n",
            "             \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kprint_cocos\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:486:29:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kformat not a string literal and no format arguments [\u001b[01;35m\u001b[K-Wformat-security\u001b[m\u001b[K]\n",
            "                 fprintf(fp, \u001b[01;35m\u001b[Kbuff\u001b[m\u001b[K);\n",
            "                             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Keliminate_bdd\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:579:21:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kstatement with no effect [\u001b[01;35m\u001b[K-Wunused-value\u001b[m\u001b[K]\n",
            "                     \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K (k; buf[k + n] != '\\0'; k++)\n",
            "                     \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_detector\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:700:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kmkd2\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         int \u001b[01;35m\u001b[Kmkd2\u001b[m\u001b[K = make_directory(buff2, 0777);\n",
            "             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:698:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kmkd\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         int \u001b[01;35m\u001b[Kmkd\u001b[m\u001b[K = make_directory(buff, 0777);\n",
            "             \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvalidate_detector_map\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:1332:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kclass_recall\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float \u001b[01;35m\u001b[Kclass_recall\u001b[m\u001b[K = (float)tp_for_thresh_per_class[i] / ((float)tp_for_thresh_per_class[i] + (float)(truth_classes_count[i] - tp_for_thresh_per_class[i]));\n",
            "               \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:1331:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kclass_precision\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float \u001b[01;35m\u001b[Kclass_precision\u001b[m\u001b[K = (float)tp_for_thresh_per_class[i] / ((float)tp_for_thresh_per_class[i] + (float)fp_for_thresh_per_class[i]);\n",
            "               \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/detector.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdraw_object\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/detector.c:1867:19:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kinv_loss\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "             float \u001b[01;35m\u001b[Kinv_loss\u001b[m\u001b[K = 1.0 / max_val_cmp(0.01, avg_loss);\n",
            "                   \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/layer.c -o obj/layer.o\n",
            "\u001b[01m\u001b[K./src/layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfree_layer_custom\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/layer.c:208:68:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Ksuggest parentheses around ‘\u001b[01m\u001b[K&&\u001b[m\u001b[K’ within ‘\u001b[01m\u001b[K||\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wparentheses\u001b[m\u001b[K]\n",
            "     if (l.delta_gpu && (l.optimized_memory < 1 || \u001b[01;35m\u001b[Kl.keep_delta_gpu && l.optimized_memory < 3\u001b[m\u001b[K)) cuda_free(l.delta_gpu), l.delta_gpu = NULL;\n",
            "                                                   \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/compare.c -o obj/compare.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/classifier.c -o obj/classifier.o\n",
            "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Ktrain_classifier\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/classifier.c:146:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kcount\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kcount\u001b[m\u001b[K = 0;\n",
            "         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kpredict_classifier\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/classifier.c:855:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktime\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     clock_t \u001b[01;35m\u001b[Ktime\u001b[m\u001b[K;\n",
            "             \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/classifier.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdemo_classifier\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/classifier.c:1287:49:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktval_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         struct timeval tval_before, tval_after, \u001b[01;35m\u001b[Ktval_result\u001b[m\u001b[K;\n",
            "                                                 \u001b[01;35m\u001b[K^~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/classifier.c:1287:37:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktval_after\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         struct timeval tval_before, \u001b[01;35m\u001b[Ktval_after\u001b[m\u001b[K, tval_result;\n",
            "                                     \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/local_layer.c -o obj/local_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/swag.c -o obj/swag.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/shortcut_layer.c -o obj/shortcut_layer.o\n",
            "\u001b[01m\u001b[K./src/shortcut_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_shortcut_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/shortcut_layer.c:55:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kscale\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float \u001b[01;35m\u001b[Kscale\u001b[m\u001b[K = sqrt(2. / l.nweights);\n",
            "               \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/activation_layer.c -o obj/activation_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/rnn_layer.c -o obj/rnn_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/gru_layer.c -o obj/gru_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/rnn.c -o obj/rnn.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/rnn_vid.c -o obj/rnn_vid.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/crnn_layer.c -o obj/crnn_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/demo.c -o obj/demo.o\n",
            "\u001b[01m\u001b[K./src/demo.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kdetect_in_thread\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/demo.c:100:16:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kprediction\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         float *\u001b[01;35m\u001b[Kprediction\u001b[m\u001b[K = network_predict(net, X);\n",
            "                \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/demo.c:98:15:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kl\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "         layer \u001b[01;35m\u001b[Kl\u001b[m\u001b[K = net.layers[net.n - 1];\n",
            "               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/tag.c -o obj/tag.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/cifar.c -o obj/cifar.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/go.c -o obj/go.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/batchnorm_layer.c -o obj/batchnorm_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/art.c -o obj/art.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/region_layer.c -o obj/region_layer.o\n",
            "\u001b[01m\u001b[K./src/region_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_region_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/region_layer.c:59:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kold_h\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kold_h\u001b[m\u001b[K = l->h;\n",
            "         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/region_layer.c:58:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kold_w\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int \u001b[01;35m\u001b[Kold_w\u001b[m\u001b[K = l->w;\n",
            "         \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/reorg_layer.c -o obj/reorg_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/reorg_old_layer.c -o obj/reorg_old_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/super.c -o obj/super.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/voxel.c -o obj/voxel.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/tree.c -o obj/tree.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/yolo_layer.c -o obj/yolo_layer.o\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:68:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl.output, batch*l.outputs*sizeof(float), cudaHostRegisterMapped)) l.output_pinned = 1;\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:75:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl.delta, batch*l.outputs*sizeof(float), cudaHostRegisterMapped)) l.delta_pinned = 1;\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:106:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl->output, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:115:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl->delta, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/activations.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/layer.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/yolo_layer.c:1\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kprocess_batch\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:426:25:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kbest_match_t\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "                     int \u001b[01;35m\u001b[Kbest_match_t\u001b[m\u001b[K = 0;\n",
            "                         \u001b[01;35m\u001b[K^~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kforward_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:707:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kavg_anyobj\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Kavg_anyobj\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:706:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kavg_obj\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Kavg_obj\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:705:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kavg_cat\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Kavg_cat\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:704:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Krecall75\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Krecall75\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:703:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Krecall\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Krecall\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:702:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_ciou_loss\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Ktot_ciou_loss\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:701:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_diou_loss\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Ktot_diou_loss\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:698:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_ciou\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Ktot_ciou\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:697:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_diou\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Ktot_diou\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:696:11:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Ktot_giou\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     float \u001b[01;35m\u001b[Ktot_giou\u001b[m\u001b[K = 0;\n",
            "           \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/yolo_layer.c:668:12:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kunused variable ‘\u001b[01m\u001b[Kn\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K-Wunused-variable\u001b[m\u001b[K]\n",
            "     int b, \u001b[01;35m\u001b[Kn\u001b[m\u001b[K;\n",
            "            \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/gaussian_yolo_layer.c -o obj/gaussian_yolo_layer.o\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmake_gaussian_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:71:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl.output, batch*l.outputs * sizeof(float), cudaHostRegisterMapped)) l.output_pinned = 1;\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:78:38:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "     if (cudaSuccess == cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl.delta, batch*l.outputs * sizeof(float), cudaHostRegisterMapped)) l.delta_pinned = 1;\n",
            "                                      \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kresize_gaussian_yolo_layer\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:110:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl->output, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K./src/gaussian_yolo_layer.c:119:42:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kpassing argument 1 of ‘\u001b[01m\u001b[KcudaHostAlloc\u001b[m\u001b[K’ from incompatible pointer type [\u001b[01;35m\u001b[K-Wincompatible-pointer-types\u001b[m\u001b[K]\n",
            "         if (cudaSuccess != cudaHostAlloc(\u001b[01;35m\u001b[K&\u001b[m\u001b[Kl->delta, l->batch*l->outputs * sizeof(float), cudaHostRegisterMapped)) {\n",
            "                                          \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "In file included from \u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime.h:96:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kinclude/darknet.h:41\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K./src/gaussian_yolo_layer.c:7\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/cuda/include/cuda_runtime_api.h:4391:39:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[Kexpected ‘\u001b[01m\u001b[Kvoid **\u001b[m\u001b[K’ but argument is of type ‘\u001b[01m\u001b[Kfloat **\u001b[m\u001b[K’\n",
            " extern __host__ cudaError_t CUDARTAPI \u001b[01;36m\u001b[KcudaHostAlloc\u001b[m\u001b[K(void **pHost, size_t size, unsigned int flags);\n",
            "                                       \u001b[01;36m\u001b[K^~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/upsample_layer.c -o obj/upsample_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/lstm_layer.c -o obj/lstm_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/conv_lstm_layer.c -o obj/conv_lstm_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/scale_channels_layer.c -o obj/scale_channels_layer.o\n",
            "gcc -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF -c ./src/sam_layer.c -o obj/sam_layer.o\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/convolutional_kernels.cu -o obj/convolutional_kernels.o\n",
            "\u001b[01m\u001b[K./src/convolutional_kernels.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid backward_convolutional_layer_gpu(convolutional_layer, network_state)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/convolutional_kernels.cu:853:40:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcomparison between signed and unsigned integer expressions [\u001b[01;35m\u001b[K-Wsign-compare\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[K            if (*state.net.max_output16_size < l.\u001b[m\u001b[Knweights) {\n",
            "                 \u001b[01;35m\u001b[K~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/activation_kernels.cu -o obj/activation_kernels.o\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "./src/activation_kernels.cu(263): warning: variable \"MISH_THRESHOLD\" was declared but never referenced\n",
            "\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/im2col_kernels.cu -o obj/im2col_kernels.o\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/col2im_kernels.cu -o obj/col2im_kernels.o\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/blas_kernels.cu -o obj/blas_kernels.o\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1086): warning: variable \"out_index\" was declared but never referenced\n",
            "\n",
            "./src/blas_kernels.cu(1130): warning: variable \"step\" was set but never used\n",
            "\n",
            "./src/blas_kernels.cu(1736): warning: variable \"stage_id\" was declared but never referenced\n",
            "\n",
            "\u001b[01m\u001b[K./src/blas_kernels.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kvoid backward_shortcut_multilayer_gpu(int, int, int, int*, float**, float*, float*, float*, float*, int, float*, float**, WEIGHTS_NORMALIZATION_T)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/blas_kernels.cu:1130:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kstep\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kint \u001b[m\u001b[Kstep = 0;\n",
            "     \u001b[01;35m\u001b[K^~~~\u001b[m\u001b[K\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/crop_layer_kernels.cu -o obj/crop_layer_kernels.o\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/dropout_layer_kernels.cu -o obj/dropout_layer_kernels.o\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(140): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(245): warning: variable \"cur_scale\" was declared but never referenced\n",
            "\n",
            "./src/dropout_layer_kernels.cu(262): warning: variable \"block_prob\" was declared but never referenced\n",
            "\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/maxpool_layer_kernels.cu -o obj/maxpool_layer_kernels.o\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/network_kernels.cu -o obj/network_kernels.o\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "./src/network_kernels.cu(364): warning: variable \"l\" was declared but never referenced\n",
            "\n",
            "\u001b[01m\u001b[K./src/network_kernels.cu:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kfloat train_network_datum_gpu(network, float*, float*)\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K./src/network_kernels.cu:364:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kvariable ‘\u001b[01m\u001b[Kl\u001b[m\u001b[K’ set but not used [\u001b[01;35m\u001b[K-Wunused-but-set-variable\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[K \u001b[m\u001b[K layer l = net.layers[net.n - 1];\n",
            "       \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "nvcc -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=[sm_50,compute_50] -gencode arch=compute_52,code=[sm_52,compute_52] -gencode arch=compute_61,code=[sm_61,compute_61] -gencode arch=compute_70,code=[sm_70,compute_70] -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF --compiler-options \"-Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF\" -c ./src/avgpool_layer_kernels.cu -o obj/avgpool_layer_kernels.o\n",
            "g++ -std=c++11 -std=c++11 -Iinclude/ -I3rdparty/stb/include -DOPENCV `pkg-config --cflags opencv4 2> /dev/null || pkg-config --cflags opencv` -DGPU -I/usr/local/cuda/include/ -DCUDNN -DCUDNN_HALF -Wall -Wfatal-errors -Wno-unused-result -Wno-unknown-pragmas -fPIC -Ofast -DOPENCV -DGPU -DCUDNN -I/usr/local/cudnn/include -DCUDNN_HALF obj/image_opencv.o obj/http_stream.o obj/gemm.o obj/utils.o obj/dark_cuda.o obj/convolutional_layer.o obj/list.o obj/image.o obj/activations.o obj/im2col.o obj/col2im.o obj/blas.o obj/crop_layer.o obj/dropout_layer.o obj/maxpool_layer.o obj/softmax_layer.o obj/data.o obj/matrix.o obj/network.o obj/connected_layer.o obj/cost_layer.o obj/parser.o obj/option_list.o obj/darknet.o obj/detection_layer.o obj/captcha.o obj/route_layer.o obj/writing.o obj/box.o obj/nightmare.o obj/normalization_layer.o obj/avgpool_layer.o obj/coco.o obj/dice.o obj/yolo.o obj/detector.o obj/layer.o obj/compare.o obj/classifier.o obj/local_layer.o obj/swag.o obj/shortcut_layer.o obj/activation_layer.o obj/rnn_layer.o obj/gru_layer.o obj/rnn.o obj/rnn_vid.o obj/crnn_layer.o obj/demo.o obj/tag.o obj/cifar.o obj/go.o obj/batchnorm_layer.o obj/art.o obj/region_layer.o obj/reorg_layer.o obj/reorg_old_layer.o obj/super.o obj/voxel.o obj/tree.o obj/yolo_layer.o obj/gaussian_yolo_layer.o obj/upsample_layer.o obj/lstm_layer.o obj/conv_lstm_layer.o obj/scale_channels_layer.o obj/sam_layer.o obj/convolutional_kernels.o obj/activation_kernels.o obj/im2col_kernels.o obj/col2im_kernels.o obj/blas_kernels.o obj/crop_layer_kernels.o obj/dropout_layer_kernels.o obj/maxpool_layer_kernels.o obj/network_kernels.o obj/avgpool_layer_kernels.o -o darknet -lm -pthread `pkg-config --libs opencv4 2> /dev/null || pkg-config --libs opencv` -L/usr/local/cuda/lib64 -lcuda -lcudart -lcublas -lcurand -L/usr/local/cudnn/lib64 -lcudnn -lstdc++\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ35pU_Hs3R3",
        "outputId": "5618b5c4-bd50-4bc2-e1ad-e3ceac494aaa"
      },
      "source": [
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-13 07:27:02--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/75388965/ba4b6380-889c-11ea-9751-f994f5961796?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210113%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210113T072702Z&X-Amz-Expires=300&X-Amz-Signature=f8447aef1b6f950b16f24fd759c2bb4e319fc52f358a3a4eb8da6fd809ad2718&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-01-13 07:27:02--  https://github-production-release-asset-2e65be.s3.amazonaws.com/75388965/ba4b6380-889c-11ea-9751-f994f5961796?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210113%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210113T072702Z&X-Amz-Expires=300&X-Amz-Signature=f8447aef1b6f950b16f24fd759c2bb4e319fc52f358a3a4eb8da6fd809ad2718&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.90.252\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.90.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257717640 (246M) [application/octet-stream]\n",
            "Saving to: ‘yolov4.weights’\n",
            "\n",
            "yolov4.weights      100%[===================>] 245.78M  46.4MB/s    in 5.7s    \n",
            "\n",
            "2021-01-13 07:27:08 (42.9 MB/s) - ‘yolov4.weights’ saved [257717640/257717640]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cvwkbek9xO2",
        "outputId": "977148f1-c9cd-44d9-c5f7-105db6a1f202"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PJYkx3ps_-G"
      },
      "source": [
        "# Run pre-trained model on images for pre-annotation\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOSEpS7oSnkU"
      },
      "source": [
        "Download video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq49P7Qds8oU",
        "outputId": "3ceec601-99aa-4f5a-cb53-4e0fbc644d41"
      },
      "source": [
        "!wget -O video.zip https://video-downloads.googleusercontent.com/AGQNM9IhueypD9T0za2nWTx-1QfR_m4MS6FTKYMOnFR4xiepfkAQolOGrfyviQUaMnB-QcF-3FcpMYXdDhkumZBl_PC2elRAVNDQR_CAXR9Zz7_DyWVxkvP809MZ3Mfp1DnTHKE5e2jCITkDqJriSVVRujXZE7_G4KFMnjdltzuDETNKl-FqZKiBkRqEmEaL7V3NNCshlB1s-4b_v3Ti0VB0EnDBM94FtLI1wyAfKfYQnhh74JjIUsIiz1gwrX0YqXyGPXAzsqiVGUYkkJ5fKKCjcqruvnVkxgLBpFT74p9PQ4LVDsypXIUYkA6p9NewUTuiGOOPOpzjC5tgCXqEtu3qwvrrC_2bY57GJQtzHcur4HGxQy0pbT9HYzgeTceDOmLNtxUpHBBD9QtQZ-WkydRKPUuY7_9TmVkzEaHcCenI1Hs6ujlzxZxdqS4d0UhyDprHGbY2kys0qfZXagUHqBhsFmbFnBPIB42qMz-hGpZ_OKQbHf_9JcUDZZgCHFcA1bEcXy6MozQVr5O9V1zrIklfq30PdUXCirPtj0peHLkh6jjRNgdZv_fDxWiLgv-SmDW2eHPx6dtHT1kda0k2_T4nIV1FBBcGN2CMYWfDA94gFTOrugJfKzKkB0U0tQ3XsQ00_b4d4vmXJ_l7grgzQh-z7ZE69zR-1WZci_hgj1IWR6bqhrgPBkAyI_v2Ub1NbAbvYjn-yoCuLVmAk9vPZ2zLPbuInYFqwxlw6kH4ns69sY06QZKqH0CzYOTa0U4THxD4P9ssHS_JsXLnmACh7qNYm_1Cp4NTGOo3hD5gtTVwETBc7sq4SMMMTvb2vhoNGNb1y8qcaEkJXkkeiOn5Q449BIPUVd25PuQGAK9Z08pkoFMt-yVYHFj3zrbs9qd_HZxt7Cgr-FwObgS9of-3CtW3PGaSxI-uLvMokS7IWvie04ZoLpdOIRE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-13 07:27:08--  https://video-downloads.googleusercontent.com/AGQNM9IhueypD9T0za2nWTx-1QfR_m4MS6FTKYMOnFR4xiepfkAQolOGrfyviQUaMnB-QcF-3FcpMYXdDhkumZBl_PC2elRAVNDQR_CAXR9Zz7_DyWVxkvP809MZ3Mfp1DnTHKE5e2jCITkDqJriSVVRujXZE7_G4KFMnjdltzuDETNKl-FqZKiBkRqEmEaL7V3NNCshlB1s-4b_v3Ti0VB0EnDBM94FtLI1wyAfKfYQnhh74JjIUsIiz1gwrX0YqXyGPXAzsqiVGUYkkJ5fKKCjcqruvnVkxgLBpFT74p9PQ4LVDsypXIUYkA6p9NewUTuiGOOPOpzjC5tgCXqEtu3qwvrrC_2bY57GJQtzHcur4HGxQy0pbT9HYzgeTceDOmLNtxUpHBBD9QtQZ-WkydRKPUuY7_9TmVkzEaHcCenI1Hs6ujlzxZxdqS4d0UhyDprHGbY2kys0qfZXagUHqBhsFmbFnBPIB42qMz-hGpZ_OKQbHf_9JcUDZZgCHFcA1bEcXy6MozQVr5O9V1zrIklfq30PdUXCirPtj0peHLkh6jjRNgdZv_fDxWiLgv-SmDW2eHPx6dtHT1kda0k2_T4nIV1FBBcGN2CMYWfDA94gFTOrugJfKzKkB0U0tQ3XsQ00_b4d4vmXJ_l7grgzQh-z7ZE69zR-1WZci_hgj1IWR6bqhrgPBkAyI_v2Ub1NbAbvYjn-yoCuLVmAk9vPZ2zLPbuInYFqwxlw6kH4ns69sY06QZKqH0CzYOTa0U4THxD4P9ssHS_JsXLnmACh7qNYm_1Cp4NTGOo3hD5gtTVwETBc7sq4SMMMTvb2vhoNGNb1y8qcaEkJXkkeiOn5Q449BIPUVd25PuQGAK9Z08pkoFMt-yVYHFj3zrbs9qd_HZxt7Cgr-FwObgS9of-3CtW3PGaSxI-uLvMokS7IWvie04ZoLpdOIRE\n",
            "Resolving video-downloads.googleusercontent.com (video-downloads.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to video-downloads.googleusercontent.com (video-downloads.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘video.zip’\n",
            "\n",
            "video.zip               [         <=>        ] 728.16M  18.1MB/s    in 47s     \n",
            "\n",
            "2021-01-13 07:27:58 (15.6 MB/s) - ‘video.zip’ saved [763535412]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmqpxiTS2bSY",
        "outputId": "090121c9-49f0-4322-f6db-e5b8998f82ac"
      },
      "source": [
        "!mkdir 'video'\r\n",
        "!unzip video.zip -d video"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  video.zip\n",
            "  inflating: video/20210112_164746.mp4  \n",
            "  inflating: video/20210112_164834.mp4  \n",
            "  inflating: video/VID_20210112_173626_764.mp4  \n",
            "  inflating: video/VID_20210112_173640.mp4  \n",
            "  inflating: video/VID_20210112_173654_487.mp4  \n",
            "  inflating: video/VID20210112173653.mp4  \n",
            "  inflating: video/VID_20210112_173706.mp4  \n",
            "  inflating: video/VID_20210112_173733.mp4  \n",
            "  inflating: video/VID_20210112_173733_731.mp4  \n",
            "  inflating: video/20210112_173510.mp4  \n",
            "  inflating: video/VID20210112173730.mp4  \n",
            "  inflating: video/VID_20210112_173800.mp4  \n",
            "  inflating: video/VID20210112173818.mp4  \n",
            "  inflating: video/VID_20210112_173846_288.mp4  \n",
            "  inflating: video/VID20210112173844.mp4  \n",
            "  inflating: video/VID_20210112_173920.mp4  \n",
            "  inflating: video/VID_20210112_173951.mp4  \n",
            "  inflating: video/20210112_173758.mp4  \n",
            "  inflating: video/VID_20210112_174127.mp4  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFG6XxtCSv5H"
      },
      "source": [
        "Extract images from videos, save all images to folder frames and image paths to file images.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQJXruMC6JRD",
        "outputId": "9d935c02-8356-40fa-8459-f4c8068c9a39"
      },
      "source": [
        "import cv2\r\n",
        "import os\r\n",
        "!mkdir frames\r\n",
        "video_files = os.listdir('video')\r\n",
        "path_list = []\r\n",
        "for video_file in video_files:\r\n",
        "    print('Video', video_file)\r\n",
        "    video_file, extension = video_file.split('.')\r\n",
        "    !mkdir frames/$video_file\r\n",
        "    video = cv2.VideoCapture(os.path.join('video', video_file + '.' + extension))\r\n",
        "    i = 0\r\n",
        "    while True:\r\n",
        "        success, frame = video.read()\r\n",
        "        if not success:\r\n",
        "            break\r\n",
        "        if i % 15 == 0:\r\n",
        "            path = os.path.join('/content/frames', video_file, str(int(i/15)+1)+'.jpg')\r\n",
        "            cv2.imwrite(path, frame)\r\n",
        "            path_list.append(path)\r\n",
        "        i += 1\r\n",
        "with open('images.txt', 'w') as f:\r\n",
        "    f.write('\\n'.join(path_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Video VID_20210112_173706.mp4\n",
            "Video VID_20210112_174127.mp4\n",
            "Video VID_20210112_173951.mp4\n",
            "Video VID_20210112_173640.mp4\n",
            "Video VID20210112173653.mp4\n",
            "Video VID20210112173730.mp4\n",
            "Video VID_20210112_173846_288.mp4\n",
            "Video VID20210112173844.mp4\n",
            "Video VID_20210112_173733.mp4\n",
            "Video 20210112_164834.mp4\n",
            "Video VID_20210112_173733_731.mp4\n",
            "Video 20210112_164746.mp4\n",
            "Video VID_20210112_173800.mp4\n",
            "Video 20210112_173510.mp4\n",
            "Video VID20210112173818.mp4\n",
            "Video 20210112_173758.mp4\n",
            "Video VID_20210112_173626_764.mp4\n",
            "Video VID_20210112_173654_487.mp4\n",
            "Video VID_20210112_173920.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-8wIwRxTBPI"
      },
      "source": [
        "Run model on images, save results to result.json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en5TivyN1e7p",
        "outputId": "0a5ffaa7-5b59-4249-c32f-50b6b725c25c"
      },
      "source": [
        "%cd darknet\r\n",
        "!./darknet detector test cfg/coco.data cfg/yolov4.cfg yolov4.weights -dont_show -ext_output -out /content/result.json < /content/images.txt\r\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "motorbike: 94%\t(left_x:  996   top_y:  598   width:  940   height:  486)\n",
            "person: 80%\t(left_x: 1258   top_y:  193   width:  430   height:  892)\n",
            "person: 85%\t(left_x: 1268   top_y:  264   width:   61   height:  139)\n",
            "car: 95%\t(left_x: 1576   top_y:  308   width:  344   height:  325)\n",
            "person: 28%\t(left_x: 1705   top_y:  271   width:   36   height:   39)\n",
            "clock: 34%\t(left_x: 1730   top_y:  186   width:   29   height:   42)\n",
            "person: 98%\t(left_x: 1843   top_y:  243   width:   77   height:  114)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/149.jpg: Predicted in 54.745000 milli-seconds.\n",
            "car: 29%\t(left_x:   -1   top_y:  288   width:   31   height:   27)\n",
            "person: 79%\t(left_x:   -0   top_y:  287   width:   67   height:  156)\n",
            "motorbike: 46%\t(left_x:    0   top_y:  319   width:   64   height:  140)\n",
            "car: 100%\t(left_x:   82   top_y:  302   width:  204   height:  106)\n",
            "person: 49%\t(left_x:  246   top_y:  290   width:   38   height:   53)\n",
            "car: 66%\t(left_x:  307   top_y:  301   width:   82   height:   69)\n",
            "car: 51%\t(left_x:  369   top_y:  292   width:   54   height:   87)\n",
            "motorbike: 69%\t(left_x:  370   top_y:  336   width:   64   height:   60)\n",
            "person: 88%\t(left_x:  372   top_y:  293   width:   51   height:   86)\n",
            "motorbike: 94%\t(left_x:  642   top_y:  345   width:   91   height:   77)\n",
            "person: 87%\t(left_x:  644   top_y:  291   width:   70   height:  111)\n",
            "motorbike: 99%\t(left_x:  798   top_y:  406   width:  376   height:  359)\n",
            "person: 83%\t(left_x:  812   top_y:  275   width:  255   height:  375)\n",
            "car: 99%\t(left_x: 1154   top_y:  265   width:  767   height:  323)\n",
            "person: 91%\t(left_x: 1261   top_y:  263   width:   36   height:   86)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/150.jpg: Predicted in 54.812000 milli-seconds.\n",
            "person: 29%\t(left_x:   -0   top_y:  288   width:   20   height:   32)\n",
            "person: 28%\t(left_x:    6   top_y:  300   width:   58   height:  106)\n",
            "motorbike: 48%\t(left_x:   17   top_y:  341   width:   43   height:   75)\n",
            "person: 70%\t(left_x:   37   top_y:  293   width:   98   height:  142)\n",
            "motorbike: 92%\t(left_x:   45   top_y:  339   width:   90   height:  139)\n",
            "car: 99%\t(left_x:  118   top_y:  293   width:  219   height:  123)\n",
            "person: 36%\t(left_x:  301   top_y:  291   width:   51   height:   84)\n",
            "person: 62%\t(left_x:  301   top_y:  286   width:   43   height:   45)\n",
            "car: 95%\t(left_x:  334   top_y:  294   width:  129   height:   74)\n",
            "person: 35%\t(left_x:  499   top_y:  288   width:   27   height:   32)\n",
            "motorbike: 78%\t(left_x:  510   top_y:  334   width:   80   height:   65)\n",
            "person: 93%\t(left_x:  512   top_y:  289   width:   57   height:   85)\n",
            "person: 26%\t(left_x:  635   top_y:  284   width:   33   height:   76)\n",
            "car: 100%\t(left_x:  880   top_y:  256   width:  532   height:  259)\n",
            "person: 28%\t(left_x: 1030   top_y:  251   width:   25   height:   27)\n",
            "motorbike: 73%\t(left_x: 1435   top_y:  529   width:  485   height:  492)\n",
            "person: 85%\t(left_x: 1528   top_y:  233   width:  393   height:  624)\n",
            "clock: 29%\t(left_x: 1744   top_y:  179   width:   29   height:   42)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/151.jpg: Predicted in 54.853000 milli-seconds.\n",
            "person: 27%\t(left_x:   -2   top_y:  287   width:   22   height:   35)\n",
            "motorbike: 80%\t(left_x:   -0   top_y:  349   width:   54   height:  114)\n",
            "person: 54%\t(left_x:   -0   top_y:  311   width:   54   height:  148)\n",
            "person: 47%\t(left_x:   37   top_y:  284   width:   79   height:   76)\n",
            "person: 38%\t(left_x:   40   top_y:  285   width:   69   height:  130)\n",
            "motorbike: 93%\t(left_x:   46   top_y:  336   width:   65   height:  102)\n",
            "person: 42%\t(left_x:   75   top_y:  288   width:   44   height:   59)\n",
            "person: 84%\t(left_x:  132   top_y:  281   width:  117   height:  216)\n",
            "motorbike: 90%\t(left_x:  142   top_y:  356   width:  109   height:  167)\n",
            "car: 87%\t(left_x:  157   top_y:  295   width:  256   height:  132)\n",
            "car: 63%\t(left_x:  348   top_y:  297   width:   75   height:   57)\n",
            "person: 75%\t(left_x:  414   top_y:  292   width:   53   height:   81)\n",
            "motorbike: 92%\t(left_x:  419   top_y:  337   width:   61   height:   55)\n",
            "person: 35%\t(left_x:  506   top_y:  286   width:   25   height:   29)\n",
            "car: 100%\t(left_x:  692   top_y:  273   width:  397   height:  200)\n",
            "person: 99%\t(left_x: 1175   top_y:  256   width:   43   height:  144)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/152.jpg: Predicted in 54.803000 milli-seconds.\n",
            "motorbike: 36%\t(left_x:   -1   top_y:  301   width:   22   height:   37)\n",
            "person: 34%\t(left_x:   23   top_y:  290   width:  106   height:   84)\n",
            "person: 88%\t(left_x:   28   top_y:  288   width:  126   height:  196)\n",
            "motorbike: 88%\t(left_x:   50   top_y:  362   width:  113   height:  140)\n",
            "motorbike: 49%\t(left_x:  133   top_y:  307   width:   45   height:   85)\n",
            "person: 28%\t(left_x:  164   top_y:  292   width:   33   height:   57)\n",
            "motorbike: 29%\t(left_x:  203   top_y:  301   width:   42   height:   68)\n",
            "motorbike: 34%\t(left_x:  207   top_y:  318   width:   32   height:   55)\n",
            "person: 94%\t(left_x:  232   top_y:  272   width:  150   height:  279)\n",
            "motorbike: 92%\t(left_x:  236   top_y:  368   width:  149   height:  240)\n",
            "car: 76%\t(left_x:  244   top_y:  293   width:  241   height:  160)\n",
            "car: 100%\t(left_x:  552   top_y:  278   width:  323   height:  164)\n",
            "person: 96%\t(left_x: 1145   top_y:  269   width:   38   height:  129)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/153.jpg: Predicted in 54.836000 milli-seconds.\n",
            "motorbike: 57%\t(left_x:   -1   top_y:  342   width:   21   height:   71)\n",
            "person: 66%\t(left_x:   -1   top_y:  303   width:   28   height:   93)\n",
            "motorbike: 77%\t(left_x:   41   top_y:  323   width:   45   height:   52)\n",
            "person: 43%\t(left_x:   84   top_y:  280   width:   78   height:  150)\n",
            "person: 42%\t(left_x:   86   top_y:  282   width:   66   height:   76)\n",
            "motorbike: 94%\t(left_x:   97   top_y:  352   width:   71   height:  107)\n",
            "person: 32%\t(left_x:  131   top_y:  291   width:  116   height:  179)\n",
            "person: 28%\t(left_x:  140   top_y:  290   width:  104   height:   88)\n",
            "motorbike: 94%\t(left_x:  162   top_y:  370   width:  129   height:  194)\n",
            "person: 36%\t(left_x:  199   top_y:  290   width:   45   height:   54)\n",
            "person: 29%\t(left_x:  201   top_y:  291   width:   33   height:   39)\n",
            "person: 30%\t(left_x:  233   top_y:  292   width:   29   height:   52)\n",
            "motorbike: 59%\t(left_x:  279   top_y:  318   width:   41   height:   55)\n",
            "person: 31%\t(left_x:  280   top_y:  284   width:   43   height:   75)\n",
            "car: 94%\t(left_x:  302   top_y:  291   width:  323   height:  175)\n",
            "motorbike: 99%\t(left_x:  403   top_y:  432   width:  238   height:  344)\n",
            "person: 87%\t(left_x:  410   top_y:  277   width:  213   height:  381)\n",
            "car: 97%\t(left_x:  523   top_y:  277   width:  198   height:  141)\n",
            "person: 99%\t(left_x: 1124   top_y:  267   width:   39   height:  124)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/154.jpg: Predicted in 54.916000 milli-seconds.\n",
            "person: 81%\t(left_x:   -1   top_y:  278   width:   60   height:  114)\n",
            "motorbike: 81%\t(left_x:   -0   top_y:  327   width:   58   height:   92)\n",
            "motorbike: 70%\t(left_x:   50   top_y:  316   width:   40   height:   59)\n",
            "person: 32%\t(left_x:  107   top_y:  290   width:   19   height:   29)\n",
            "person: 86%\t(left_x:  117   top_y:  279   width:   91   height:  147)\n",
            "person: 48%\t(left_x:  119   top_y:  276   width:   80   height:   86)\n",
            "motorbike: 97%\t(left_x:  124   top_y:  341   width:   89   height:  126)\n",
            "person: 36%\t(left_x:  169   top_y:  283   width:   27   height:   43)\n",
            "motorbike: 77%\t(left_x:  236   top_y:  307   width:   41   height:   54)\n",
            "person: 90%\t(left_x:  267   top_y:  270   width:  163   height:  314)\n",
            "motorbike: 95%\t(left_x:  286   top_y:  388   width:  186   height:  264)\n",
            "car: 100%\t(left_x:  379   top_y:  282   width:  405   height:  219)\n",
            "car: 57%\t(left_x:  393   top_y:  272   width:  169   height:   43)\n",
            "motorbike: 66%\t(left_x:  731   top_y:  562   width:  711   height:  516)\n",
            "person: 47%\t(left_x:  818   top_y:  237   width:  506   height:  714)\n",
            "person: 73%\t(left_x: 1094   top_y:  261   width:   45   height:  134)\n",
            "motorbike: 96%\t(left_x: 1409   top_y:  362   width:  289   height:  166)\n",
            "person: 88%\t(left_x: 1481   top_y:  272   width:  159   height:  206)\n",
            "person: 34%\t(left_x: 1596   top_y:  270   width:   69   height:   79)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/155.jpg: Predicted in 54.893000 milli-seconds.\n",
            "person: 50%\t(left_x:   -1   top_y:  277   width:   55   height:  112)\n",
            "motorbike: 89%\t(left_x:   -0   top_y:  323   width:   57   height:  104)\n",
            "motorbike: 26%\t(left_x:   88   top_y:  279   width:   42   height:   52)\n",
            "motorbike: 41%\t(left_x:   92   top_y:  301   width:   32   height:   35)\n",
            "person: 83%\t(left_x:  107   top_y:  272   width:  111   height:  162)\n",
            "person: 26%\t(left_x:  110   top_y:  269   width:  100   height:  102)\n",
            "motorbike: 96%\t(left_x:  116   top_y:  345   width:  107   height:  140)\n",
            "person: 41%\t(left_x:  203   top_y:  263   width:   29   height:   66)\n",
            "motorbike: 39%\t(left_x:  205   top_y:  277   width:   28   height:   58)\n",
            "car: 93%\t(left_x:  244   top_y:  274   width:  216   height:  101)\n",
            "person: 51%\t(left_x:  250   top_y:  273   width:  196   height:  111)\n",
            "person: 63%\t(left_x:  301   top_y:  276   width:   94   height:  121)\n",
            "motorbike: 70%\t(left_x:  313   top_y:  311   width:   90   height:  107)\n",
            "person: 27%\t(left_x:  451   top_y:  265   width:  261   height:  428)\n",
            "person: 40%\t(left_x:  457   top_y:  264   width:  162   height:  243)\n",
            "motorbike: 99%\t(left_x:  463   top_y:  461   width:  316   height:  394)\n",
            "car: 100%\t(left_x:  562   top_y:  282   width:  421   height:  246)\n",
            "bicycle: 29%\t(left_x:  951   top_y:  285   width:   43   height:   91)\n",
            "person: 63%\t(left_x:  955   top_y:  273   width:   38   height:   99)\n",
            "motorbike: 83%\t(left_x: 1023   top_y:  341   width:  187   height:  130)\n",
            "person: 41%\t(left_x: 1046   top_y:  255   width:   46   height:   91)\n",
            "person: 81%\t(left_x: 1062   top_y:  277   width:  136   height:  158)\n",
            "person: 25%\t(left_x: 1710   top_y:  259   width:   35   height:   37)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/156.jpg: Predicted in 54.831000 milli-seconds.\n",
            "car: 97%\t(left_x:   -3   top_y:  270   width:  176   height:  106)\n",
            "car: 49%\t(left_x:   -1   top_y:  307   width:   63   height:  214)\n",
            "car: 87%\t(left_x:  137   top_y:  278   width:  138   height:   81)\n",
            "motorbike: 84%\t(left_x:  243   top_y:  313   width:  126   height:  134)\n",
            "person: 58%\t(left_x:  252   top_y:  275   width:  112   height:  145)\n",
            "car: 96%\t(left_x:  444   top_y:  283   width:  708   height:  334)\n",
            "motorbike: 73%\t(left_x:  781   top_y:  595   width:  996   height:  479)\n",
            "person: 39%\t(left_x:  858   top_y:  262   width:   36   height:   33)\n",
            "person: 75%\t(left_x:  880   top_y:  268   width:  583   height:  812)\n",
            "cell phone: 31%\t(left_x: 1171   top_y:  604   width:   75   height:   26)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/157.jpg: Predicted in 54.822000 milli-seconds.\n",
            "motorbike: 98%\t(left_x:   83   top_y:  327   width:  187   height:  175)\n",
            "person: 91%\t(left_x:  109   top_y:  273   width:  119   height:  186)\n",
            "car: 100%\t(left_x:  392   top_y:  273   width: 1053   height:  466)\n",
            "car: 41%\t(left_x: 1835   top_y:  400   width:   85   height:  135)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/158.jpg: Predicted in 54.870000 milli-seconds.\n",
            "car: 100%\t(left_x:  180   top_y:  261   width: 1492   height:  526)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/159.jpg: Predicted in 57.116000 milli-seconds.\n",
            "car: 100%\t(left_x:  262   top_y:  226   width: 1552   height:  559)\n",
            "person: 82%\t(left_x: 1833   top_y:  211   width:   89   height:  180)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/160.jpg: Predicted in 54.890000 milli-seconds.\n",
            "car: 100%\t(left_x:  336   top_y:  248   width: 1195   height:  512)\n",
            "car: 27%\t(left_x: 1732   top_y:  273   width:  101   height:   45)\n",
            "car: 60%\t(left_x: 1814   top_y:  289   width:  105   height:   89)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/161.jpg: Predicted in 54.798000 milli-seconds.\n",
            "car: 100%\t(left_x:  538   top_y:  304   width:  890   height:  405)\n",
            "car: 46%\t(left_x: 1176   top_y:  308   width:  205   height:   49)\n",
            "car: 37%\t(left_x: 1271   top_y:  334   width:  164   height:   91)\n",
            "car: 97%\t(left_x: 1508   top_y:  320   width:  190   height:  122)\n",
            "car: 87%\t(left_x: 1683   top_y:  332   width:  137   height:   45)\n",
            "car: 95%\t(left_x: 1773   top_y:  334   width:  150   height:   52)\n",
            "car: 55%\t(left_x: 1851   top_y:  395   width:   69   height:  206)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/162.jpg: Predicted in 54.794000 milli-seconds.\n",
            "motorbike: 90%\t(left_x:   -5   top_y:  394   width:  269   height:  314)\n",
            "person: 58%\t(left_x:    1   top_y:  247   width:  175   height:  368)\n",
            "motorbike: 73%\t(left_x:  118   top_y:  375   width:  293   height:  181)\n",
            "person: 46%\t(left_x:  203   top_y:  297   width:  116   height:  165)\n",
            "person: 89%\t(left_x:  500   top_y:  278   width:   98   height:  165)\n",
            "car: 100%\t(left_x:  736   top_y:  313   width:  694   height:  303)\n",
            "person: 41%\t(left_x: 1156   top_y:  303   width:  122   height:   27)\n",
            "car: 35%\t(left_x: 1156   top_y:  304   width:  122   height:   26)\n",
            "car: 47%\t(left_x: 1303   top_y:  318   width:  150   height:   77)\n",
            "car: 81%\t(left_x: 1433   top_y:  320   width:  118   height:   48)\n",
            "car: 82%\t(left_x: 1530   top_y:  325   width:   96   height:   46)\n",
            "car: 37%\t(left_x: 1693   top_y:  320   width:  103   height:   57)\n",
            "motorbike: 47%\t(left_x: 1750   top_y:  418   width:  107   height:  114)\n",
            "person: 47%\t(left_x: 1801   top_y:  310   width:  114   height:  141)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/163.jpg: Predicted in 54.764000 milli-seconds.\n",
            "motorbike: 99%\t(left_x:  129   top_y:  374   width:  396   height:  235)\n",
            "pottedplant: 38%\t(left_x:  158   top_y:  243   width:  137   height:  120)\n",
            "person: 98%\t(left_x:  276   top_y:  221   width:  206   height:  297)\n",
            "person: 98%\t(left_x:  507   top_y:  224   width:   50   height:  146)\n",
            "motorbike: 67%\t(left_x:  761   top_y:  305   width:  101   height:   95)\n",
            "person: 32%\t(left_x:  765   top_y:  279   width:   78   height:  109)\n",
            "person: 79%\t(left_x:  794   top_y:  270   width:   53   height:  101)\n",
            "car: 100%\t(left_x:  861   top_y:  273   width:  468   height:  254)\n",
            "person: 65%\t(left_x:  967   top_y:  263   width:   21   height:   36)\n",
            "car: 39%\t(left_x:  998   top_y:  265   width:  104   height:   18)\n",
            "person: 38%\t(left_x: 1236   top_y:  278   width:   29   height:   35)\n",
            "motorbike: 31%\t(left_x: 1260   top_y:  295   width:   48   height:   52)\n",
            "person: 28%\t(left_x: 1267   top_y:  283   width:   36   height:   43)\n",
            "person: 67%\t(left_x: 1408   top_y:  287   width:   34   height:   44)\n",
            "motorbike: 33%\t(left_x: 1409   top_y:  297   width:   35   height:   38)\n",
            "person: 57%\t(left_x: 1446   top_y:  294   width:   52   height:   56)\n",
            "motorbike: 40%\t(left_x: 1447   top_y:  295   width:   50   height:   54)\n",
            "person: 28%\t(left_x: 1459   top_y:  281   width:   43   height:   57)\n",
            "person: 42%\t(left_x: 1489   top_y:  283   width:   23   height:   50)\n",
            "car: 93%\t(left_x: 1518   top_y:  292   width:  111   height:   49)\n",
            "motorbike: 79%\t(left_x: 1594   top_y:  310   width:   80   height:   54)\n",
            "person: 55%\t(left_x: 1596   top_y:  289   width:   75   height:   67)\n",
            "motorbike: 54%\t(left_x: 1819   top_y:  311   width:   43   height:   73)\n",
            "car: 41%\t(left_x: 1897   top_y:  305   width:   24   height:   89)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/164.jpg: Predicted in 54.949000 milli-seconds.\n",
            "motorbike: 69%\t(left_x:   -5   top_y:  588   width:  552   height:  368)\n",
            "person: 67%\t(left_x:   -4   top_y:  238   width:  296   height:  616)\n",
            "person: 87%\t(left_x:   63   top_y:  217   width:  422   height:  523)\n",
            "bus: 37%\t(left_x:  276   top_y:  170   width:  226   height:   67)\n",
            "person: 95%\t(left_x:  276   top_y:  213   width:   60   height:  169)\n",
            "person: 95%\t(left_x:  463   top_y:  201   width:   48   height:  138)\n",
            "motorbike: 97%\t(left_x:  545   top_y:  329   width:  231   height:  179)\n",
            "person: 99%\t(left_x:  617   top_y:  216   width:  149   height:  226)\n",
            "car: 100%\t(left_x:  718   top_y:  230   width:  302   height:  181)\n",
            "car: 100%\t(left_x:  994   top_y:  246   width:  422   height:  203)\n",
            "car: 84%\t(left_x: 1010   top_y:  227   width:  147   height:   63)\n",
            "person: 55%\t(left_x: 1367   top_y:  243   width:   31   height:   44)\n",
            "person: 61%\t(left_x: 1383   top_y:  250   width:   45   height:   58)\n",
            "person: 44%\t(left_x: 1401   top_y:  233   width:   33   height:   65)\n",
            "car: 93%\t(left_x: 1429   top_y:  244   width:  123   height:   52)\n",
            "bicycle: 44%\t(left_x: 1523   top_y:  270   width:   66   height:   33)\n",
            "person: 56%\t(left_x: 1545   top_y:  233   width:   26   height:   64)\n",
            "person: 42%\t(left_x: 1589   top_y:  235   width:   34   height:   60)\n",
            "person: 28%\t(left_x: 1606   top_y:  236   width:   43   height:   80)\n",
            "motorbike: 48%\t(left_x: 1609   top_y:  266   width:   42   height:   52)\n",
            "person: 36%\t(left_x: 1611   top_y:  236   width:   32   height:   55)\n",
            "person: 29%\t(left_x: 1638   top_y:  237   width:   23   height:   54)\n",
            "car: 37%\t(left_x: 1875   top_y:  250   width:   46   height:  107)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/165.jpg: Predicted in 54.780000 milli-seconds.\n",
            "motorbike: 49%\t(left_x:   -2   top_y:  772   width:  334   height:  310)\n",
            "person: 91%\t(left_x:  276   top_y:  210   width:   59   height:  175)\n",
            "bus: 52%\t(left_x:  330   top_y:  171   width:  225   height:   63)\n",
            "car: 98%\t(left_x:  374   top_y:  218   width:  427   height:  238)\n",
            "person: 56%\t(left_x:  438   top_y:  205   width:   51   height:   82)\n",
            "person: 30%\t(left_x:  506   top_y:  217   width:   40   height:   38)\n",
            "motorbike: 94%\t(left_x:  710   top_y:  387   width:  282   height:  283)\n",
            "person: 73%\t(left_x:  725   top_y:  241   width:  199   height:  336)\n",
            "person: 27%\t(left_x:  805   top_y:  228   width:  163   height:  159)\n",
            "person: 49%\t(left_x:  859   top_y:  222   width:  114   height:  136)\n",
            "car: 97%\t(left_x:  919   top_y:  240   width:  131   height:   44)\n",
            "car: 48%\t(left_x: 1023   top_y:  241   width:   48   height:   37)\n",
            "car: 69%\t(left_x: 1068   top_y:  230   width:  141   height:   69)\n",
            "person: 87%\t(left_x: 1068   top_y:  230   width:  140   height:   69)\n",
            "motorbike: 84%\t(left_x: 1080   top_y:  272   width:   71   height:   71)\n",
            "person: 64%\t(left_x: 1082   top_y:  231   width:   84   height:   90)\n",
            "motorbike: 26%\t(left_x: 1141   top_y:  246   width:  360   height:  196)\n",
            "car: 99%\t(left_x: 1143   top_y:  242   width:  354   height:  184)\n",
            "car: 93%\t(left_x: 1403   top_y:  245   width:   89   height:   45)\n",
            "motorbike: 41%\t(left_x: 1535   top_y:  258   width:   51   height:   46)\n",
            "motorbike: 35%\t(left_x: 1554   top_y:  253   width:   52   height:   49)\n",
            "person: 55%\t(left_x: 1572   top_y:  234   width:   35   height:   64)\n",
            "person: 38%\t(left_x: 1864   top_y:  252   width:   28   height:   56)\n",
            "person: 61%\t(left_x: 1887   top_y:  243   width:   32   height:   65)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/166.jpg: Predicted in 54.892000 milli-seconds.\n",
            "motorbike: 87%\t(left_x:    3   top_y:  563   width:  782   height:  528)\n",
            "car: 97%\t(left_x:    4   top_y:  239   width:  529   height:  345)\n",
            "person: 99%\t(left_x:  183   top_y:  234   width:  549   height:  768)\n",
            "bus: 66%\t(left_x:  427   top_y:  197   width:  250   height:  104)\n",
            "bicycle: 88%\t(left_x:  767   top_y:  293   width:   71   height:   83)\n",
            "person: 65%\t(left_x:  777   top_y:  245   width:   56   height:  115)\n",
            "person: 72%\t(left_x:  796   top_y:  242   width:   58   height:  109)\n",
            "person: 33%\t(left_x:  825   top_y:  231   width:   53   height:  123)\n",
            "motorbike: 63%\t(left_x:  866   top_y:  294   width:   52   height:   46)\n",
            "car: 87%\t(left_x:  880   top_y:  261   width:   97   height:   42)\n",
            "motorbike: 94%\t(left_x:  987   top_y:  332   width:   96   height:  118)\n",
            "person: 89%\t(left_x: 1016   top_y:  251   width:   85   height:  151)\n",
            "motorbike: 77%\t(left_x: 1060   top_y:  406   width:  175   height:  166)\n",
            "person: 26%\t(left_x: 1078   top_y:  292   width:  149   height:  268)\n",
            "person: 87%\t(left_x: 1110   top_y:  245   width:  134   height:  279)\n",
            "car: 89%\t(left_x: 1114   top_y:  243   width:  179   height:   74)\n",
            "car: 99%\t(left_x: 1270   top_y:  257   width:  343   height:  164)\n",
            "person: 33%\t(left_x: 1472   top_y:  241   width:   21   height:   21)\n",
            "person: 30%\t(left_x: 1535   top_y:  248   width:   23   height:   27)\n",
            "person: 76%\t(left_x: 1553   top_y:  248   width:   36   height:   53)\n",
            "car: 53%\t(left_x: 1584   top_y:  260   width:   40   height:   34)\n",
            "person: 51%\t(left_x: 1615   top_y:  248   width:   20   height:   31)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/167.jpg: Predicted in 54.851000 milli-seconds.\n",
            "motorbike: 97%\t(left_x:    7   top_y:  323   width:  272   height:  179)\n",
            "person: 94%\t(left_x:  116   top_y:  255   width:   82   height:  183)\n",
            "motorbike: 99%\t(left_x:  213   top_y:  434   width:  455   height:  337)\n",
            "person: 55%\t(left_x:  326   top_y:  238   width:   49   height:  168)\n",
            "person: 78%\t(left_x:  329   top_y:  225   width:  303   height:  429)\n",
            "bus: 68%\t(left_x:  529   top_y:  189   width:  253   height:  113)\n",
            "bus: 27%\t(left_x:  641   top_y:  191   width:  148   height:  111)\n",
            "motorbike: 94%\t(left_x:  688   top_y:  465   width:  392   height:  460)\n",
            "motorbike: 86%\t(left_x:  737   top_y:  280   width:   75   height:  100)\n",
            "person: 62%\t(left_x:  760   top_y:  235   width:   58   height:  114)\n",
            "person: 97%\t(left_x:  771   top_y:  198   width:  309   height:  565)\n",
            "motorbike: 56%\t(left_x:  906   top_y:  284   width:   46   height:   45)\n",
            "motorbike: 83%\t(left_x:  967   top_y:  290   width:   68   height:   82)\n",
            "person: 84%\t(left_x:  970   top_y:  239   width:   63   height:  119)\n",
            "motorbike: 74%\t(left_x: 1030   top_y:  281   width:   54   height:   70)\n",
            "person: 81%\t(left_x: 1031   top_y:  244   width:   51   height:   96)\n",
            "motorbike: 87%\t(left_x: 1166   top_y:  309   width:  105   height:  102)\n",
            "person: 97%\t(left_x: 1190   top_y:  246   width:   85   height:  140)\n",
            "car: 71%\t(left_x: 1236   top_y:  234   width:  108   height:   70)\n",
            "motorbike: 61%\t(left_x: 1307   top_y:  262   width:   45   height:   59)\n",
            "motorbike: 65%\t(left_x: 1317   top_y:  371   width:  115   height:  125)\n",
            "person: 89%\t(left_x: 1332   top_y:  239   width:  124   height:  218)\n",
            "car: 99%\t(left_x: 1440   top_y:  239   width:  262   height:  154)\n",
            "person: 53%\t(left_x: 1447   top_y:  228   width:   24   height:   47)\n",
            "person: 47%\t(left_x: 1496   top_y:  237   width:   25   height:   23)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/168.jpg: Predicted in 54.973000 milli-seconds.\n",
            "person: 99%\t(left_x:  291   top_y:  130   width:   59   height:  179)\n",
            "person: 96%\t(left_x:  423   top_y:  114   width:   59   height:  153)\n",
            "bus: 87%\t(left_x:  602   top_y:   79   width:  251   height:  123)\n",
            "bicycle: 92%\t(left_x:  648   top_y:  193   width:   89   height:   96)\n",
            "person: 89%\t(left_x:  670   top_y:  136   width:   62   height:  130)\n",
            "motorbike: 61%\t(left_x:  808   top_y:  190   width:   75   height:  110)\n",
            "motorbike: 77%\t(left_x:  813   top_y:  255   width:  210   height:  226)\n",
            "person: 40%\t(left_x:  832   top_y:  129   width:   69   height:  150)\n",
            "person: 93%\t(left_x:  860   top_y:  134   width:  152   height:  278)\n",
            "person: 62%\t(left_x:  954   top_y:  141   width:   49   height:   73)\n",
            "motorbike: 81%\t(left_x:  973   top_y:  361   width:  229   height:  261)\n",
            "person: 97%\t(left_x: 1022   top_y:  112   width:  235   height:  419)\n",
            "car: 97%\t(left_x: 1139   top_y:  149   width:  112   height:   46)\n",
            "car: 71%\t(left_x: 1240   top_y:  134   width:  193   height:   79)\n",
            "person: 85%\t(left_x: 1251   top_y:  143   width:  104   height:  132)\n",
            "motorbike: 92%\t(left_x: 1257   top_y:  198   width:   91   height:   95)\n",
            "motorbike: 39%\t(left_x: 1403   top_y:  160   width:   75   height:   59)\n",
            "motorbike: 74%\t(left_x: 1449   top_y:  194   width:   99   height:  163)\n",
            "person: 30%\t(left_x: 1462   top_y:  155   width:   39   height:   47)\n",
            "person: 87%\t(left_x: 1485   top_y:  145   width:   91   height:  187)\n",
            "car: 78%\t(left_x: 1543   top_y:  151   width:  336   height:  125)\n",
            "car: 47%\t(left_x: 1552   top_y:  158   width:  125   height:  120)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/169.jpg: Predicted in 54.831000 milli-seconds.\n",
            "person: 98%\t(left_x:  259   top_y:  171   width:   55   height:  176)\n",
            "person: 94%\t(left_x:  405   top_y:  168   width:   43   height:  137)\n",
            "bicycle: 52%\t(left_x:  519   top_y:  239   width:   66   height:  100)\n",
            "person: 55%\t(left_x:  551   top_y:  167   width:   64   height:  142)\n",
            "motorbike: 87%\t(left_x:  579   top_y:  240   width:  147   height:  131)\n",
            "person: 81%\t(left_x:  594   top_y:  160   width:  108   height:  177)\n",
            "traffic light: 44%\t(left_x:  595   top_y:   -1   width:   31   height:   45)\n",
            "bus: 93%\t(left_x:  599   top_y:  125   width:  289   height:  111)\n",
            "motorbike: 89%\t(left_x:  797   top_y:  216   width:   96   height:  100)\n",
            "person: 93%\t(left_x:  811   top_y:  176   width:   72   height:  126)\n",
            "motorbike: 31%\t(left_x:  876   top_y:  225   width:   26   height:   48)\n",
            "motorbike: 33%\t(left_x:  990   top_y:  189   width:   76   height:   55)\n",
            "car: 26%\t(left_x:  990   top_y:  189   width:   76   height:   55)\n",
            "person: 31%\t(left_x:  991   top_y:  196   width:   72   height:   54)\n",
            "motorbike: 70%\t(left_x:  993   top_y:  207   width:   70   height:   44)\n",
            "person: 75%\t(left_x: 1000   top_y:  183   width:   57   height:   54)\n",
            "car: 76%\t(left_x: 1034   top_y:  187   width:   69   height:   43)\n",
            "motorbike: 90%\t(left_x: 1046   top_y:  289   width:  112   height:  142)\n",
            "person: 80%\t(left_x: 1081   top_y:  190   width:   88   height:  167)\n",
            "motorbike: 71%\t(left_x: 1118   top_y:  359   width:  162   height:  207)\n",
            "person: 97%\t(left_x: 1155   top_y:  140   width:  184   height:  367)\n",
            "car: 90%\t(left_x: 1261   top_y:  172   width:  183   height:   78)\n",
            "motorbike: 87%\t(left_x: 1300   top_y:  223   width:   97   height:   88)\n",
            "person: 58%\t(left_x: 1315   top_y:  184   width:   82   height:  105)\n",
            "motorbike: 80%\t(left_x: 1440   top_y:  205   width:   99   height:   53)\n",
            "person: 36%\t(left_x: 1442   top_y:  182   width:   27   height:   47)\n",
            "person: 41%\t(left_x: 1449   top_y:  191   width:   88   height:   63)\n",
            "motorbike: 26%\t(left_x: 1551   top_y:  224   width:   68   height:  137)\n",
            "motorbike: 56%\t(left_x: 1551   top_y:  272   width:   63   height:   97)\n",
            "person: 44%\t(left_x: 1565   top_y:  186   width:   63   height:   97)\n",
            "person: 30%\t(left_x: 1574   top_y:  186   width:   45   height:   44)\n",
            "car: 94%\t(left_x: 1774   top_y:  188   width:  150   height:  122)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/170.jpg: Predicted in 54.819000 milli-seconds.\n",
            "person: 78%\t(left_x:   -1   top_y:  193   width:   33   height:  167)\n",
            "skateboard: 39%\t(left_x:   -1   top_y:  350   width:   31   height:   21)\n",
            "person: 88%\t(left_x:  261   top_y:  197   width:   59   height:  159)\n",
            "motorbike: 97%\t(left_x:  271   top_y:  276   width:  223   height:  171)\n",
            "person: 97%\t(left_x:  321   top_y:  191   width:  130   height:  214)\n",
            "person: 67%\t(left_x:  425   top_y:  179   width:   32   height:   85)\n",
            "motorbike: 34%\t(left_x:  439   top_y:  281   width:  102   height:   88)\n",
            "person: 57%\t(left_x:  449   top_y:  200   width:   73   height:  130)\n",
            "motorbike: 42%\t(left_x:  484   top_y:  283   width:   59   height:   83)\n",
            "car: 30%\t(left_x:  585   top_y:  207   width:   60   height:   33)\n",
            "bus: 94%\t(left_x:  670   top_y:  136   width:  317   height:  124)\n",
            "motorbike: 90%\t(left_x:  696   top_y:  241   width:   98   height:  114)\n",
            "person: 94%\t(left_x:  708   top_y:  196   width:   81   height:  135)\n",
            "motorbike: 35%\t(left_x:  851   top_y:  238   width:   54   height:   51)\n",
            "car: 46%\t(left_x:  917   top_y:  208   width:   72   height:   46)\n",
            "motorbike: 72%\t(left_x: 1081   top_y:  233   width:   75   height:   72)\n",
            "person: 67%\t(left_x: 1090   top_y:  204   width:   66   height:   78)\n",
            "motorbike: 26%\t(left_x: 1133   top_y:  219   width:   35   height:   54)\n",
            "motorbike: 83%\t(left_x: 1202   top_y:  289   width:   73   height:  119)\n",
            "person: 69%\t(left_x: 1228   top_y:  194   width:   65   height:  109)\n",
            "motorbike: 93%\t(left_x: 1245   top_y:  350   width:  121   height:  173)\n",
            "person: 97%\t(left_x: 1262   top_y:  175   width:  154   height:  309)\n",
            "car: 51%\t(left_x: 1346   top_y:  188   width:  170   height:   74)\n",
            "person: 34%\t(left_x: 1370   top_y:  198   width:  116   height:   84)\n",
            "car: 69%\t(left_x: 1373   top_y:  198   width:  111   height:   83)\n",
            "motorbike: 62%\t(left_x: 1388   top_y:  252   width:   70   height:   70)\n",
            "person: 72%\t(left_x: 1398   top_y:  200   width:   68   height:  103)\n",
            "car: 54%\t(left_x: 1478   top_y:  215   width:   46   height:   39)\n",
            "motorbike: 75%\t(left_x: 1549   top_y:  214   width:   84   height:   67)\n",
            "person: 43%\t(left_x: 1552   top_y:  199   width:   70   height:   71)\n",
            "car: 78%\t(left_x: 1785   top_y:  201   width:  135   height:  127)\n",
            "car: 45%\t(left_x: 1857   top_y:  201   width:   63   height:  128)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/171.jpg: Predicted in 54.786000 milli-seconds.\n",
            "motorbike: 88%\t(left_x:   -3   top_y:  430   width:  538   height:  581)\n",
            "person: 41%\t(left_x:   -2   top_y:  167   width:  392   height:  644)\n",
            "bicycle: 93%\t(left_x:  264   top_y:  272   width:  174   height:  125)\n",
            "person: 76%\t(left_x:  282   top_y:  198   width:   58   height:  135)\n",
            "person: 33%\t(left_x:  323   top_y:  197   width:   46   height:   74)\n",
            "person: 96%\t(left_x:  335   top_y:  202   width:   71   height:  157)\n",
            "person: 92%\t(left_x:  422   top_y:  181   width:   54   height:  147)\n",
            "motorbike: 93%\t(left_x:  555   top_y:  256   width:  134   height:  129)\n",
            "person: 97%\t(left_x:  588   top_y:  189   width:   88   height:  157)\n",
            "bus: 81%\t(left_x:  790   top_y:  139   width:  290   height:  124)\n",
            "motorbike: 69%\t(left_x: 1015   top_y:  252   width:   70   height:   72)\n",
            "person: 72%\t(left_x: 1018   top_y:  204   width:   73   height:   97)\n",
            "person: 75%\t(left_x: 1226   top_y:  204   width:   41   height:   59)\n",
            "motorbike: 49%\t(left_x: 1233   top_y:  223   width:   72   height:   57)\n",
            "person: 40%\t(left_x: 1268   top_y:  204   width:   36   height:   59)\n",
            "person: 46%\t(left_x: 1272   top_y:  204   width:   28   height:   33)\n",
            "motorbike: 40%\t(left_x: 1322   top_y:  283   width:   50   height:  105)\n",
            "person: 43%\t(left_x: 1331   top_y:  195   width:   63   height:   89)\n",
            "motorbike: 77%\t(left_x: 1336   top_y:  328   width:  109   height:  155)\n",
            "person: 91%\t(left_x: 1352   top_y:  193   width:  134   height:  253)\n",
            "car: 76%\t(left_x: 1429   top_y:  191   width:  156   height:   87)\n",
            "motorbike: 59%\t(left_x: 1454   top_y:  255   width:   60   height:   69)\n",
            "motorbike: 50%\t(left_x: 1463   top_y:  221   width:   62   height:   98)\n",
            "person: 66%\t(left_x: 1466   top_y:  215   width:   61   height:  100)\n",
            "car: 33%\t(left_x: 1612   top_y:  205   width:   48   height:   61)\n",
            "person: 53%\t(left_x: 1882   top_y:  220   width:   40   height:  137)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/172.jpg: Predicted in 54.776000 milli-seconds.\n",
            "person: 95%\t(left_x:   68   top_y:  190   width:   57   height:  158)\n",
            "bicycle: 97%\t(left_x:   99   top_y:  283   width:  197   height:  145)\n",
            "person: 71%\t(left_x:  128   top_y:  174   width:   61   height:  180)\n",
            "person: 94%\t(left_x:  181   top_y:  201   width:   85   height:  192)\n",
            "person: 96%\t(left_x:  284   top_y:  205   width:   60   height:  177)\n",
            "motorbike: 97%\t(left_x:  336   top_y:  276   width:  190   height:  154)\n",
            "person: 95%\t(left_x:  381   top_y:  204   width:   96   height:  186)\n",
            "person: 57%\t(left_x:  445   top_y:  199   width:   57   height:  186)\n",
            "car: 36%\t(left_x:  607   top_y:  200   width:   74   height:   65)\n",
            "car: 27%\t(left_x:  638   top_y:  209   width:   64   height:   58)\n",
            "car: 94%\t(left_x:  712   top_y:  217   width:  109   height:   41)\n",
            "motorbike: 96%\t(left_x:  768   top_y:  313   width:  293   height:  331)\n",
            "car: 38%\t(left_x:  794   top_y:  215   width:   54   height:   39)\n",
            "bus: 85%\t(left_x:  800   top_y:  145   width:  351   height:  133)\n",
            "person: 93%\t(left_x:  816   top_y:  160   width:  232   height:  405)\n",
            "bus: 55%\t(left_x:  943   top_y:  140   width:  203   height:  142)\n",
            "person: 37%\t(left_x:  965   top_y:  208   width:   48   height:  106)\n",
            "motorbike: 48%\t(left_x: 1260   top_y:  215   width:   47   height:   62)\n",
            "person: 51%\t(left_x: 1260   top_y:  209   width:   48   height:   60)\n",
            "motorbike: 26%\t(left_x: 1279   top_y:  237   width:   27   height:   42)\n",
            "motorbike: 50%\t(left_x: 1324   top_y:  226   width:   36   height:   51)\n",
            "person: 25%\t(left_x: 1338   top_y:  200   width:   28   height:   36)\n",
            "motorbike: 46%\t(left_x: 1352   top_y:  240   width:   50   height:   46)\n",
            "person: 53%\t(left_x: 1360   top_y:  206   width:   39   height:   64)\n",
            "motorbike: 85%\t(left_x: 1403   top_y:  316   width:  104   height:  140)\n",
            "person: 66%\t(left_x: 1408   top_y:  206   width:   56   height:   83)\n",
            "person: 95%\t(left_x: 1424   top_y:  213   width:  116   height:  195)\n",
            "car: 72%\t(left_x: 1428   top_y:  202   width:  229   height:   84)\n",
            "person: 36%\t(left_x: 1463   top_y:  194   width:   39   height:   45)\n",
            "car: 39%\t(left_x: 1498   top_y:  202   width:  101   height:   93)\n",
            "person: 74%\t(left_x: 1508   top_y:  217   width:   60   height:  101)\n",
            "motorbike: 40%\t(left_x: 1512   top_y:  260   width:   51   height:   64)\n",
            "person: 28%\t(left_x: 1611   top_y:  208   width:   26   height:   22)\n",
            "person: 27%\t(left_x: 1807   top_y:  209   width:   36   height:   74)\n",
            "car: 56%\t(left_x: 1881   top_y:  208   width:   40   height:   62)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/173.jpg: Predicted in 54.839000 milli-seconds.\n",
            "motorbike: 98%\t(left_x:   -8   top_y:  281   width:  297   height:  203)\n",
            "person: 64%\t(left_x:   -1   top_y:  197   width:   85   height:  148)\n",
            "motorbike: 95%\t(left_x:   33   top_y:  533   width:  666   height:  384)\n",
            "person: 53%\t(left_x:   91   top_y:  197   width:   85   height:  224)\n",
            "person: 76%\t(left_x:  128   top_y:  191   width:   94   height:  228)\n",
            "person: 87%\t(left_x:  193   top_y:  188   width:   59   height:  145)\n",
            "person: 50%\t(left_x:  289   top_y:  206   width:  350   height:  548)\n",
            "person: 81%\t(left_x:  295   top_y:  206   width:   52   height:  116)\n",
            "person: 82%\t(left_x:  452   top_y:  194   width:   45   height:  148)\n",
            "car: 87%\t(left_x:  622   top_y:  215   width:  140   height:   43)\n",
            "car: 64%\t(left_x:  761   top_y:  221   width:   80   height:   38)\n",
            "motorbike: 73%\t(left_x:  805   top_y:  267   width:  100   height:   99)\n",
            "person: 58%\t(left_x:  810   top_y:  215   width:   80   height:  121)\n",
            "person: 70%\t(left_x:  856   top_y:  216   width:   57   height:  112)\n",
            "bus: 99%\t(left_x:  886   top_y:  140   width:  319   height:  143)\n",
            "motorbike: 95%\t(left_x: 1103   top_y:  314   width:  175   height:  201)\n",
            "person: 96%\t(left_x: 1149   top_y:  188   width:  140   height:  269)\n",
            "person: 54%\t(left_x: 1254   top_y:  214   width:   24   height:   45)\n",
            "person: 64%\t(left_x: 1284   top_y:  207   width:   30   height:   62)\n",
            "bicycle: 65%\t(left_x: 1288   top_y:  237   width:   27   height:   43)\n",
            "motorbike: 56%\t(left_x: 1288   top_y:  237   width:   27   height:   43)\n",
            "bicycle: 80%\t(left_x: 1337   top_y:  241   width:   32   height:   38)\n",
            "motorbike: 39%\t(left_x: 1337   top_y:  241   width:   32   height:   38)\n",
            "person: 52%\t(left_x: 1337   top_y:  224   width:   33   height:   56)\n",
            "person: 63%\t(left_x: 1342   top_y:  198   width:   33   height:   77)\n",
            "person: 53%\t(left_x: 1455   top_y:  207   width:   65   height:  136)\n",
            "person: 44%\t(left_x: 1460   top_y:  207   width:   56   height:   85)\n",
            "motorbike: 80%\t(left_x: 1476   top_y:  313   width:   86   height:  119)\n",
            "person: 98%\t(left_x: 1481   top_y:  200   width:  116   height:  203)\n",
            "car: 53%\t(left_x: 1549   top_y:  203   width:   92   height:   84)\n",
            "person: 27%\t(left_x: 1549   top_y:  203   width:   92   height:   84)\n",
            "person: 61%\t(left_x: 1555   top_y:  209   width:   49   height:   78)\n",
            "car: 55%\t(left_x: 1834   top_y:  209   width:   87   height:   61)\n",
            "car: 43%\t(left_x: 1893   top_y:  205   width:   27   height:   66)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/174.jpg: Predicted in 54.803000 milli-seconds.\n",
            "person: 55%\t(left_x:   -2   top_y:  222   width:   36   height:  142)\n",
            "person: 99%\t(left_x:  204   top_y:  187   width:   52   height:  152)\n",
            "person: 98%\t(left_x:  240   top_y:  175   width:   74   height:  170)\n",
            "person: 98%\t(left_x:  312   top_y:  199   width:   54   height:  175)\n",
            "person: 99%\t(left_x:  457   top_y:  187   width:   57   height:  152)\n",
            "car: 53%\t(left_x:  627   top_y:  212   width:   49   height:   45)\n",
            "motorbike: 93%\t(left_x:  650   top_y:  259   width:  137   height:  129)\n",
            "person: 86%\t(left_x:  691   top_y:  206   width:   77   height:  144)\n",
            "motorbike: 29%\t(left_x:  803   top_y:  221   width:   49   height:   52)\n",
            "car: 35%\t(left_x:  811   top_y:  216   width:   52   height:   42)\n",
            "motorbike: 97%\t(left_x:  894   top_y:  360   width:  246   height:  261)\n",
            "motorbike: 35%\t(left_x:  895   top_y:  249   width:   49   height:   49)\n",
            "bus: 98%\t(left_x:  926   top_y:  136   width:  353   height:  146)\n",
            "person: 98%\t(left_x:  959   top_y:  193   width:  167   height:  354)\n",
            "motorbike: 91%\t(left_x: 1290   top_y:  297   width:  123   height:  139)\n",
            "person: 30%\t(left_x: 1298   top_y:  225   width:   27   height:   52)\n",
            "motorbike: 28%\t(left_x: 1298   top_y:  225   width:   27   height:   52)\n",
            "person: 93%\t(left_x: 1317   top_y:  189   width:  116   height:  203)\n",
            "motorbike: 83%\t(left_x: 1456   top_y:  227   width:   35   height:   46)\n",
            "person: 76%\t(left_x: 1484   top_y:  205   width:   38   height:   64)\n",
            "motorbike: 62%\t(left_x: 1504   top_y:  277   width:   49   height:   81)\n",
            "person: 68%\t(left_x: 1507   top_y:  206   width:   60   height:  138)\n",
            "motorbike: 82%\t(left_x: 1531   top_y:  303   width:   87   height:  112)\n",
            "person: 99%\t(left_x: 1541   top_y:  197   width:  102   height:  191)\n",
            "car: 86%\t(left_x: 1619   top_y:  202   width:   80   height:   70)\n",
            "car: 36%\t(left_x: 1835   top_y:  232   width:   38   height:   54)\n",
            "car: 32%\t(left_x: 1836   top_y:  217   width:   84   height:   65)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/175.jpg: Predicted in 54.879000 milli-seconds.\n",
            "motorbike: 67%\t(left_x:   16   top_y:  459   width:  658   height:  617)\n",
            "person: 81%\t(left_x:   83   top_y:  220   width:  581   height:  627)\n",
            "person: 97%\t(left_x:  116   top_y:  184   width:   67   height:  156)\n",
            "person: 59%\t(left_x:  293   top_y:  182   width:   37   height:   38)\n",
            "person: 57%\t(left_x:  339   top_y:  190   width:   53   height:   64)\n",
            "motorbike: 80%\t(left_x:  439   top_y:  262   width:  196   height:  144)\n",
            "person: 55%\t(left_x:  485   top_y:  177   width:   51   height:   85)\n",
            "person: 45%\t(left_x:  503   top_y:  196   width:   67   height:  164)\n",
            "person: 41%\t(left_x:  513   top_y:  200   width:   55   height:   70)\n",
            "person: 86%\t(left_x:  554   top_y:  193   width:   69   height:  173)\n",
            "car: 44%\t(left_x:  666   top_y:  205   width:   64   height:   50)\n",
            "car: 80%\t(left_x:  805   top_y:  210   width:   83   height:   37)\n",
            "bus: 99%\t(left_x:  978   top_y:  125   width:  422   height:  148)\n",
            "motorbike: 92%\t(left_x: 1220   top_y:  326   width:  143   height:  175)\n",
            "person: 99%\t(left_x: 1257   top_y:  193   width:  133   height:  256)\n",
            "motorbike: 80%\t(left_x: 1378   top_y:  223   width:   35   height:   48)\n",
            "person: 30%\t(left_x: 1379   top_y:  209   width:   34   height:   56)\n",
            "motorbike: 95%\t(left_x: 1424   top_y:  268   width:  119   height:  139)\n",
            "person: 97%\t(left_x: 1448   top_y:  189   width:  101   height:  159)\n",
            "person: 31%\t(left_x: 1555   top_y:  200   width:   43   height:   63)\n",
            "person: 43%\t(left_x: 1561   top_y:  196   width:   39   height:   45)\n",
            "motorbike: 79%\t(left_x: 1571   top_y:  258   width:   57   height:   91)\n",
            "person: 76%\t(left_x: 1577   top_y:  199   width:   60   height:   91)\n",
            "motorbike: 84%\t(left_x: 1607   top_y:  286   width:   92   height:  104)\n",
            "person: 95%\t(left_x: 1622   top_y:  199   width:   97   height:  159)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/176.jpg: Predicted in 54.817000 milli-seconds.\n",
            "motorbike: 98%\t(left_x:  108   top_y:  263   width:  282   height:  208)\n",
            "person: 48%\t(left_x:  216   top_y:  188   width:   86   height:  220)\n",
            "person: 86%\t(left_x:  274   top_y:  190   width:  107   height:  222)\n",
            "car: 30%\t(left_x:  338   top_y:  183   width:   43   height:   21)\n",
            "person: 97%\t(left_x:  391   top_y:  175   width:   68   height:  183)\n",
            "person: 96%\t(left_x:  432   top_y:  165   width:   63   height:  149)\n",
            "person: 98%\t(left_x:  540   top_y:  173   width:   50   height:  151)\n",
            "car: 98%\t(left_x:  749   top_y:  196   width:  101   height:   53)\n",
            "motorbike: 88%\t(left_x:  829   top_y:  407   width:  309   height:  293)\n",
            "car: 91%\t(left_x:  871   top_y:  202   width:   64   height:   36)\n",
            "person: 85%\t(left_x:  926   top_y:  211   width:  211   height:  353)\n",
            "bus: 99%\t(left_x: 1093   top_y:  109   width:  420   height:  158)\n",
            "person: 38%\t(left_x: 1107   top_y:  105   width:  420   height:  168)\n",
            "motorbike: 76%\t(left_x: 1455   top_y:  306   width:  112   height:  135)\n",
            "person: 99%\t(left_x: 1499   top_y:  190   width:   90   height:  213)\n",
            "motorbike: 52%\t(left_x: 1577   top_y:  245   width:   86   height:  125)\n",
            "person: 75%\t(left_x: 1578   top_y:  173   width:   88   height:  186)\n",
            "person: 51%\t(left_x: 1645   top_y:  184   width:   36   height:   44)\n",
            "person: 26%\t(left_x: 1647   top_y:  183   width:   30   height:   28)\n",
            "motorbike: 75%\t(left_x: 1660   top_y:  252   width:   57   height:   88)\n",
            "person: 79%\t(left_x: 1668   top_y:  190   width:   67   height:  103)\n",
            "motorbike: 79%\t(left_x: 1707   top_y:  275   width:   66   height:   98)\n",
            "person: 35%\t(left_x: 1720   top_y:  186   width:   71   height:  174)\n",
            "person: 46%\t(left_x: 1726   top_y:  185   width:   67   height:  105)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/177.jpg: Predicted in 54.836000 milli-seconds.\n",
            "pottedplant: 26%\t(left_x:  296   top_y:  190   width:  106   height:  107)\n",
            "person: 28%\t(left_x:  387   top_y:  173   width:   41   height:   99)\n",
            "person: 94%\t(left_x:  433   top_y:  181   width:   58   height:  172)\n",
            "person: 94%\t(left_x:  476   top_y:  177   width:   46   height:  127)\n",
            "person: 99%\t(left_x:  510   top_y:  161   width:   53   height:  153)\n",
            "person: 95%\t(left_x:  577   top_y:  174   width:   52   height:  144)\n",
            "bench: 29%\t(left_x:  614   top_y:  231   width:  141   height:   81)\n",
            "car: 57%\t(left_x:  853   top_y:  196   width:   81   height:   49)\n",
            "car: 77%\t(left_x:  908   top_y:  198   width:   65   height:   41)\n",
            "motorbike: 76%\t(left_x: 1122   top_y:  204   width:   65   height:   62)\n",
            "bus: 99%\t(left_x: 1196   top_y:  100   width:  450   height:  167)\n",
            "motorbike: 87%\t(left_x: 1199   top_y:  358   width:  186   height:  203)\n",
            "person: 95%\t(left_x: 1258   top_y:  203   width:  164   height:  295)\n",
            "car: 53%\t(left_x: 1563   top_y:  192   width:   73   height:   65)\n",
            "person: 61%\t(left_x: 1631   top_y:  183   width:   34   height:   73)\n",
            "motorbike: 27%\t(left_x: 1637   top_y:  252   width:   77   height:  113)\n",
            "motorbike: 74%\t(left_x: 1643   top_y:  262   width:  165   height:  142)\n",
            "person: 28%\t(left_x: 1657   top_y:  171   width:   88   height:  187)\n",
            "person: 54%\t(left_x: 1663   top_y:  173   width:   81   height:   95)\n",
            "person: 96%\t(left_x: 1709   top_y:  191   width:   94   height:  177)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/178.jpg: Predicted in 54.885000 milli-seconds.\n",
            "pottedplant: 42%\t(left_x:  310   top_y:  187   width:  128   height:  112)\n",
            "person: 97%\t(left_x:  451   top_y:  181   width:   57   height:  169)\n",
            "person: 77%\t(left_x:  477   top_y:  144   width:   32   height:   45)\n",
            "person: 96%\t(left_x:  531   top_y:  174   width:   37   height:  128)\n",
            "person: 95%\t(left_x:  557   top_y:  163   width:   43   height:  143)\n",
            "person: 99%\t(left_x:  596   top_y:  170   width:   46   height:  150)\n",
            "car: 60%\t(left_x:  899   top_y:  197   width:   82   height:   45)\n",
            "bicycle: 40%\t(left_x:  940   top_y:  213   width:  121   height:   68)\n",
            "bicycle: 42%\t(left_x: 1022   top_y:  226   width:   51   height:   54)\n",
            "motorbike: 92%\t(left_x: 1230   top_y:  193   width:   90   height:   82)\n",
            "person: 53%\t(left_x: 1238   top_y:  181   width:   76   height:   87)\n",
            "bus: 99%\t(left_x: 1286   top_y:   99   width:  471   height:  173)\n",
            "person: 48%\t(left_x: 1416   top_y:  165   width:   25   height:   22)\n",
            "motorbike: 93%\t(left_x: 1425   top_y:  325   width:  129   height:  156)\n",
            "person: 99%\t(left_x: 1461   top_y:  198   width:  135   height:  235)\n",
            "motorbike: 96%\t(left_x: 1699   top_y:  245   width:  116   height:  114)\n",
            "person: 96%\t(left_x: 1726   top_y:  173   width:  100   height:  149)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/179.jpg: Predicted in 54.847000 milli-seconds.\n",
            "person: 99%\t(left_x:  469   top_y:  183   width:   52   height:  168)\n",
            "car: 59%\t(left_x:  512   top_y:  184   width:   57   height:   17)\n",
            "person: 43%\t(left_x:  569   top_y:  153   width:   34   height:   47)\n",
            "person: 92%\t(left_x:  574   top_y:  176   width:   38   height:  133)\n",
            "person: 95%\t(left_x:  600   top_y:  167   width:   55   height:  151)\n",
            "bench: 36%\t(left_x:  644   top_y:  243   width:   96   height:   70)\n",
            "bench: 43%\t(left_x:  661   top_y:  236   width:  158   height:   68)\n",
            "person: 62%\t(left_x:  796   top_y:  186   width:   27   height:   62)\n",
            "car: 48%\t(left_x:  931   top_y:  199   width:   69   height:   38)\n",
            "car: 25%\t(left_x:  935   top_y:  192   width:  116   height:   51)\n",
            "person: 29%\t(left_x: 1236   top_y:  194   width:   32   height:   61)\n",
            "motorbike: 36%\t(left_x: 1301   top_y:  214   width:   32   height:   36)\n",
            "person: 86%\t(left_x: 1302   top_y:  187   width:   33   height:   64)\n",
            "bus: 99%\t(left_x: 1362   top_y:   92   width:  541   height:  184)\n",
            "motorbike: 91%\t(left_x: 1369   top_y:  198   width:   82   height:   78)\n",
            "person: 34%\t(left_x: 1372   top_y:  184   width:   75   height:   77)\n",
            "motorbike: 88%\t(left_x: 1580   top_y:  298   width:  127   height:  137)\n",
            "person: 43%\t(left_x: 1614   top_y:  168   width:   31   height:   22)\n",
            "person: 98%\t(left_x: 1620   top_y:  197   width:  111   height:  201)\n",
            "motorbike: 69%\t(left_x: 1756   top_y:  236   width:   90   height:  112)\n",
            "person: 59%\t(left_x: 1788   top_y:  176   width:   76   height:  132)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/180.jpg: Predicted in 54.953000 milli-seconds.\n",
            "motorbike: 79%\t(left_x:  -11   top_y:  427   width:  737   height:  455)\n",
            "backpack: 42%\t(left_x:  148   top_y:  307   width:  170   height:  192)\n",
            "person: 68%\t(left_x:  173   top_y:  197   width:  507   height:  543)\n",
            "pottedplant: 46%\t(left_x:  373   top_y:  191   width:   92   height:  144)\n",
            "person: 93%\t(left_x:  468   top_y:  187   width:   64   height:  156)\n",
            "car: 44%\t(left_x:  558   top_y:  182   width:   53   height:   19)\n",
            "person: 98%\t(left_x:  615   top_y:  170   width:   58   height:  149)\n",
            "person: 62%\t(left_x:  651   top_y:  167   width:   45   height:  144)\n",
            "bench: 34%\t(left_x:  662   top_y:  236   width:  171   height:   71)\n",
            "person: 47%\t(left_x:  820   top_y:  187   width:   23   height:   60)\n",
            "car: 77%\t(left_x:  948   top_y:  198   width:   43   height:   37)\n",
            "motorbike: 39%\t(left_x: 1042   top_y:  220   width:   54   height:   56)\n",
            "car: 74%\t(left_x: 1082   top_y:  195   width:   68   height:   47)\n",
            "person: 62%\t(left_x: 1294   top_y:  188   width:   34   height:   63)\n",
            "motorbike: 49%\t(left_x: 1294   top_y:  189   width:   34   height:   62)\n",
            "motorbike: 72%\t(left_x: 1373   top_y:  197   width:   49   height:   43)\n",
            "person: 49%\t(left_x: 1383   top_y:  190   width:   27   height:   36)\n",
            "person: 33%\t(left_x: 1452   top_y:  191   width:   22   height:   64)\n",
            "bus: 97%\t(left_x: 1461   top_y:   73   width:  459   height:  182)\n",
            "motorbike: 72%\t(left_x: 1543   top_y:  196   width:  100   height:   76)\n",
            "person: 48%\t(left_x: 1551   top_y:  179   width:   80   height:   86)\n",
            "person: 35%\t(left_x: 1662   top_y:  151   width:   29   height:   28)\n",
            "motorbike: 83%\t(left_x: 1719   top_y:  278   width:  124   height:  117)\n",
            "person: 90%\t(left_x: 1762   top_y:  196   width:   95   height:  158)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/181.jpg: Predicted in 54.895000 milli-seconds.\n",
            "pottedplant: 33%\t(left_x:  354   top_y:  199   width:  129   height:  105)\n",
            "person: 99%\t(left_x:  497   top_y:  190   width:   50   height:  172)\n",
            "person: 73%\t(left_x:  639   top_y:  178   width:   45   height:  151)\n",
            "person: 91%\t(left_x:  676   top_y:  176   width:   52   height:  142)\n",
            "car: 56%\t(left_x:  798   top_y:  200   width:   52   height:   46)\n",
            "person: 78%\t(left_x:  846   top_y:  193   width:   31   height:   72)\n",
            "car: 40%\t(left_x:  952   top_y:  205   width:   47   height:   35)\n",
            "person: 33%\t(left_x:  983   top_y:  197   width:   34   height:   43)\n",
            "motorbike: 95%\t(left_x: 1043   top_y:  316   width:  223   height:  237)\n",
            "person: 99%\t(left_x: 1074   top_y:  172   width:  204   height:  295)\n",
            "backpack: 59%\t(left_x: 1075   top_y:  234   width:   98   height:  115)\n",
            "motorbike: 63%\t(left_x: 1290   top_y:  207   width:   36   height:   53)\n",
            "person: 61%\t(left_x: 1292   top_y:  191   width:   35   height:   65)\n",
            "person: 26%\t(left_x: 1297   top_y:  191   width:   28   height:   35)\n",
            "motorbike: 29%\t(left_x: 1308   top_y:  214   width:   46   height:   41)\n",
            "motorbike: 40%\t(left_x: 1463   top_y:  203   width:   35   height:   59)\n",
            "person: 78%\t(left_x: 1463   top_y:  190   width:   37   height:   68)\n",
            "motorbike: 81%\t(left_x: 1492   top_y:  207   width:   39   height:   56)\n",
            "person: 32%\t(left_x: 1492   top_y:  191   width:   41   height:   67)\n",
            "motorbike: 34%\t(left_x: 1578   top_y:  206   width:   38   height:   58)\n",
            "bus: 99%\t(left_x: 1587   top_y:   91   width:  340   height:  184)\n",
            "motorbike: 37%\t(left_x: 1740   top_y:  233   width:   96   height:   52)\n",
            "person: 70%\t(left_x: 1787   top_y:  188   width:   42   height:   65)\n",
            "person: 28%\t(left_x: 1819   top_y:  194   width:   62   height:  100)\n",
            "motorbike: 28%\t(left_x: 1823   top_y:  224   width:   64   height:   85)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/182.jpg: Predicted in 54.749000 milli-seconds.\n",
            "person: 96%\t(left_x:  515   top_y:  191   width:   53   height:  166)\n",
            "person: 62%\t(left_x:  548   top_y:  475   width:  410   height:  587)\n",
            "person: 97%\t(left_x:  656   top_y:  179   width:   48   height:  146)\n",
            "person: 91%\t(left_x:  709   top_y:  184   width:   42   height:  125)\n",
            "person: 89%\t(left_x:  744   top_y:  179   width:   43   height:  128)\n",
            "person: 59%\t(left_x:  855   top_y:  195   width:   53   height:   82)\n",
            "car: 27%\t(left_x:  859   top_y:  195   width:   61   height:   73)\n",
            "car: 33%\t(left_x:  924   top_y:  203   width:   88   height:   41)\n",
            "car: 32%\t(left_x:  992   top_y:  201   width:   54   height:   39)\n",
            "motorbike: 39%\t(left_x: 1075   top_y:  235   width:   57   height:   48)\n",
            "car: 70%\t(left_x: 1154   top_y:  196   width:   99   height:   56)\n",
            "motorbike: 46%\t(left_x: 1225   top_y:  217   width:   53   height:   61)\n",
            "motorbike: 53%\t(left_x: 1292   top_y:  206   width:   39   height:   61)\n",
            "person: 32%\t(left_x: 1301   top_y:  197   width:   30   height:   47)\n",
            "motorbike: 93%\t(left_x: 1395   top_y:  287   width:  123   height:  156)\n",
            "person: 97%\t(left_x: 1415   top_y:  178   width:  128   height:  200)\n",
            "motorbike: 45%\t(left_x: 1500   top_y:  213   width:   39   height:   46)\n",
            "motorbike: 64%\t(left_x: 1587   top_y:  222   width:   45   height:   45)\n",
            "person: 85%\t(left_x: 1618   top_y:  189   width:   37   height:   69)\n",
            "motorbike: 83%\t(left_x: 1671   top_y:  213   width:   34   height:   41)\n",
            "person: 44%\t(left_x: 1695   top_y:  194   width:   26   height:   52)\n",
            "person: 30%\t(left_x: 1695   top_y:  189   width:   25   height:   35)\n",
            "bus: 97%\t(left_x: 1757   top_y:   96   width:  162   height:  172)\n",
            "motorbike: 83%\t(left_x: 1847   top_y:  228   width:   70   height:   70)\n",
            "person: 71%\t(left_x: 1851   top_y:  193   width:   67   height:   95)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/183.jpg: Predicted in 54.901000 milli-seconds.\n",
            "person: 99%\t(left_x:  520   top_y:  192   width:   48   height:  168)\n",
            "person: 98%\t(left_x:  655   top_y:  177   width:   49   height:  151)\n",
            "person: 91%\t(left_x:  742   top_y:  187   width:   39   height:  121)\n",
            "person: 88%\t(left_x:  875   top_y:  192   width:   31   height:   75)\n",
            "car: 90%\t(left_x:  926   top_y:  204   width:   96   height:   52)\n",
            "car: 72%\t(left_x:  999   top_y:  203   width:   50   height:   37)\n",
            "motorbike: 33%\t(left_x: 1083   top_y:  237   width:   48   height:   47)\n",
            "motorbike: 75%\t(left_x: 1175   top_y:  465   width:  244   height:  302)\n",
            "motorbike: 52%\t(left_x: 1187   top_y:  211   width:   45   height:   78)\n",
            "car: 31%\t(left_x: 1214   top_y:  197   width:   72   height:   53)\n",
            "person: 68%\t(left_x: 1215   top_y:  216   width:  254   height:  395)\n",
            "motorbike: 27%\t(left_x: 1461   top_y:  194   width:   53   height:   78)\n",
            "person: 63%\t(left_x: 1462   top_y:  188   width:   50   height:   74)\n",
            "motorbike: 87%\t(left_x: 1464   top_y:  221   width:   45   height:   52)\n",
            "motorbike: 94%\t(left_x: 1561   top_y:  259   width:   91   height:  123)\n",
            "person: 26%\t(left_x: 1566   top_y:  173   width:   31   height:   65)\n",
            "person: 98%\t(left_x: 1577   top_y:  183   width:   96   height:  157)\n",
            "motorbike: 40%\t(left_x: 1756   top_y:  208   width:   51   height:   47)\n",
            "car: 92%\t(left_x: 1764   top_y:  190   width:  157   height:   67)\n",
            "motorbike: 83%\t(left_x: 1852   top_y:  233   width:   65   height:   63)\n",
            "person: 62%\t(left_x: 1854   top_y:  199   width:   66   height:   88)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/184.jpg: Predicted in 54.940000 milli-seconds.\n",
            "person: 99%\t(left_x:  519   top_y:  192   width:   50   height:  167)\n",
            "person: 96%\t(left_x:  656   top_y:  178   width:   46   height:  148)\n",
            "person: 30%\t(left_x:  770   top_y:  190   width:   37   height:  113)\n",
            "person: 29%\t(left_x:  808   top_y:  183   width:   33   height:  125)\n",
            "person: 79%\t(left_x:  881   top_y:  189   width:   29   height:   81)\n",
            "person: 65%\t(left_x:  934   top_y:  195   width:   38   height:   88)\n",
            "car: 86%\t(left_x:  962   top_y:  202   width:   82   height:   49)\n",
            "motorbike: 77%\t(left_x: 1114   top_y:  230   width:   69   height:   69)\n",
            "person: 55%\t(left_x: 1130   top_y:  202   width:   51   height:   92)\n",
            "motorbike: 86%\t(left_x: 1246   top_y:  223   width:   49   height:   53)\n",
            "person: 45%\t(left_x: 1248   top_y:  203   width:   50   height:   63)\n",
            "person: 32%\t(left_x: 1265   top_y:  197   width:   34   height:   48)\n",
            "person: 57%\t(left_x: 1270   top_y:  192   width:   67   height:   59)\n",
            "car: 27%\t(left_x: 1270   top_y:  192   width:   66   height:   59)\n",
            "car: 39%\t(left_x: 1288   top_y:  196   width:   85   height:   54)\n",
            "motorbike: 41%\t(left_x: 1298   top_y:  213   width:   51   height:   43)\n",
            "person: 52%\t(left_x: 1437   top_y:  203   width:   45   height:   70)\n",
            "motorbike: 91%\t(left_x: 1438   top_y:  217   width:   44   height:   60)\n",
            "motorbike: 94%\t(left_x: 1445   top_y:  350   width:  157   height:  199)\n",
            "person: 98%\t(left_x: 1491   top_y:  178   width:  157   height:  278)\n",
            "motorbike: 93%\t(left_x: 1616   top_y:  211   width:   34   height:   46)\n",
            "person: 67%\t(left_x: 1619   top_y:  186   width:   36   height:   67)\n",
            "motorbike: 95%\t(left_x: 1666   top_y:  242   width:   80   height:  107)\n",
            "person: 96%\t(left_x: 1684   top_y:  179   width:   76   height:  129)\n",
            "car: 96%\t(left_x: 1746   top_y:  186   width:  163   height:   68)\n",
            "motorbike: 58%\t(left_x: 1863   top_y:  234   width:   56   height:   58)\n",
            "person: 52%\t(left_x: 1873   top_y:  194   width:   48   height:   94)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/185.jpg: Predicted in 54.894000 milli-seconds.\n",
            "person: 98%\t(left_x:  524   top_y:  188   width:   51   height:  163)\n",
            "person: 97%\t(left_x:  662   top_y:  173   width:   50   height:  151)\n",
            "person: 44%\t(left_x:  829   top_y:  182   width:   44   height:  108)\n",
            "person: 70%\t(left_x:  885   top_y:  183   width:   32   height:   82)\n",
            "person: 79%\t(left_x:  953   top_y:  187   width:   32   height:   89)\n",
            "person: 26%\t(left_x:  982   top_y:  193   width:   24   height:   58)\n",
            "car: 66%\t(left_x: 1004   top_y:  198   width:   50   height:   49)\n",
            "car: 43%\t(left_x: 1004   top_y:  194   width:   99   height:   55)\n",
            "motorbike: 78%\t(left_x: 1043   top_y:  224   width:   65   height:   89)\n",
            "person: 28%\t(left_x: 1046   top_y:  202   width:   75   height:   82)\n",
            "person: 49%\t(left_x: 1046   top_y:  220   width:   53   height:   94)\n",
            "motorbike: 41%\t(left_x: 1098   top_y:  224   width:   40   height:   53)\n",
            "motorbike: 90%\t(left_x: 1232   top_y:  224   width:   44   height:   54)\n",
            "person: 34%\t(left_x: 1235   top_y:  200   width:   41   height:   71)\n",
            "person: 44%\t(left_x: 1242   top_y:  197   width:   33   height:   45)\n",
            "car: 80%\t(left_x: 1280   top_y:  191   width:  107   height:   59)\n",
            "person: 59%\t(left_x: 1318   top_y:  186   width:   67   height:   65)\n",
            "motorbike: 27%\t(left_x: 1350   top_y:  209   width:   50   height:   44)\n",
            "motorbike: 75%\t(left_x: 1395   top_y:  214   width:   46   height:   66)\n",
            "person: 56%\t(left_x: 1413   top_y:  179   width:   47   height:   88)\n",
            "person: 78%\t(left_x: 1437   top_y:  185   width:   37   height:   77)\n",
            "motorbike: 25%\t(left_x: 1440   top_y:  200   width:   31   height:   67)\n",
            "person: 67%\t(left_x: 1532   top_y:  182   width:   57   height:   81)\n",
            "motorbike: 81%\t(left_x: 1532   top_y:  216   width:   45   height:   59)\n",
            "person: 53%\t(left_x: 1598   top_y:  189   width:   22   height:   36)\n",
            "motorbike: 85%\t(left_x: 1608   top_y:  309   width:  127   height:  143)\n",
            "person: 39%\t(left_x: 1613   top_y:  188   width:   40   height:   63)\n",
            "motorbike: 91%\t(left_x: 1613   top_y:  214   width:   36   height:   45)\n",
            "person: 63%\t(left_x: 1616   top_y:  185   width:   35   height:   43)\n",
            "person: 99%\t(left_x: 1654   top_y:  190   width:  117   height:  209)\n",
            "motorbike: 97%\t(left_x: 1751   top_y:  228   width:   73   height:   94)\n",
            "person: 81%\t(left_x: 1762   top_y:  177   width:   75   height:   89)\n",
            "car: 96%\t(left_x: 1805   top_y:  182   width:  105   height:   69)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/186.jpg: Predicted in 54.910000 milli-seconds.\n",
            "person: 98%\t(left_x:  536   top_y:  196   width:   50   height:  159)\n",
            "person: 96%\t(left_x:  670   top_y:  176   width:   45   height:  150)\n",
            "person: 33%\t(left_x:  830   top_y:  187   width:   38   height:  102)\n",
            "person: 67%\t(left_x:  860   top_y:  176   width:   40   height:  112)\n",
            "person: 49%\t(left_x:  896   top_y:  187   width:   34   height:   73)\n",
            "motorbike: 73%\t(left_x:  913   top_y:  248   width:   80   height:   91)\n",
            "person: 27%\t(left_x:  914   top_y:  242   width:   75   height:   97)\n",
            "person: 28%\t(left_x:  948   top_y:  206   width:   43   height:   85)\n",
            "person: 39%\t(left_x:  979   top_y:  194   width:   28   height:   58)\n",
            "car: 82%\t(left_x: 1004   top_y:  201   width:   50   height:   38)\n",
            "motorbike: 27%\t(left_x: 1097   top_y:  237   width:   45   height:   42)\n",
            "car: 77%\t(left_x: 1103   top_y:  195   width:   99   height:   55)\n",
            "person: 68%\t(left_x: 1214   top_y:  193   width:   44   height:   84)\n",
            "motorbike: 80%\t(left_x: 1214   top_y:  234   width:   42   height:   51)\n",
            "motorbike: 27%\t(left_x: 1337   top_y:  190   width:   60   height:   91)\n",
            "person: 77%\t(left_x: 1337   top_y:  189   width:   60   height:   91)\n",
            "motorbike: 52%\t(left_x: 1339   top_y:  233   width:   43   height:   55)\n",
            "motorbike: 28%\t(left_x: 1342   top_y:  223   width:   56   height:   59)\n",
            "person: 35%\t(left_x: 1391   top_y:  190   width:   29   height:   62)\n",
            "person: 29%\t(left_x: 1395   top_y:  190   width:   24   height:   31)\n",
            "motorbike: 55%\t(left_x: 1406   top_y:  218   width:   38   height:   53)\n",
            "person: 80%\t(left_x: 1414   top_y:  187   width:   41   height:   74)\n",
            "car: 44%\t(left_x: 1450   top_y:  204   width:   34   height:   42)\n",
            "motorbike: 35%\t(left_x: 1451   top_y:  210   width:   30   height:   38)\n",
            "motorbike: 82%\t(left_x: 1501   top_y:  214   width:   40   height:   67)\n",
            "person: 75%\t(left_x: 1510   top_y:  185   width:   42   height:   80)\n",
            "person: 70%\t(left_x: 1544   top_y:  187   width:   29   height:   73)\n",
            "motorbike: 41%\t(left_x: 1544   top_y:  208   width:   29   height:   55)\n",
            "person: 72%\t(left_x: 1610   top_y:  182   width:   40   height:   70)\n",
            "motorbike: 84%\t(left_x: 1611   top_y:  213   width:   36   height:   46)\n",
            "car: 53%\t(left_x: 1677   top_y:  208   width:   47   height:   31)\n",
            "car: 76%\t(left_x: 1720   top_y:  180   width:  130   height:   69)\n",
            "motorbike: 92%\t(left_x: 1750   top_y:  286   width:  115   height:  117)\n",
            "person: 97%\t(left_x: 1793   top_y:  192   width:  112   height:  161)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/187.jpg: Predicted in 54.895000 milli-seconds.\n",
            "person: 98%\t(left_x:  571   top_y:  190   width:   57   height:  162)\n",
            "person: 94%\t(left_x:  712   top_y:  173   width:   45   height:  149)\n",
            "motorbike: 81%\t(left_x:  721   top_y:  259   width:  123   height:  115)\n",
            "person: 69%\t(left_x:  774   top_y:  201   width:   58   height:  127)\n",
            "person: 68%\t(left_x:  883   top_y:  186   width:   42   height:  107)\n",
            "person: 89%\t(left_x:  919   top_y:  180   width:   36   height:  105)\n",
            "car: 44%\t(left_x:  943   top_y:  192   width:   69   height:   54)\n",
            "car: 63%\t(left_x:  965   top_y:  194   width:   62   height:   52)\n",
            "person: 30%\t(left_x: 1014   top_y:  193   width:   31   height:   56)\n",
            "car: 93%\t(left_x: 1039   top_y:  201   width:   60   height:   37)\n",
            "motorbike: 44%\t(left_x: 1143   top_y:  228   width:   45   height:   51)\n",
            "car: 44%\t(left_x: 1174   top_y:  194   width:  124   height:   56)\n",
            "person: 70%\t(left_x: 1198   top_y:  191   width:   70   height:   92)\n",
            "motorbike: 86%\t(left_x: 1209   top_y:  237   width:   52   height:   58)\n",
            "car: 51%\t(left_x: 1256   top_y:  207   width:   46   height:   43)\n",
            "motorbike: 87%\t(left_x: 1298   top_y:  227   width:   63   height:   75)\n",
            "person: 90%\t(left_x: 1305   top_y:  185   width:   56   height:  104)\n",
            "motorbike: 31%\t(left_x: 1417   top_y:  190   width:   53   height:   85)\n",
            "motorbike: 79%\t(left_x: 1418   top_y:  222   width:   37   height:   56)\n",
            "person: 59%\t(left_x: 1421   top_y:  190   width:   48   height:   83)\n",
            "car: 26%\t(left_x: 1447   top_y:  193   width:   57   height:   59)\n",
            "motorbike: 29%\t(left_x: 1492   top_y:  228   width:   42   height:   66)\n",
            "person: 92%\t(left_x: 1493   top_y:  189   width:   58   height:   93)\n",
            "motorbike: 36%\t(left_x: 1497   top_y:  212   width:   52   height:   77)\n",
            "motorbike: 64%\t(left_x: 1551   top_y:  215   width:   42   height:   59)\n",
            "person: 83%\t(left_x: 1560   top_y:  188   width:   38   height:   70)\n",
            "person: 34%\t(left_x: 1629   top_y:  189   width:   19   height:   36)\n",
            "person: 62%\t(left_x: 1643   top_y:  182   width:   45   height:   81)\n",
            "motorbike: 80%\t(left_x: 1647   top_y:  219   width:   37   height:   53)\n",
            "car: 98%\t(left_x: 1759   top_y:  185   width:  163   height:   69)\n",
            "motorbike: 38%\t(left_x: 1903   top_y:  225   width:   17   height:   74)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/188.jpg: Predicted in 54.869000 milli-seconds.\n",
            "motorbike: 95%\t(left_x:  340   top_y:  278   width:  210   height:  156)\n",
            "person: 58%\t(left_x:  417   top_y:  212   width:   87   height:  167)\n",
            "person: 99%\t(left_x:  590   top_y:  189   width:   50   height:  166)\n",
            "person: 98%\t(left_x:  724   top_y:  177   width:   44   height:  149)\n",
            "person: 64%\t(left_x:  916   top_y:  190   width:   33   height:   94)\n",
            "person: 89%\t(left_x:  947   top_y:  181   width:   41   height:  123)\n",
            "car: 90%\t(left_x:  987   top_y:  192   width:  104   height:   60)\n",
            "car: 43%\t(left_x: 1066   top_y:  199   width:   49   height:   35)\n",
            "motorbike: 83%\t(left_x: 1164   top_y:  237   width:  107   height:   83)\n",
            "person: 78%\t(left_x: 1175   top_y:  193   width:   87   height:  103)\n",
            "car: 97%\t(left_x: 1240   top_y:  192   width:  133   height:   60)\n",
            "person: 90%\t(left_x: 1394   top_y:  190   width:   51   height:   85)\n",
            "motorbike: 46%\t(left_x: 1394   top_y:  223   width:   33   height:   58)\n",
            "motorbike: 34%\t(left_x: 1438   top_y:  225   width:   42   height:   77)\n",
            "person: 87%\t(left_x: 1445   top_y:  195   width:   51   height:   99)\n",
            "car: 61%\t(left_x: 1488   top_y:  191   width:   91   height:   59)\n",
            "person: 35%\t(left_x: 1525   top_y:  188   width:   59   height:   69)\n",
            "motorbike: 70%\t(left_x: 1529   top_y:  219   width:   36   height:   61)\n",
            "person: 33%\t(left_x: 1572   top_y:  190   width:   33   height:   66)\n",
            "motorbike: 34%\t(left_x: 1582   top_y:  219   width:   48   height:   51)\n",
            "person: 42%\t(left_x: 1583   top_y:  208   width:   44   height:   57)\n",
            "motorbike: 87%\t(left_x: 1641   top_y:  222   width:   38   height:   53)\n",
            "person: 61%\t(left_x: 1642   top_y:  185   width:   42   height:   79)\n",
            "person: 31%\t(left_x: 1677   top_y:  191   width:   19   height:   36)\n",
            "car: 99%\t(left_x: 1761   top_y:  183   width:  161   height:   70)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/189.jpg: Predicted in 54.935000 milli-seconds.\n",
            "car: 98%\t(left_x:   16   top_y:  295   width:  616   height:  740)\n",
            "person: 97%\t(left_x:  596   top_y:  201   width:   49   height:  171)\n",
            "person: 98%\t(left_x:  724   top_y:  184   width:   49   height:  156)\n",
            "car: 59%\t(left_x:  896   top_y:  192   width:   53   height:   48)\n",
            "person: 94%\t(left_x:  934   top_y:  201   width:   35   height:   90)\n",
            "car: 59%\t(left_x:  999   top_y:  201   width:  116   height:   45)\n",
            "motorbike: 77%\t(left_x: 1005   top_y:  248   width:  102   height:  114)\n",
            "person: 87%\t(left_x: 1015   top_y:  199   width:   88   height:  141)\n",
            "motorbike: 25%\t(left_x: 1095   top_y:  210   width:   60   height:  113)\n",
            "person: 50%\t(left_x: 1100   top_y:  197   width:   54   height:  106)\n",
            "motorbike: 53%\t(left_x: 1148   top_y:  241   width:   58   height:   50)\n",
            "car: 98%\t(left_x: 1270   top_y:  201   width:  106   height:   61)\n",
            "person: 92%\t(left_x: 1351   top_y:  193   width:   74   height:  113)\n",
            "person: 31%\t(left_x: 1352   top_y:  229   width:   71   height:   94)\n",
            "motorbike: 71%\t(left_x: 1354   top_y:  249   width:   67   height:   77)\n",
            "bicycle: 47%\t(left_x: 1500   top_y:  230   width:   45   height:   64)\n",
            "motorbike: 75%\t(left_x: 1500   top_y:  230   width:   46   height:   63)\n",
            "person: 82%\t(left_x: 1503   top_y:  194   width:   52   height:   84)\n",
            "car: 71%\t(left_x: 1527   top_y:  200   width:  113   height:   59)\n",
            "car: 29%\t(left_x: 1612   top_y:  195   width:   86   height:   83)\n",
            "motorbike: 43%\t(left_x: 1616   top_y:  231   width:   42   height:   63)\n",
            "person: 85%\t(left_x: 1618   top_y:  193   width:   64   height:   84)\n",
            "motorbike: 43%\t(left_x: 1619   top_y:  215   width:   81   height:   72)\n",
            "motorbike: 33%\t(left_x: 1657   top_y:  219   width:   50   height:   58)\n",
            "car: 99%\t(left_x: 1761   top_y:  189   width:  161   height:   70)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/190.jpg: Predicted in 54.775000 milli-seconds.\n",
            "car: 100%\t(left_x:   12   top_y:  215   width: 1231   height:  665)\n",
            "person: 67%\t(left_x:  747   top_y:  193   width:   39   height:   30)\n",
            "person: 46%\t(left_x:  962   top_y:  207   width:   32   height:   65)\n",
            "person: 26%\t(left_x:  993   top_y:  197   width:   28   height:   79)\n",
            "person: 38%\t(left_x:  998   top_y:  219   width:   75   height:   95)\n",
            "motorbike: 31%\t(left_x:  998   top_y:  219   width:   75   height:   95)\n",
            "person: 29%\t(left_x: 1000   top_y:  213   width:   56   height:   77)\n",
            "motorbike: 73%\t(left_x: 1002   top_y:  259   width:   82   height:   67)\n",
            "car: 44%\t(left_x: 1059   top_y:  206   width:   62   height:   61)\n",
            "car: 43%\t(left_x: 1071   top_y:  205   width:  129   height:   65)\n",
            "motorbike: 59%\t(left_x: 1085   top_y:  237   width:  126   height:   57)\n",
            "motorbike: 93%\t(left_x: 1234   top_y:  238   width:   93   height:  116)\n",
            "person: 89%\t(left_x: 1246   top_y:  191   width:   79   height:  143)\n",
            "motorbike: 74%\t(left_x: 1323   top_y:  243   width:   47   height:   65)\n",
            "person: 94%\t(left_x: 1329   top_y:  204   width:   51   height:   94)\n",
            "car: 93%\t(left_x: 1365   top_y:  203   width:  118   height:   64)\n",
            "motorbike: 29%\t(left_x: 1468   top_y:  242   width:   35   height:   62)\n",
            "motorbike: 58%\t(left_x: 1469   top_y:  233   width:   56   height:   68)\n",
            "person: 89%\t(left_x: 1473   top_y:  199   width:   52   height:   89)\n",
            "person: 93%\t(left_x: 1579   top_y:  200   width:   60   height:   95)\n",
            "motorbike: 88%\t(left_x: 1582   top_y:  240   width:   53   height:   67)\n",
            "car: 87%\t(left_x: 1620   top_y:  201   width:  107   height:   65)\n",
            "motorbike: 73%\t(left_x: 1717   top_y:  224   width:   88   height:   59)\n",
            "person: 52%\t(left_x: 1719   top_y:  192   width:   36   height:   80)\n",
            "person: 79%\t(left_x: 1720   top_y:  208   width:   75   height:   76)\n",
            "person: 41%\t(left_x: 1729   top_y:  194   width:   42   height:   77)\n",
            "car: 95%\t(left_x: 1781   top_y:  191   width:  141   height:   70)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/191.jpg: Predicted in 54.789000 milli-seconds.\n",
            "motorbike: 45%\t(left_x:   -1   top_y:  683   width:  481   height:  396)\n",
            "person: 28%\t(left_x:   -0   top_y:  658   width:  247   height:  421)\n",
            "motorbike: 97%\t(left_x:  217   top_y:  316   width:  297   height:  187)\n",
            "person: 64%\t(left_x:  322   top_y:  239   width:  109   height:  218)\n",
            "person: 99%\t(left_x:  623   top_y:  224   width:   47   height:  165)\n",
            "person: 93%\t(left_x:  764   top_y:  212   width:   60   height:  148)\n",
            "car: 100%\t(left_x:  808   top_y:  219   width:  754   height:  417)\n",
            "person: 76%\t(left_x:  864   top_y:  219   width:   75   height:  117)\n",
            "person: 26%\t(left_x:  897   top_y:  218   width:   49   height:   64)\n",
            "person: 55%\t(left_x:  961   top_y:  218   width:   28   height:   41)\n",
            "person: 34%\t(left_x:  987   top_y:  215   width:   25   height:   33)\n",
            "person: 40%\t(left_x: 1019   top_y:  206   width:   27   height:   30)\n",
            "person: 27%\t(left_x: 1311   top_y:  211   width:   22   height:   16)\n",
            "car: 84%\t(left_x: 1407   top_y:  212   width:  144   height:   67)\n",
            "car: 28%\t(left_x: 1416   top_y:  207   width:   84   height:   85)\n",
            "motorbike: 51%\t(left_x: 1420   top_y:  232   width:   71   height:   70)\n",
            "person: 84%\t(left_x: 1421   top_y:  204   width:   75   height:   91)\n",
            "bicycle: 30%\t(left_x: 1427   top_y:  241   width:   60   height:   64)\n",
            "motorbike: 76%\t(left_x: 1531   top_y:  251   width:   61   height:   79)\n",
            "person: 81%\t(left_x: 1534   top_y:  210   width:   56   height:  104)\n",
            "person: 71%\t(left_x: 1615   top_y:  209   width:   20   height:   44)\n",
            "car: 99%\t(left_x: 1640   top_y:  207   width:  178   height:   73)\n",
            "motorbike: 89%\t(left_x: 1816   top_y:  233   width:  104   height:   65)\n",
            "person: 51%\t(left_x: 1823   top_y:  201   width:   61   height:   69)\n",
            "person: 62%\t(left_x: 1824   top_y:  200   width:   32   height:   68)\n",
            "car: 37%\t(left_x: 1855   top_y:  200   width:   66   height:   68)\n",
            "car: 35%\t(left_x: 1861   top_y:  202   width:   59   height:   38)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/192.jpg: Predicted in 54.841000 milli-seconds.\n",
            "person: 83%\t(left_x:  623   top_y:  228   width:   58   height:  150)\n",
            "motorbike: 72%\t(left_x:  656   top_y:  299   width:  143   height:  121)\n",
            "motorbike: 95%\t(left_x:  659   top_y:  436   width:  600   height:  554)\n",
            "person: 72%\t(left_x:  691   top_y:  243   width:   87   height:  124)\n",
            "motorbike: 91%\t(left_x:  752   top_y:  294   width:  164   height:  164)\n",
            "person: 45%\t(left_x:  763   top_y:  213   width:   47   height:  105)\n",
            "person: 33%\t(left_x:  836   top_y:  223   width:   65   height:  157)\n",
            "person: 39%\t(left_x:  836   top_y:  224   width:   64   height:   77)\n",
            "person: 73%\t(left_x:  868   top_y:  172   width:  357   height:  638)\n",
            "car: 38%\t(left_x: 1050   top_y:  215   width:   55   height:   71)\n",
            "car: 27%\t(left_x: 1096   top_y:  231   width:   54   height:   38)\n",
            "car: 25%\t(left_x: 1203   top_y:  219   width:   50   height:   30)\n",
            "motorbike: 49%\t(left_x: 1211   top_y:  250   width:   86   height:   59)\n",
            "car: 100%\t(left_x: 1213   top_y:  211   width:  567   height:  321)\n",
            "person: 74%\t(left_x: 1224   top_y:  217   width:   70   height:   88)\n",
            "car: 40%\t(left_x: 1230   top_y:  217   width:   78   height:   65)\n",
            "car: 36%\t(left_x: 1273   top_y:  232   width:   47   height:   33)\n",
            "car: 100%\t(left_x: 1701   top_y:  212   width:  207   height:   76)\n",
            "car: 93%\t(left_x: 1842   top_y:  207   width:   81   height:   67)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/193.jpg: Predicted in 54.841000 milli-seconds.\n",
            "motorbike: 98%\t(left_x:  147   top_y:  314   width:  365   height:  235)\n",
            "person: 72%\t(left_x:  289   top_y:  210   width:  134   height:  243)\n",
            "motorbike: 66%\t(left_x:  300   top_y:  579   width:  885   height:  496)\n",
            "person: 74%\t(left_x:  413   top_y:  216   width:  125   height:  152)\n",
            "motorbike: 56%\t(left_x:  471   top_y:  320   width:  123   height:  109)\n",
            "person: 97%\t(left_x:  622   top_y:  214   width:   55   height:  166)\n",
            "car: 36%\t(left_x:  671   top_y:  191   width:  227   height:  152)\n",
            "person: 88%\t(left_x:  689   top_y:  246   width:  417   height:  816)\n",
            "person: 71%\t(left_x:  953   top_y:  211   width:   29   height:   85)\n",
            "person: 68%\t(left_x:  980   top_y:  210   width:   31   height:   88)\n",
            "person: 80%\t(left_x: 1014   top_y:  210   width:   27   height:   87)\n",
            "person: 91%\t(left_x: 1039   top_y:  201   width:   36   height:  100)\n",
            "car: 41%\t(left_x: 1077   top_y:  225   width:   34   height:   44)\n",
            "bicycle: 29%\t(left_x: 1113   top_y:  257   width:   88   height:  103)\n",
            "motorbike: 65%\t(left_x: 1116   top_y:  249   width:   81   height:  111)\n",
            "person: 92%\t(left_x: 1120   top_y:  208   width:   78   height:  142)\n",
            "car: 90%\t(left_x: 1223   top_y:  208   width:   95   height:   63)\n",
            "motorbike: 46%\t(left_x: 1275   top_y:  241   width:   90   height:  105)\n",
            "person: 91%\t(left_x: 1290   top_y:  201   width:   69   height:  130)\n",
            "bicycle: 61%\t(left_x: 1299   top_y:  245   width:   94   height:  107)\n",
            "motorbike: 51%\t(left_x: 1299   top_y:  245   width:   94   height:  107)\n",
            "motorbike: 87%\t(left_x: 1300   top_y:  363   width:  277   height:  323)\n",
            "person: 48%\t(left_x: 1345   top_y:  206   width:   50   height:   56)\n",
            "person: 96%\t(left_x: 1368   top_y:  164   width:  203   height:  417)\n",
            "car: 58%\t(left_x: 1505   top_y:  207   width:  138   height:   57)\n",
            "car: 100%\t(left_x: 1509   top_y:  200   width:  407   height:  273)\n",
            "car: 29%\t(left_x: 1514   top_y:  205   width:  131   height:   30)\n",
            "car: 82%\t(left_x: 1790   top_y:  199   width:  131   height:   98)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/194.jpg: Predicted in 54.804000 milli-seconds.\n",
            "motorbike: 96%\t(left_x:   -4   top_y:  320   width:  283   height:  172)\n",
            "person: 88%\t(left_x:   34   top_y:  213   width:  159   height:  219)\n",
            "person: 98%\t(left_x:  624   top_y:  204   width:   43   height:  166)\n",
            "person: 99%\t(left_x:  757   top_y:  185   width:   57   height:  168)\n",
            "person: 69%\t(left_x:  935   top_y:  203   width:   41   height:   95)\n",
            "motorbike: 88%\t(left_x:  961   top_y:  269   width:  112   height:  107)\n",
            "person: 58%\t(left_x:  974   top_y:  199   width:   33   height:   73)\n",
            "person: 92%\t(left_x:  986   top_y:  202   width:   79   height:  146)\n",
            "car: 61%\t(left_x: 1039   top_y:  210   width:   83   height:   58)\n",
            "car: 39%\t(left_x: 1065   top_y:  211   width:   75   height:   51)\n",
            "motorbike: 87%\t(left_x: 1174   top_y:  256   width:  110   height:  119)\n",
            "person: 98%\t(left_x: 1188   top_y:  198   width:   97   height:  141)\n",
            "motorbike: 82%\t(left_x: 1254   top_y:  502   width:  275   height:  298)\n",
            "car: 77%\t(left_x: 1263   top_y:  192   width:  129   height:   68)\n",
            "person: 90%\t(left_x: 1321   top_y:  185   width:  231   height:  470)\n",
            "motorbike: 79%\t(left_x: 1535   top_y:  325   width:  193   height:  223)\n",
            "car: 32%\t(left_x: 1565   top_y:  174   width:  165   height:   87)\n",
            "person: 38%\t(left_x: 1566   top_y:  174   width:  165   height:   86)\n",
            "person: 97%\t(left_x: 1576   top_y:  175   width:  171   height:  315)\n",
            "car: 99%\t(left_x: 1698   top_y:  189   width:  223   height:  233)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/195.jpg: Predicted in 54.901000 milli-seconds.\n",
            "person: 96%\t(left_x:  589   top_y:  173   width:   54   height:  169)\n",
            "motorbike: 87%\t(left_x:  702   top_y:  254   width:  164   height:  135)\n",
            "person: 73%\t(left_x:  728   top_y:  152   width:   42   height:  106)\n",
            "person: 97%\t(left_x:  735   top_y:  170   width:   94   height:  189)\n",
            "traffic light: 27%\t(left_x:  907   top_y:   -0   width:   30   height:   44)\n",
            "person: 77%\t(left_x:  907   top_y:  172   width:   36   height:   92)\n",
            "person: 67%\t(left_x:  942   top_y:  168   width:   28   height:   96)\n",
            "motorbike: 68%\t(left_x:  952   top_y:  228   width:  142   height:  158)\n",
            "person: 95%\t(left_x:  978   top_y:  167   width:  100   height:  188)\n",
            "person: 48%\t(left_x:  984   top_y:  171   width:   27   height:   64)\n",
            "car: 30%\t(left_x: 1047   top_y:  185   width:   38   height:   22)\n",
            "motorbike: 41%\t(left_x: 1073   top_y:  242   width:   64   height:   91)\n",
            "person: 92%\t(left_x: 1073   top_y:  173   width:   66   height:  143)\n",
            "motorbike: 56%\t(left_x: 1148   top_y:  207   width:   55   height:   58)\n",
            "motorbike: 30%\t(left_x: 1182   top_y:  192   width:   44   height:   49)\n",
            "car: 96%\t(left_x: 1270   top_y:  165   width:  158   height:   72)\n",
            "motorbike: 93%\t(left_x: 1411   top_y:  194   width:   75   height:   53)\n",
            "person: 42%\t(left_x: 1423   top_y:  173   width:   52   height:   65)\n",
            "motorbike: 78%\t(left_x: 1501   top_y:  344   width:  181   height:  243)\n",
            "person: 96%\t(left_x: 1541   top_y:  162   width:  174   height:  299)\n",
            "motorbike: 67%\t(left_x: 1685   top_y:  274   width:   94   height:  159)\n",
            "person: 88%\t(left_x: 1686   top_y:  152   width:  131   height:  241)\n",
            "car: 38%\t(left_x: 1769   top_y:  164   width:   93   height:   54)\n",
            "car: 96%\t(left_x: 1775   top_y:  168   width:  146   height:  196)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/196.jpg: Predicted in 54.685000 milli-seconds.\n",
            "motorbike: 98%\t(left_x:  301   top_y:  269   width:  254   height:  172)\n",
            "motorbike: 26%\t(left_x:  349   top_y:  162   width:  166   height:  256)\n",
            "person: 98%\t(left_x:  363   top_y:  163   width:  133   height:  235)\n",
            "person: 94%\t(left_x:  570   top_y:  170   width:   58   height:  161)\n",
            "motorbike: 96%\t(left_x:  589   top_y:  243   width:  249   height:  201)\n",
            "person: 95%\t(left_x:  670   top_y:  154   width:  107   height:  239)\n",
            "motorbike: 87%\t(left_x:  819   top_y:  226   width:  157   height:  133)\n",
            "bicycle: 42%\t(left_x:  822   top_y:  223   width:  152   height:  137)\n",
            "person: 90%\t(left_x:  876   top_y:  159   width:   98   height:  153)\n",
            "person: 37%\t(left_x:  970   top_y:  165   width:   23   height:   77)\n",
            "person: 91%\t(left_x:  998   top_y:  162   width:   33   height:   87)\n",
            "car: 60%\t(left_x: 1028   top_y:  175   width:   74   height:   54)\n",
            "car: 31%\t(left_x: 1031   top_y:  173   width:  142   height:   64)\n",
            "motorbike: 38%\t(left_x: 1061   top_y:  178   width:  117   height:   71)\n",
            "motorbike: 59%\t(left_x: 1197   top_y:  179   width:   62   height:   46)\n",
            "person: 27%\t(left_x: 1203   top_y:  164   width:   53   height:   61)\n",
            "car: 99%\t(left_x: 1300   top_y:  155   width:  182   height:   75)\n",
            "motorbike: 85%\t(left_x: 1468   top_y:  179   width:   89   height:   61)\n",
            "person: 43%\t(left_x: 1482   top_y:  134   width:   37   height:   92)\n",
            "motorbike: 88%\t(left_x: 1635   top_y:  316   width:  133   height:  156)\n",
            "person: 67%\t(left_x: 1649   top_y:  163   width:   30   height:   56)\n",
            "person: 96%\t(left_x: 1665   top_y:  154   width:  139   height:  245)\n",
            "motorbike: 45%\t(left_x: 1777   top_y:  252   width:   68   height:  141)\n",
            "person: 90%\t(left_x: 1781   top_y:  141   width:  106   height:  217)\n",
            "car: 78%\t(left_x: 1855   top_y:  155   width:   66   height:   54)\n",
            "car: 69%\t(left_x: 1863   top_y:  195   width:   57   height:  130)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/197.jpg: Predicted in 54.925000 milli-seconds.\n",
            "motorbike: 96%\t(left_x:    6   top_y:  298   width:  400   height:  257)\n",
            "person: 64%\t(left_x:   87   top_y:  176   width:  214   height:  320)\n",
            "motorbike: 97%\t(left_x:  574   top_y:  236   width:  214   height:  164)\n",
            "person: 85%\t(left_x:  583   top_y:  173   width:   54   height:  135)\n",
            "person: 84%\t(left_x:  666   top_y:  167   width:  111   height:  169)\n",
            "person: 32%\t(left_x:  739   top_y:  157   width:   56   height:  153)\n",
            "person: 41%\t(left_x:  882   top_y:  169   width:   43   height:   96)\n",
            "person: 96%\t(left_x:  922   top_y:  158   width:   34   height:   99)\n",
            "person: 94%\t(left_x: 1001   top_y:  156   width:   36   height:   91)\n",
            "car: 31%\t(left_x: 1032   top_y:  183   width:   34   height:   47)\n",
            "car: 74%\t(left_x: 1057   top_y:  176   width:   49   height:   36)\n",
            "motorbike: 47%\t(left_x: 1069   top_y:  173   width:  126   height:   81)\n",
            "motorbike: 37%\t(left_x: 1186   top_y:  181   width:   65   height:   47)\n",
            "motorbike: 67%\t(left_x: 1246   top_y:  180   width:   72   height:   45)\n",
            "person: 42%\t(left_x: 1252   top_y:  163   width:   60   height:   60)\n",
            "person: 35%\t(left_x: 1259   top_y:  160   width:   33   height:   34)\n",
            "car: 99%\t(left_x: 1361   top_y:  152   width:  196   height:   78)\n",
            "motorbike: 81%\t(left_x: 1564   top_y:  168   width:   98   height:   72)\n",
            "person: 30%\t(left_x: 1574   top_y:  157   width:   71   height:   78)\n",
            "person: 28%\t(left_x: 1641   top_y:  155   width:   29   height:   52)\n",
            "car: 96%\t(left_x: 1678   top_y:  151   width:  148   height:   75)\n",
            "motorbike: 91%\t(left_x: 1745   top_y:  286   width:  112   height:  135)\n",
            "car: 70%\t(left_x: 1758   top_y:  148   width:  163   height:   81)\n",
            "person: 88%\t(left_x: 1768   top_y:  155   width:  143   height:  203)\n",
            "motorbike: 77%\t(left_x: 1855   top_y:  233   width:   66   height:  135)\n",
            "person: 49%\t(left_x: 1887   top_y:  150   width:   35   height:   84)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/198.jpg: Predicted in 54.879000 milli-seconds.\n",
            "motorbike: 98%\t(left_x:  219   top_y:  259   width:  286   height:  192)\n",
            "person: 77%\t(left_x:  325   top_y:  176   width:  127   height:  224)\n",
            "person: 30%\t(left_x:  430   top_y:  198   width:   77   height:  152)\n",
            "person: 98%\t(left_x:  594   top_y:  170   width:   49   height:  168)\n",
            "car: 29%\t(left_x:  698   top_y:  165   width:   44   height:   20)\n",
            "person: 95%\t(left_x:  775   top_y:  165   width:   60   height:  160)\n",
            "person: 91%\t(left_x:  924   top_y:  160   width:   33   height:   99)\n",
            "car: 33%\t(left_x:  999   top_y:  163   width:   52   height:   78)\n",
            "person: 95%\t(left_x: 1003   top_y:  158   width:   31   height:   88)\n",
            "car: 39%\t(left_x: 1023   top_y:  173   width:   60   height:   60)\n",
            "car: 56%\t(left_x: 1039   top_y:  175   width:   70   height:   51)\n",
            "car: 89%\t(left_x: 1173   top_y:  169   width:  135   height:   64)\n",
            "motorbike: 66%\t(left_x: 1299   top_y:  161   width:   68   height:   61)\n",
            "person: 37%\t(left_x: 1301   top_y:  161   width:   66   height:   61)\n",
            "car: 100%\t(left_x: 1416   top_y:  150   width:  218   height:   82)\n",
            "motorbike: 28%\t(left_x: 1620   top_y:  161   width:   37   height:   54)\n",
            "motorbike: 96%\t(left_x: 1660   top_y:  180   width:  104   height:   61)\n",
            "person: 68%\t(left_x: 1681   top_y:  151   width:   52   height:   75)\n",
            "car: 86%\t(left_x: 1712   top_y:  149   width:  136   height:   74)\n",
            "motorbike: 94%\t(left_x: 1833   top_y:  265   width:   88   height:  119)\n",
            "car: 94%\t(left_x: 1836   top_y:  148   width:   82   height:   63)\n",
            "person: 84%\t(left_x: 1855   top_y:  168   width:   68   height:  150)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/199.jpg: Predicted in 54.904000 milli-seconds.\n",
            "person: 46%\t(left_x:   -2   top_y:  203   width:  105   height:  242)\n",
            "motorbike: 36%\t(left_x:   -0   top_y:  253   width:  110   height:  245)\n",
            "motorbike: 32%\t(left_x:    0   top_y:  339   width:   97   height:  151)\n",
            "person: 96%\t(left_x:  595   top_y:  173   width:   53   height:  169)\n",
            "person: 97%\t(left_x:  824   top_y:  166   width:   77   height:  169)\n",
            "person: 92%\t(left_x:  915   top_y:  166   width:   39   height:  104)\n",
            "person: 73%\t(left_x:  963   top_y:  170   width:   26   height:   72)\n",
            "person: 97%\t(left_x: 1000   top_y:  161   width:   29   height:   86)\n",
            "car: 74%\t(left_x: 1035   top_y:  176   width:   82   height:   51)\n",
            "bicycle: 42%\t(left_x: 1077   top_y:  206   width:  132   height:   50)\n",
            "car: 99%\t(left_x: 1199   top_y:  171   width:  164   height:   63)\n",
            "person: 58%\t(left_x: 1353   top_y:  161   width:   62   height:   61)\n",
            "motorbike: 41%\t(left_x: 1353   top_y:  161   width:   63   height:   61)\n",
            "motorbike: 32%\t(left_x: 1363   top_y:  180   width:   59   height:   42)\n",
            "car: 100%\t(left_x: 1477   top_y:  150   width:  225   height:   87)\n",
            "car: 52%\t(left_x: 1648   top_y:  162   width:   61   height:   25)\n",
            "car: 88%\t(left_x: 1696   top_y:  153   width:  108   height:   72)\n",
            "motorbike: 90%\t(left_x: 1762   top_y:  188   width:  121   height:   58)\n",
            "person: 55%\t(left_x: 1791   top_y:  154   width:   51   height:   73)\n",
            "car: 92%\t(left_x: 1826   top_y:  149   width:   96   height:   68)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/200.jpg: Predicted in 54.741000 milli-seconds.\n",
            "person: 97%\t(left_x:  585   top_y:  171   width:   55   height:  163)\n",
            "car: 42%\t(left_x:  677   top_y:  166   width:   42   height:   17)\n",
            "car: 28%\t(left_x:  682   top_y:  164   width:   65   height:   19)\n",
            "person: 70%\t(left_x:  822   top_y:  168   width:   34   height:  111)\n",
            "person: 99%\t(left_x:  878   top_y:  154   width:   77   height:  186)\n",
            "person: 65%\t(left_x:  942   top_y:  168   width:   30   height:   74)\n",
            "person: 93%\t(left_x:  987   top_y:  160   width:   29   height:   84)\n",
            "car: 35%\t(left_x: 1051   top_y:  181   width:   43   height:   47)\n",
            "car: 39%\t(left_x: 1067   top_y:  175   width:   51   height:   39)\n",
            "car: 99%\t(left_x: 1225   top_y:  169   width:  194   height:   66)\n",
            "motorbike: 36%\t(left_x: 1404   top_y:  163   width:   51   height:   56)\n",
            "person: 48%\t(left_x: 1405   top_y:  162   width:   49   height:   57)\n",
            "motorbike: 48%\t(left_x: 1405   top_y:  183   width:   60   height:   37)\n",
            "person: 71%\t(left_x: 1406   top_y:  158   width:   29   height:   41)\n",
            "person: 29%\t(left_x: 1440   top_y:  162   width:   19   height:   29)\n",
            "car: 87%\t(left_x: 1468   top_y:  166   width:  108   height:   52)\n",
            "car: 100%\t(left_x: 1537   top_y:  149   width:  234   height:   93)\n",
            "car: 45%\t(left_x: 1714   top_y:  155   width:  162   height:   67)\n",
            "person: 52%\t(left_x: 1738   top_y:  156   width:   78   height:   67)\n",
            "car: 37%\t(left_x: 1738   top_y:  157   width:   79   height:   67)\n",
            "car: 52%\t(left_x: 1803   top_y:  153   width:   92   height:   64)\n",
            "motorbike: 84%\t(left_x: 1822   top_y:  195   width:   99   height:   76)\n",
            "person: 75%\t(left_x: 1854   top_y:  150   width:   67   height:  108)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/201.jpg: Predicted in 54.882000 milli-seconds.\n",
            "person: 30%\t(left_x:  257   top_y:  149   width:   27   height:   55)\n",
            "person: 97%\t(left_x:  585   top_y:  182   width:   55   height:  164)\n",
            "person: 67%\t(left_x:  784   top_y:  169   width:   59   height:  131)\n",
            "person: 67%\t(left_x:  881   top_y:  166   width:   40   height:  113)\n",
            "person: 97%\t(left_x:  924   top_y:  157   width:   87   height:  190)\n",
            "car: 100%\t(left_x: 1274   top_y:  170   width:  205   height:   69)\n",
            "car: 90%\t(left_x: 1426   top_y:  166   width:  100   height:   50)\n",
            "person: 78%\t(left_x: 1558   top_y:  162   width:   33   height:   59)\n",
            "motorbike: 65%\t(left_x: 1559   top_y:  185   width:   34   height:   36)\n",
            "car: 48%\t(left_x: 1602   top_y:  145   width:  165   height:   91)\n",
            "car: 88%\t(left_x: 1602   top_y:  149   width:  276   height:   91)\n",
            "motorbike: 76%\t(left_x: 1711   top_y:  191   width:  101   height:   85)\n",
            "person: 73%\t(left_x: 1742   top_y:  148   width:   75   height:  112)\n",
            "person: 33%\t(left_x: 1802   top_y:  147   width:   49   height:   87)\n",
            "car: 55%\t(left_x: 1823   top_y:  148   width:   55   height:   81)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/202.jpg: Predicted in 54.899000 milli-seconds.\n",
            "person: 99%\t(left_x:  593   top_y:  191   width:   48   height:  167)\n",
            "person: 97%\t(left_x:  770   top_y:  181   width:   43   height:  126)\n",
            "person: 57%\t(left_x:  921   top_y:  184   width:   31   height:   62)\n",
            "car: 32%\t(left_x:  978   top_y:  199   width:   35   height:   46)\n",
            "person: 99%\t(left_x:  990   top_y:  167   width:   92   height:  189)\n",
            "car: 29%\t(left_x: 1057   top_y:  194   width:   52   height:   31)\n",
            "car: 51%\t(left_x: 1060   top_y:  189   width:  173   height:   57)\n",
            "car: 71%\t(left_x: 1176   top_y:  187   width:   87   height:   53)\n",
            "car: 96%\t(left_x: 1275   top_y:  182   width:  114   height:   48)\n",
            "car: 99%\t(left_x: 1338   top_y:  179   width:  215   height:   71)\n",
            "person: 68%\t(left_x: 1534   top_y:  176   width:   41   height:   60)\n",
            "motorbike: 93%\t(left_x: 1600   top_y:  208   width:  108   height:   88)\n",
            "person: 74%\t(left_x: 1615   top_y:  162   width:   88   height:  114)\n",
            "person: 58%\t(left_x: 1666   top_y:  159   width:   51   height:  112)\n",
            "person: 27%\t(left_x: 1689   top_y:  157   width:   35   height:  102)\n",
            "car: 99%\t(left_x: 1708   top_y:  150   width:  214   height:  101)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/203.jpg: Predicted in 54.907000 milli-seconds.\n",
            "pottedplant: 31%\t(left_x:  465   top_y:  196   width:  124   height:  106)\n",
            "person: 98%\t(left_x:  600   top_y:  187   width:   54   height:  170)\n",
            "person: 94%\t(left_x:  755   top_y:  186   width:   47   height:  116)\n",
            "person: 59%\t(left_x:  925   top_y:  188   width:   23   height:   56)\n",
            "car: 64%\t(left_x:  960   top_y:  194   width:   72   height:   52)\n",
            "car: 39%\t(left_x:  990   top_y:  195   width:   62   height:   51)\n",
            "car: 74%\t(left_x: 1056   top_y:  193   width:   42   height:   39)\n",
            "person: 98%\t(left_x: 1059   top_y:  169   width:  113   height:  189)\n",
            "motorbike: 39%\t(left_x: 1152   top_y:  218   width:   56   height:   54)\n",
            "car: 95%\t(left_x: 1198   top_y:  188   width:  105   height:   54)\n",
            "car: 44%\t(left_x: 1214   top_y:  184   width:  120   height:   45)\n",
            "car: 79%\t(left_x: 1258   top_y:  186   width:   78   height:   40)\n",
            "person: 45%\t(left_x: 1390   top_y:  175   width:   20   height:   44)\n",
            "car: 98%\t(left_x: 1399   top_y:  178   width:  156   height:   75)\n",
            "motorbike: 86%\t(left_x: 1500   top_y:  216   width:  106   height:   93)\n",
            "person: 68%\t(left_x: 1535   top_y:  168   width:   73   height:  113)\n",
            "person: 37%\t(left_x: 1587   top_y:  167   width:   39   height:  108)\n",
            "person: 27%\t(left_x: 1591   top_y:  166   width:   33   height:   56)\n",
            "car: 99%\t(left_x: 1622   top_y:  171   width:  168   height:   75)\n",
            "motorbike: 98%\t(left_x: 1750   top_y:  240   width:  171   height:  154)\n",
            "car: 85%\t(left_x: 1767   top_y:  167   width:   69   height:   61)\n",
            "person: 89%\t(left_x: 1804   top_y:  160   width:  116   height:  203)\n",
            "car: 42%\t(left_x: 1812   top_y:  155   width:  106   height:   77)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/204.jpg: Predicted in 54.776000 milli-seconds.\n",
            "person: 99%\t(left_x:  614   top_y:  182   width:   52   height:  168)\n",
            "car: 30%\t(left_x:  699   top_y:  180   width:   42   height:   19)\n",
            "person: 98%\t(left_x:  739   top_y:  176   width:   47   height:  125)\n",
            "person: 97%\t(left_x:  827   top_y:  173   width:   44   height:  123)\n",
            "person: 62%\t(left_x:  925   top_y:  180   width:   27   height:   79)\n",
            "person: 60%\t(left_x:  966   top_y:  181   width:   21   height:   59)\n",
            "person: 50%\t(left_x:  976   top_y:  178   width:   27   height:   75)\n",
            "car: 80%\t(left_x: 1005   top_y:  188   width:  102   height:   55)\n",
            "car: 70%\t(left_x: 1083   top_y:  185   width:   60   height:   35)\n",
            "person: 98%\t(left_x: 1156   top_y:  145   width:  107   height:  210)\n",
            "car: 97%\t(left_x: 1230   top_y:  177   width:  120   height:   62)\n",
            "motorbike: 90%\t(left_x: 1382   top_y:  211   width:  124   height:   99)\n",
            "person: 32%\t(left_x: 1387   top_y:  170   width:   23   height:   43)\n",
            "person: 87%\t(left_x: 1417   top_y:  158   width:   81   height:  125)\n",
            "motorbike: 94%\t(left_x: 1469   top_y:  242   width:  231   height:  181)\n",
            "person: 49%\t(left_x: 1484   top_y:  162   width:   40   height:   92)\n",
            "car: 34%\t(left_x: 1497   top_y:  167   width:  262   height:   77)\n",
            "car: 54%\t(left_x: 1516   top_y:  167   width:   88   height:   80)\n",
            "person: 97%\t(left_x: 1524   top_y:  160   width:  149   height:  231)\n",
            "person: 39%\t(left_x: 1659   top_y:  155   width:   63   height:   96)\n",
            "car: 82%\t(left_x: 1695   top_y:  161   width:   98   height:   71)\n",
            "car: 91%\t(left_x: 1759   top_y:  160   width:   81   height:   65)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/205.jpg: Predicted in 54.786000 milli-seconds.\n",
            "person: 98%\t(left_x:  622   top_y:  188   width:   54   height:  164)\n",
            "person: 87%\t(left_x:  727   top_y:  182   width:   44   height:  122)\n",
            "person: 90%\t(left_x:  813   top_y:  171   width:   40   height:  135)\n",
            "person: 28%\t(left_x:  928   top_y:  173   width:   25   height:   61)\n",
            "car: 26%\t(left_x:  967   top_y:  173   width:   30   height:   74)\n",
            "person: 54%\t(left_x:  972   top_y:  176   width:   30   height:   78)\n",
            "car: 91%\t(left_x: 1029   top_y:  186   width:  114   height:   59)\n",
            "motorbike: 96%\t(left_x: 1041   top_y:  272   width:  310   height:  234)\n",
            "person: 95%\t(left_x: 1108   top_y:  161   width:  182   height:  293)\n",
            "person: 29%\t(left_x: 1271   top_y:  147   width:   93   height:  175)\n",
            "person: 28%\t(left_x: 1350   top_y:  159   width:   48   height:  114)\n",
            "motorbike: 49%\t(left_x: 1350   top_y:  215   width:   37   height:  100)\n",
            "person: 31%\t(left_x: 1351   top_y:  160   width:   47   height:   55)\n",
            "motorbike: 65%\t(left_x: 1492   top_y:  195   width:   41   height:   46)\n",
            "person: 77%\t(left_x: 1493   top_y:  174   width:   39   height:   66)\n",
            "car: 100%\t(left_x: 1564   top_y:  163   width:  294   height:   88)\n",
            "car: 66%\t(left_x: 1723   top_y:  159   width:  107   height:   32)\n",
            "car: 58%\t(left_x: 1899   top_y:  163   width:   21   height:   58)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/206.jpg: Predicted in 54.878000 milli-seconds.\n",
            "motorbike: 96%\t(left_x:  223   top_y:  362   width:  508   height:  322)\n",
            "person: 25%\t(left_x:  306   top_y:  162   width:   28   height:   53)\n",
            "person: 81%\t(left_x:  356   top_y:  181   width:  263   height:  409)\n",
            "person: 37%\t(left_x:  574   top_y:  168   width:  149   height:  382)\n",
            "person: 96%\t(left_x:  695   top_y:  187   width:   50   height:  121)\n",
            "person: 96%\t(left_x:  793   top_y:  183   width:   46   height:  125)\n",
            "person: 69%\t(left_x:  970   top_y:  181   width:   24   height:   69)\n",
            "car: 46%\t(left_x: 1023   top_y:  195   width:   51   height:   32)\n",
            "motorbike: 88%\t(left_x: 1064   top_y:  232   width:  158   height:  127)\n",
            "car: 25%\t(left_x: 1071   top_y:  183   width:  115   height:   57)\n",
            "car: 43%\t(left_x: 1092   top_y:  188   width:   56   height:   44)\n",
            "person: 93%\t(left_x: 1108   top_y:  170   width:   88   height:  161)\n",
            "person: 29%\t(left_x: 1142   top_y:  165   width:   75   height:  153)\n",
            "person: 41%\t(left_x: 1179   top_y:  168   width:   56   height:  104)\n",
            "motorbike: 29%\t(left_x: 1195   top_y:  223   width:   48   height:   47)\n",
            "person: 36%\t(left_x: 1273   top_y:  177   width:  100   height:   67)\n",
            "car: 28%\t(left_x: 1275   top_y:  178   width:   99   height:   71)\n",
            "motorbike: 78%\t(left_x: 1276   top_y:  178   width:   97   height:   70)\n",
            "person: 100%\t(left_x: 1340   top_y:  150   width:  119   height:  218)\n",
            "person: 55%\t(left_x: 1475   top_y:  177   width:   45   height:   67)\n",
            "motorbike: 75%\t(left_x: 1475   top_y:  187   width:   42   height:   61)\n",
            "car: 99%\t(left_x: 1626   top_y:  160   width:  294   height:   94)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/207.jpg: Predicted in 55.117000 milli-seconds.\n",
            "person: 96%\t(left_x:  633   top_y:  189   width:   57   height:  167)\n",
            "person: 88%\t(left_x:  675   top_y:  189   width:   43   height:  119)\n",
            "person: 96%\t(left_x:  772   top_y:  184   width:   43   height:  128)\n",
            "motorbike: 96%\t(left_x:  836   top_y:  246   width:  179   height:  146)\n",
            "person: 96%\t(left_x:  896   top_y:  189   width:   87   height:  164)\n",
            "person: 60%\t(left_x:  971   top_y:  172   width:   54   height:  142)\n",
            "car: 64%\t(left_x: 1026   top_y:  198   width:   57   height:   41)\n",
            "motorbike: 39%\t(left_x: 1118   top_y:  203   width:  129   height:   68)\n",
            "motorbike: 31%\t(left_x: 1193   top_y:  200   width:   64   height:   72)\n",
            "car: 90%\t(left_x: 1300   top_y:  177   width:  149   height:   70)\n",
            "person: 36%\t(left_x: 1301   top_y:  174   width:  111   height:   71)\n",
            "motorbike: 25%\t(left_x: 1305   top_y:  192   width:   96   height:   58)\n",
            "person: 100%\t(left_x: 1431   top_y:  146   width:  131   height:  234)\n",
            "car: 99%\t(left_x: 1610   top_y:  162   width:  172   height:   83)\n",
            "person: 62%\t(left_x: 1772   top_y:  161   width:   34   height:   63)\n",
            "car: 98%\t(left_x: 1787   top_y:  155   width:  135   height:   99)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/208.jpg: Predicted in 54.744000 milli-seconds.\n",
            "motorbike: 97%\t(left_x:  494   top_y:  272   width:  237   height:  172)\n",
            "person: 95%\t(left_x:  588   top_y:  205   width:  103   height:  191)\n",
            "person: 62%\t(left_x:  680   top_y:  197   width:   70   height:  200)\n",
            "person: 86%\t(left_x:  724   top_y:  189   width:   59   height:  123)\n",
            "car: 41%\t(left_x:  881   top_y:  182   width:  115   height:   68)\n",
            "car: 60%\t(left_x:  938   top_y:  196   width:   68   height:   53)\n",
            "car: 77%\t(left_x:  972   top_y:  195   width:  124   height:   48)\n",
            "car: 76%\t(left_x: 1066   top_y:  196   width:   80   height:   43)\n",
            "car: 54%\t(left_x: 1197   top_y:  189   width:   82   height:   55)\n",
            "car: 69%\t(left_x: 1309   top_y:  178   width:  122   height:   72)\n",
            "person: 45%\t(left_x: 1331   top_y:  181   width:   87   height:   70)\n",
            "motorbike: 68%\t(left_x: 1402   top_y:  198   width:   57   height:   72)\n",
            "person: 74%\t(left_x: 1405   top_y:  184   width:   52   height:   81)\n",
            "person: 99%\t(left_x: 1524   top_y:  151   width:  103   height:  244)\n",
            "car: 100%\t(left_x: 1603   top_y:  167   width:  149   height:   84)\n",
            "car: 92%\t(left_x: 1755   top_y:  164   width:  114   height:   62)\n",
            "person: 35%\t(left_x: 1770   top_y:  155   width:   23   height:   26)\n",
            "car: 98%\t(left_x: 1831   top_y:  157   width:   93   height:   78)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/209.jpg: Predicted in 54.824000 milli-seconds.\n",
            "motorbike: 95%\t(left_x:   27   top_y:  311   width:  342   height:  217)\n",
            "person: 85%\t(left_x:  159   top_y:  230   width:  141   height:  237)\n",
            "person: 74%\t(left_x:  275   top_y:  206   width:  101   height:  240)\n",
            "person: 42%\t(left_x:  603   top_y:  198   width:   44   height:  152)\n",
            "person: 96%\t(left_x:  634   top_y:  199   width:   55   height:  166)\n",
            "person: 96%\t(left_x:  699   top_y:  191   width:   47   height:  136)\n",
            "car: 92%\t(left_x:  944   top_y:  196   width:  123   height:   54)\n",
            "car: 97%\t(left_x: 1044   top_y:  194   width:  107   height:   42)\n",
            "motorbike: 27%\t(left_x: 1191   top_y:  221   width:   53   height:   50)\n",
            "car: 64%\t(left_x: 1205   top_y:  189   width:   98   height:   56)\n",
            "car: 87%\t(left_x: 1321   top_y:  175   width:  149   height:   73)\n",
            "truck: 26%\t(left_x: 1321   top_y:  175   width:  149   height:   73)\n",
            "person: 67%\t(left_x: 1349   top_y:  175   width:   99   height:   83)\n",
            "motorbike: 79%\t(left_x: 1365   top_y:  205   width:   64   height:   73)\n",
            "car: 96%\t(left_x: 1564   top_y:  168   width:  180   height:   81)\n",
            "person: 97%\t(left_x: 1601   top_y:  146   width:  146   height:  256)\n",
            "car: 86%\t(left_x: 1724   top_y:  164   width:   84   height:   55)\n",
            "person: 26%\t(left_x: 1788   top_y:  149   width:   31   height:   59)\n",
            "car: 98%\t(left_x: 1828   top_y:  151   width:   94   height:   79)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/210.jpg: Predicted in 54.825000 milli-seconds.\n",
            "person: 33%\t(left_x:  308   top_y:  176   width:   27   height:   56)\n",
            "person: 96%\t(left_x:  558   top_y:  196   width:   47   height:  133)\n",
            "person: 78%\t(left_x:  626   top_y:  198   width:   54   height:  164)\n",
            "person: 96%\t(left_x:  663   top_y:  192   width:   48   height:  141)\n",
            "car: 30%\t(left_x:  720   top_y:  197   width:   58   height:   17)\n",
            "car: 79%\t(left_x: 1020   top_y:  201   width:  101   height:   50)\n",
            "car: 70%\t(left_x: 1094   top_y:  198   width:   57   height:   40)\n",
            "car: 45%\t(left_x: 1111   top_y:  196   width:  134   height:   78)\n",
            "car: 74%\t(left_x: 1220   top_y:  192   width:   73   height:   59)\n",
            "person: 80%\t(left_x: 1287   top_y:  189   width:   64   height:  103)\n",
            "motorbike: 69%\t(left_x: 1288   top_y:  202   width:   64   height:   92)\n",
            "car: 74%\t(left_x: 1332   top_y:  185   width:  124   height:   64)\n",
            "motorbike: 76%\t(left_x: 1395   top_y:  211   width:   80   height:   47)\n",
            "person: 78%\t(left_x: 1405   top_y:  180   width:   56   height:   73)\n",
            "person: 38%\t(left_x: 1418   top_y:  180   width:   32   height:   57)\n",
            "car: 99%\t(left_x: 1533   top_y:  171   width:  159   height:   91)\n",
            "car: 49%\t(left_x: 1644   top_y:  174   width:   78   height:   64)\n",
            "car: 27%\t(left_x: 1681   top_y:  175   width:   41   height:   64)\n",
            "person: 98%\t(left_x: 1701   top_y:  148   width:  117   height:  277)\n",
            "car: 99%\t(left_x: 1804   top_y:  159   width:  115   height:   84)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/211.jpg: Predicted in 54.885000 milli-seconds.\n",
            "person: 31%\t(left_x:  496   top_y:  213   width:   38   height:  101)\n",
            "person: 94%\t(left_x:  521   top_y:  197   width:   45   height:  140)\n",
            "person: 90%\t(left_x:  619   top_y:  205   width:   67   height:  163)\n",
            "car: 27%\t(left_x:  695   top_y:  199   width:   59   height:   17)\n",
            "car: 87%\t(left_x: 1039   top_y:  200   width:  106   height:   49)\n",
            "motorbike: 67%\t(left_x: 1178   top_y:  232   width:   87   height:   79)\n",
            "person: 36%\t(left_x: 1182   top_y:  204   width:   51   height:   94)\n",
            "person: 65%\t(left_x: 1198   top_y:  196   width:   58   height:   98)\n",
            "person: 47%\t(left_x: 1237   top_y:  193   width:   37   height:   79)\n",
            "car: 25%\t(left_x: 1246   top_y:  194   width:   61   height:   60)\n",
            "car: 92%\t(left_x: 1323   top_y:  184   width:  140   height:   67)\n",
            "motorbike: 48%\t(left_x: 1436   top_y:  207   width:   70   height:   53)\n",
            "person: 33%\t(left_x: 1454   top_y:  182   width:   43   height:   72)\n",
            "car: 99%\t(left_x: 1503   top_y:  173   width:  161   height:   94)\n",
            "car: 52%\t(left_x: 1632   top_y:  174   width:   65   height:   67)\n",
            "car: 68%\t(left_x: 1646   top_y:  172   width:   75   height:   61)\n",
            "car: 71%\t(left_x: 1673   top_y:  174   width:   83   height:   54)\n",
            "car: 48%\t(left_x: 1776   top_y:  165   width:  124   height:   79)\n",
            "car: 30%\t(left_x: 1778   top_y:  189   width:   37   height:   58)\n",
            "person: 99%\t(left_x: 1789   top_y:  143   width:  132   height:  293)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/212.jpg: Predicted in 54.815000 milli-seconds.\n",
            "person: 99%\t(left_x:  466   top_y:  193   width:   58   height:  149)\n",
            "person: 98%\t(left_x:  571   top_y:  190   width:   44   height:  153)\n",
            "person: 96%\t(left_x:  620   top_y:  200   width:   50   height:  172)\n",
            "motorbike: 79%\t(left_x: 1035   top_y:  241   width:  101   height:   95)\n",
            "person: 84%\t(left_x: 1047   top_y:  187   width:   79   height:  127)\n",
            "car: 37%\t(left_x: 1094   top_y:  197   width:   53   height:   47)\n",
            "car: 34%\t(left_x: 1111   top_y:  191   width:   84   height:   66)\n",
            "motorbike: 28%\t(left_x: 1137   top_y:  205   width:   90   height:   74)\n",
            "motorbike: 26%\t(left_x: 1176   top_y:  220   width:   54   height:   56)\n",
            "car: 62%\t(left_x: 1202   top_y:  193   width:   80   height:   59)\n",
            "person: 59%\t(left_x: 1263   top_y:  186   width:   47   height:   73)\n",
            "car: 99%\t(left_x: 1320   top_y:  183   width:  151   height:   69)\n",
            "car: 100%\t(left_x: 1461   top_y:  176   width:  164   height:   98)\n",
            "car: 98%\t(left_x: 1604   top_y:  175   width:   68   height:   70)\n",
            "car: 94%\t(left_x: 1738   top_y:  163   width:  148   height:   95)\n",
            "person: 41%\t(left_x: 1743   top_y:  166   width:  167   height:   92)\n",
            "motorbike: 81%\t(left_x: 1820   top_y:  204   width:   81   height:   68)\n",
            "person: 33%\t(left_x: 1823   top_y:  200   width:   76   height:   73)\n",
            "car: 53%\t(left_x: 1883   top_y:  159   width:   38   height:   62)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/213.jpg: Predicted in 54.697000 milli-seconds.\n",
            "person: 99%\t(left_x:  417   top_y:  194   width:   52   height:  152)\n",
            "person: 99%\t(left_x:  512   top_y:  198   width:   73   height:  145)\n",
            "person: 98%\t(left_x:  609   top_y:  199   width:   57   height:  166)\n",
            "motorbike: 69%\t(left_x:  825   top_y:  266   width:  145   height:  100)\n",
            "person: 88%\t(left_x:  846   top_y:  208   width:   85   height:  137)\n",
            "person: 39%\t(left_x:  944   top_y:  202   width:   26   height:   38)\n",
            "car: 74%\t(left_x: 1063   top_y:  201   width:   68   height:   39)\n",
            "bicycle: 26%\t(left_x: 1094   top_y:  217   width:  125   height:   63)\n",
            "car: 83%\t(left_x: 1201   top_y:  196   width:   94   height:   56)\n",
            "car: 31%\t(left_x: 1220   top_y:  192   width:   76   height:   26)\n",
            "motorbike: 60%\t(left_x: 1280   top_y:  204   width:   60   height:   60)\n",
            "person: 41%\t(left_x: 1286   top_y:  189   width:   50   height:   72)\n",
            "car: 98%\t(left_x: 1326   top_y:  188   width:  125   height:   65)\n",
            "car: 99%\t(left_x: 1412   top_y:  181   width:  175   height:  104)\n",
            "car: 98%\t(left_x: 1556   top_y:  180   width:   96   height:   71)\n",
            "motorbike: 73%\t(left_x: 1672   top_y:  204   width:   86   height:   96)\n",
            "person: 70%\t(left_x: 1696   top_y:  164   width:   60   height:  100)\n",
            "car: 97%\t(left_x: 1742   top_y:  170   width:  108   height:   92)\n",
            "car: 43%\t(left_x: 1840   top_y:  162   width:   79   height:   79)\n",
            "car: 30%\t(left_x: 1886   top_y:  163   width:   36   height:   66)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/214.jpg: Predicted in 54.858000 milli-seconds.\n",
            "person: 99%\t(left_x:  369   top_y:  195   width:   54   height:  151)\n",
            "person: 97%\t(left_x:  462   top_y:  198   width:   73   height:  149)\n",
            "motorbike: 94%\t(left_x:  522   top_y:  280   width:  194   height:  132)\n",
            "person: 92%\t(left_x:  588   top_y:  211   width:   73   height:  156)\n",
            "car: 28%\t(left_x:  695   top_y:  196   width:   61   height:   21)\n",
            "car: 32%\t(left_x: 1019   top_y:  203   width:  108   height:   39)\n",
            "car: 68%\t(left_x: 1064   top_y:  205   width:   62   height:   36)\n",
            "car: 90%\t(left_x: 1183   top_y:  196   width:  118   height:   58)\n",
            "car: 67%\t(left_x: 1248   top_y:  193   width:   74   height:   25)\n",
            "motorbike: 46%\t(left_x: 1295   top_y:  202   width:   91   height:   63)\n",
            "car: 44%\t(left_x: 1296   top_y:  186   width:  119   height:   73)\n",
            "car: 98%\t(left_x: 1355   top_y:  187   width:  181   height:  108)\n",
            "motorbike: 95%\t(left_x: 1496   top_y:  222   width:  105   height:   97)\n",
            "person: 77%\t(left_x: 1514   top_y:  169   width:   79   height:  127)\n",
            "person: 76%\t(left_x: 1579   top_y:  174   width:   60   height:   86)\n",
            "car: 98%\t(left_x: 1642   top_y:  175   width:  174   height:  101)\n",
            "motorbike: 76%\t(left_x: 1766   top_y:  221   width:   92   height:   78)\n",
            "person: 72%\t(left_x: 1794   top_y:  161   width:   66   height:  109)\n",
            "car: 49%\t(left_x: 1848   top_y:  166   width:   64   height:   51)\n",
            "person: 67%\t(left_x: 1862   top_y:  168   width:   60   height:  101)\n",
            "car: 25%\t(left_x: 1862   top_y:  168   width:   60   height:  101)\n",
            "motorbike: 69%\t(left_x: 1863   top_y:  203   width:   57   height:   79)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/215.jpg: Predicted in 54.808000 milli-seconds.\n",
            "motorbike: 95%\t(left_x:   52   top_y:  295   width:  283   height:  173)\n",
            "person: 83%\t(left_x:  159   top_y:  215   width:   95   height:  211)\n",
            "person: 98%\t(left_x:  328   top_y:  194   width:   45   height:  148)\n",
            "person: 99%\t(left_x:  392   top_y:  194   width:   99   height:  158)\n",
            "person: 96%\t(left_x:  613   top_y:  199   width:   52   height:  167)\n",
            "car: 32%\t(left_x:  694   top_y:  197   width:   63   height:   17)\n",
            "person: 29%\t(left_x:  799   top_y:  177   width:   24   height:   36)\n",
            "car: 61%\t(left_x: 1072   top_y:  203   width:   67   height:   38)\n",
            "car: 29%\t(left_x: 1082   top_y:  199   width:  101   height:   43)\n",
            "car: 93%\t(left_x: 1192   top_y:  194   width:  117   height:   61)\n",
            "car: 34%\t(left_x: 1237   top_y:  193   width:  104   height:   52)\n",
            "car: 66%\t(left_x: 1273   top_y:  192   width:   77   height:   35)\n",
            "car: 70%\t(left_x: 1278   top_y:  189   width:  224   height:  117)\n",
            "motorbike: 86%\t(left_x: 1286   top_y:  233   width:  113   height:  125)\n",
            "person: 76%\t(left_x: 1301   top_y:  177   width:   92   height:  151)\n",
            "car: 99%\t(left_x: 1490   top_y:  185   width:  130   height:   79)\n",
            "motorbike: 98%\t(left_x: 1577   top_y:  228   width:  113   height:   95)\n",
            "person: 98%\t(left_x: 1607   top_y:  172   width:   76   height:  128)\n",
            "car: 92%\t(left_x: 1665   top_y:  180   width:  125   height:  106)\n",
            "motorbike: 72%\t(left_x: 1803   top_y:  221   width:   66   height:   76)\n",
            "person: 84%\t(left_x: 1805   top_y:  170   width:   74   height:  106)\n",
            "car: 26%\t(left_x: 1864   top_y:  174   width:   54   height:   77)\n",
            "person: 27%\t(left_x: 1897   top_y:  176   width:   24   height:   67)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/216.jpg: Predicted in 54.809000 milli-seconds.\n",
            "person: 98%\t(left_x:  288   top_y:  198   width:   67   height:  158)\n",
            "person: 99%\t(left_x:  362   top_y:  195   width:   75   height:  161)\n",
            "person: 95%\t(left_x:  621   top_y:  202   width:   51   height:  167)\n",
            "car: 41%\t(left_x:  700   top_y:  200   width:   47   height:   17)\n",
            "person: 27%\t(left_x:  756   top_y:  193   width:   18   height:   22)\n",
            "car: 25%\t(left_x:  916   top_y:  196   width:   61   height:   51)\n",
            "motorbike: 94%\t(left_x:  968   top_y:  255   width:  172   height:  153)\n",
            "car: 39%\t(left_x:  974   top_y:  201   width:   96   height:   46)\n",
            "person: 80%\t(left_x:  989   top_y:  202   width:  131   height:  184)\n",
            "car: 28%\t(left_x: 1006   top_y:  201   width:   76   height:   43)\n",
            "car: 58%\t(left_x: 1184   top_y:  191   width:   98   height:   52)\n",
            "car: 74%\t(left_x: 1197   top_y:  188   width:  276   height:  131)\n",
            "motorbike: 87%\t(left_x: 1327   top_y:  243   width:  135   height:  103)\n",
            "person: 53%\t(left_x: 1349   top_y:  181   width:  106   height:  140)\n",
            "car: 99%\t(left_x: 1479   top_y:  181   width:  132   height:   82)\n",
            "car: 99%\t(left_x: 1558   top_y:  174   width:  180   height:  121)\n",
            "person: 33%\t(left_x: 1711   top_y:  172   width:   35   height:   37)\n",
            "motorbike: 88%\t(left_x: 1726   top_y:  219   width:   76   height:   87)\n",
            "person: 57%\t(left_x: 1729   top_y:  182   width:   73   height:  110)\n",
            "motorbike: 40%\t(left_x: 1810   top_y:  205   width:   85   height:   56)\n",
            "car: 58%\t(left_x: 1817   top_y:  163   width:   99   height:   61)\n",
            "motorbike: 27%\t(left_x: 1852   top_y:  196   width:   54   height:   50)\n",
            "person: 36%\t(left_x: 1854   top_y:  169   width:   53   height:   68)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/217.jpg: Predicted in 54.753000 milli-seconds.\n",
            "person: 90%\t(left_x:  231   top_y:  204   width:   64   height:  164)\n",
            "person: 93%\t(left_x:  307   top_y:  189   width:   82   height:  173)\n",
            "motorbike: 94%\t(left_x:  441   top_y:  310   width:  286   height:  193)\n",
            "person: 28%\t(left_x:  460   top_y:  284   width:  256   height:  206)\n",
            "person: 35%\t(left_x:  514   top_y:  192   width:  150   height:  265)\n",
            "person: 84%\t(left_x:  622   top_y:  200   width:   59   height:  137)\n",
            "car: 57%\t(left_x:  707   top_y:  200   width:   75   height:   18)\n",
            "car: 56%\t(left_x:  928   top_y:  204   width:  115   height:   54)\n",
            "motorbike: 91%\t(left_x: 1006   top_y:  252   width:  181   height:  143)\n",
            "person: 85%\t(left_x: 1051   top_y:  173   width:  105   height:  194)\n",
            "car: 98%\t(left_x: 1130   top_y:  191   width:  233   height:  151)\n",
            "car: 88%\t(left_x: 1357   top_y:  182   width:  124   height:   80)\n",
            "motorbike: 38%\t(left_x: 1365   top_y:  202   width:  114   height:   60)\n",
            "car: 91%\t(left_x: 1462   top_y:  182   width:  103   height:   87)\n",
            "car: 98%\t(left_x: 1499   top_y:  174   width:  221   height:  139)\n",
            "person: 31%\t(left_x: 1518   top_y:  174   width:  209   height:  138)\n",
            "motorbike: 55%\t(left_x: 1624   top_y:  219   width:   94   height:   99)\n",
            "motorbike: 43%\t(left_x: 1823   top_y:  189   width:   51   height:   59)\n",
            "person: 68%\t(left_x: 1823   top_y:  166   width:   51   height:   78)\n",
            "car: 39%\t(left_x: 1855   top_y:  159   width:   61   height:   69)\n",
            "car: 46%\t(left_x: 1873   top_y:  159   width:   48   height:   93)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/218.jpg: Predicted in 54.915000 milli-seconds.\n",
            "person: 89%\t(left_x:  186   top_y:  220   width:   65   height:  148)\n",
            "person: 96%\t(left_x:  255   top_y:  209   width:   77   height:  174)\n",
            "person: 29%\t(left_x:  307   top_y:  189   width:   25   height:   54)\n",
            "motorbike: 97%\t(left_x:  540   top_y:  292   width:  268   height:  188)\n",
            "person: 38%\t(left_x:  624   top_y:  212   width:   47   height:   79)\n",
            "person: 82%\t(left_x:  642   top_y:  195   width:  114   height:  223)\n",
            "car: 100%\t(left_x:  926   top_y:  196   width:  314   height:  184)\n",
            "car: 94%\t(left_x: 1220   top_y:  193   width:  103   height:   62)\n",
            "car: 62%\t(left_x: 1282   top_y:  188   width:   83   height:   31)\n",
            "car: 33%\t(left_x: 1283   top_y:  190   width:   79   height:   55)\n",
            "car: 92%\t(left_x: 1335   top_y:  185   width:  139   height:   72)\n",
            "car: 92%\t(left_x: 1412   top_y:  175   width:  252   height:  147)\n",
            "motorbike: 30%\t(left_x: 1417   top_y:  179   width:  240   height:  143)\n",
            "person: 77%\t(left_x: 1422   top_y:  177   width:  233   height:  143)\n",
            "motorbike: 66%\t(left_x: 1460   top_y:  227   width:  127   height:  123)\n",
            "person: 62%\t(left_x: 1487   top_y:  170   width:   84   height:  158)\n",
            "motorbike: 38%\t(left_x: 1634   top_y:  176   width:   58   height:   73)\n",
            "person: 65%\t(left_x: 1777   top_y:  165   width:   59   height:   83)\n",
            "motorbike: 83%\t(left_x: 1779   top_y:  176   width:   56   height:   76)\n",
            "motorbike: 26%\t(left_x: 1780   top_y:  204   width:   53   height:   50)\n",
            "car: 34%\t(left_x: 1819   top_y:  151   width:   79   height:   73)\n",
            "car: 84%\t(left_x: 1843   top_y:  157   width:   77   height:   77)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/219.jpg: Predicted in 54.872000 milli-seconds.\n",
            "car: 84%\t(left_x:   16   top_y:  212   width:  820   height:  867)\n",
            "person: 80%\t(left_x:  129   top_y:  222   width:   66   height:   97)\n",
            "person: 96%\t(left_x:  201   top_y:  214   width:   56   height:  134)\n",
            "car: 30%\t(left_x:  257   top_y:  219   width:   60   height:   24)\n",
            "person: 96%\t(left_x:  633   top_y:  212   width:   55   height:  167)\n",
            "car: 100%\t(left_x:  682   top_y:  204   width:  413   height:  217)\n",
            "car: 25%\t(left_x:  710   top_y:  205   width:   73   height:   22)\n",
            "person: 25%\t(left_x: 1079   top_y:  204   width:   37   height:   56)\n",
            "car: 72%\t(left_x: 1225   top_y:  196   width:  101   height:   56)\n",
            "motorbike: 93%\t(left_x: 1273   top_y:  234   width:  156   height:  147)\n",
            "car: 38%\t(left_x: 1301   top_y:  188   width:   69   height:   34)\n",
            "person: 67%\t(left_x: 1312   top_y:  186   width:   88   height:  149)\n",
            "car: 98%\t(left_x: 1377   top_y:  179   width:  212   height:  160)\n",
            "person: 55%\t(left_x: 1608   top_y:  180   width:   48   height:   79)\n",
            "motorbike: 76%\t(left_x: 1609   top_y:  201   width:   45   height:   59)\n",
            "motorbike: 65%\t(left_x: 1731   top_y:  204   width:   58   height:   58)\n",
            "person: 93%\t(left_x: 1732   top_y:  171   width:   59   height:   87)\n",
            "truck: 34%\t(left_x: 1776   top_y:  152   width:  119   height:   69)\n",
            "car: 42%\t(left_x: 1776   top_y:  152   width:  119   height:   69)\n",
            "car: 76%\t(left_x: 1859   top_y:  169   width:   62   height:   67)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/220.jpg: Predicted in 54.801000 milli-seconds.\n",
            "car: 100%\t(left_x:   61   top_y:  144   width: 1361   height:  688)\n",
            "car: 100%\t(left_x: 1210   top_y:  185   width:  300   height:  161)\n",
            "car: 76%\t(left_x: 1475   top_y:  186   width:   52   height:   94)\n",
            "person: 65%\t(left_x: 1514   top_y:  185   width:   42   height:   72)\n",
            "person: 33%\t(left_x: 1562   top_y:  178   width:   51   height:   90)\n",
            "motorbike: 66%\t(left_x: 1564   top_y:  197   width:   48   height:   78)\n",
            "motorbike: 34%\t(left_x: 1620   top_y:  180   width:   28   height:   52)\n",
            "motorbike: 25%\t(left_x: 1633   top_y:  198   width:   57   height:   36)\n",
            "truck: 39%\t(left_x: 1679   top_y:  163   width:  139   height:   62)\n",
            "car: 64%\t(left_x: 1682   top_y:  162   width:  135   height:   64)\n",
            "person: 69%\t(left_x: 1688   top_y:  172   width:   55   height:   98)\n",
            "motorbike: 75%\t(left_x: 1690   top_y:  199   width:   52   height:   76)\n",
            "person: 52%\t(left_x: 1700   top_y:  171   width:   47   height:   74)\n",
            "motorbike: 31%\t(left_x: 1897   top_y:  190   width:   24   height:   52)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/221.jpg: Predicted in 54.842000 milli-seconds.\n",
            "motorbike: 54%\t(left_x:   -0   top_y:  563   width:  701   height:  517)\n",
            "car: 99%\t(left_x:   -0   top_y:  241   width:  551   height:  344)\n",
            "person: 92%\t(left_x:  631   top_y:  214   width:   59   height:  163)\n",
            "motorbike: 97%\t(left_x:  655   top_y:  276   width:  259   height:  228)\n",
            "person: 88%\t(left_x:  745   top_y:  192   width:  116   height:  267)\n",
            "car: 99%\t(left_x:  881   top_y:  136   width:  777   height:  448)\n",
            "car: 36%\t(left_x: 1521   top_y:  177   width:   51   height:   31)\n",
            "person: 38%\t(left_x: 1590   top_y:  175   width:   35   height:   70)\n",
            "car: 28%\t(left_x: 1620   top_y:  161   width:  111   height:   61)\n",
            "motorbike: 68%\t(left_x: 1634   top_y:  188   width:   60   height:   93)\n",
            "person: 61%\t(left_x: 1635   top_y:  173   width:   60   height:   98)\n",
            "motorbike: 43%\t(left_x: 1728   top_y:  192   width:   51   height:   27)\n",
            "person: 45%\t(left_x: 1735   top_y:  171   width:   37   height:   46)\n",
            "motorbike: 63%\t(left_x: 1858   top_y:  169   width:   61   height:   53)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/222.jpg: Predicted in 54.870000 milli-seconds.\n",
            "motorbike: 97%\t(left_x:   -4   top_y:  368   width:  461   height:  301)\n",
            "person: 90%\t(left_x:  148   top_y:  220   width:  179   height:  347)\n",
            "car: 26%\t(left_x:  366   top_y:  224   width:   45   height:   26)\n",
            "person: 94%\t(left_x:  620   top_y:  225   width:   66   height:  163)\n",
            "car: 94%\t(left_x:  783   top_y:  205   width:  409   height:  244)\n",
            "motorbike: 98%\t(left_x: 1041   top_y:  446   width:  399   height:  393)\n",
            "person: 81%\t(left_x: 1084   top_y:  171   width:  332   height:  495)\n",
            "car: 48%\t(left_x: 1264   top_y:  206   width:   43   height:   29)\n",
            "car: 100%\t(left_x: 1273   top_y:  147   width:  537   height:  331)\n",
            "car: 88%\t(left_x: 1831   top_y:  154   width:   89   height:   81)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/223.jpg: Predicted in 54.879000 milli-seconds.\n",
            "motorbike: 82%\t(left_x:   -6   top_y:  488   width:  595   height:  574)\n",
            "car: 66%\t(left_x:  467   top_y:  214   width:  566   height:  299)\n",
            "motorbike: 60%\t(left_x:  527   top_y:  347   width:  486   height:  410)\n",
            "person: 80%\t(left_x:  638   top_y:  206   width:  297   height:  417)\n",
            "car: 90%\t(left_x: 1055   top_y:  221   width:   85   height:   36)\n",
            "car: 94%\t(left_x: 1181   top_y:  208   width:  215   height:  129)\n",
            "motorbike: 78%\t(left_x: 1276   top_y:  242   width:  111   height:  112)\n",
            "person: 63%\t(left_x: 1291   top_y:  205   width:   87   height:  127)\n",
            "car: 96%\t(left_x: 1405   top_y:  194   width:  104   height:   73)\n",
            "car: 82%\t(left_x: 1462   top_y:  150   width:  449   height:  263)\n",
            "person: 43%\t(left_x: 1486   top_y:  144   width:  349   height:  305)\n",
            "motorbike: 88%\t(left_x: 1497   top_y:  337   width:  212   height:  266)\n",
            "person: 93%\t(left_x: 1526   top_y:  162   width:  202   height:  337)\n",
            "car: 47%\t(left_x: 1850   top_y:  159   width:   72   height:   64)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/224.jpg: Predicted in 54.793000 milli-seconds.\n",
            "person: 95%\t(left_x:   15   top_y:  206   width:  825   height:  872)\n",
            "car: 99%\t(left_x:  261   top_y:  232   width:  512   height:  319)\n",
            "motorbike: 35%\t(left_x:  370   top_y:  831   width:  592   height:  249)\n",
            "motorbike: 77%\t(left_x:  884   top_y:  415   width:  401   height:  348)\n",
            "car: 39%\t(left_x:  915   top_y:  217   width:   65   height:   45)\n",
            "car: 67%\t(left_x:  921   top_y:  213   width:  111   height:   59)\n",
            "person: 26%\t(left_x:  971   top_y:  214   width:   45   height:   67)\n",
            "person: 90%\t(left_x:  998   top_y:  193   width:  254   height:  464)\n",
            "car: 54%\t(left_x: 1147   top_y:  205   width:  142   height:  140)\n",
            "motorbike: 58%\t(left_x: 1184   top_y:  306   width:  241   height:  231)\n",
            "person: 55%\t(left_x: 1200   top_y:  176   width:  202   height:  292)\n",
            "car: 42%\t(left_x: 1343   top_y:  191   width:   84   height:   30)\n",
            "motorbike: 56%\t(left_x: 1364   top_y:  212   width:   95   height:  126)\n",
            "person: 56%\t(left_x: 1366   top_y:  207   width:   87   height:  131)\n",
            "person: 28%\t(left_x: 1417   top_y:  191   width:   28   height:   29)\n",
            "car: 98%\t(left_x: 1447   top_y:  191   width:  188   height:   78)\n",
            "car: 92%\t(left_x: 1623   top_y:  158   width:  302   height:  218)\n",
            "person: 26%\t(left_x: 1623   top_y:  158   width:  302   height:  218)\n",
            "motorbike: 82%\t(left_x: 1690   top_y:  297   width:  125   height:  190)\n",
            "person: 93%\t(left_x: 1711   top_y:  153   width:  144   height:  280)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/225.jpg: Predicted in 54.948000 milli-seconds.\n",
            "car: 99%\t(left_x:   -2   top_y:  253   width:  337   height:  438)\n",
            "person: 99%\t(left_x:  612   top_y:  223   width:   59   height:  163)\n",
            "car: 36%\t(left_x:  697   top_y:  215   width:   53   height:   19)\n",
            "motorbike: 98%\t(left_x:  702   top_y:  285   width:  231   height:  179)\n",
            "person: 67%\t(left_x:  774   top_y:  213   width:  101   height:  192)\n",
            "motorbike: 91%\t(left_x:  869   top_y:  521   width:  521   height:  565)\n",
            "car: 27%\t(left_x:  911   top_y:  197   width:   58   height:   50)\n",
            "car: 28%\t(left_x:  950   top_y:  212   width:   36   height:   51)\n",
            "car: 66%\t(left_x:  953   top_y:  211   width:  100   height:   60)\n",
            "person: 99%\t(left_x:  995   top_y:  163   width:  394   height:  773)\n",
            "car: 27%\t(left_x: 1183   top_y:  209   width:   51   height:   87)\n",
            "motorbike: 85%\t(left_x: 1222   top_y:  224   width:  109   height:  144)\n",
            "person: 66%\t(left_x: 1232   top_y:  186   width:   92   height:  166)\n",
            "person: 57%\t(left_x: 1234   top_y:  183   width:   85   height:  107)\n",
            "car: 29%\t(left_x: 1234   top_y:  183   width:   85   height:  108)\n",
            "car: 94%\t(left_x: 1297   top_y:  204   width:   99   height:   63)\n",
            "person: 44%\t(left_x: 1347   top_y:  191   width:   24   height:   24)\n",
            "person: 49%\t(left_x: 1376   top_y:  191   width:   49   height:   63)\n",
            "motorbike: 70%\t(left_x: 1378   top_y:  208   width:   51   height:   52)\n",
            "person: 41%\t(left_x: 1380   top_y:  192   width:   30   height:   34)\n",
            "motorbike: 93%\t(left_x: 1389   top_y:  299   width:  241   height:  267)\n",
            "person: 96%\t(left_x: 1451   top_y:  172   width:  172   height:  319)\n",
            "person: 28%\t(left_x: 1550   top_y:  185   width:   82   height:  106)\n",
            "car: 92%\t(left_x: 1576   top_y:  187   width:  111   height:   75)\n",
            "car: 80%\t(left_x: 1787   top_y:  147   width:  134   height:  192)\n",
            "motorbike: 70%\t(left_x: 1827   top_y:  245   width:   94   height:  176)\n",
            "person: 43%\t(left_x: 1843   top_y:  175   width:   77   height:  194)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/226.jpg: Predicted in 54.874000 milli-seconds.\n",
            "motorbike: 98%\t(left_x:   85   top_y:  331   width:  398   height:  225)\n",
            "person: 73%\t(left_x:  215   top_y:  228   width:  135   height:  260)\n",
            "car: 33%\t(left_x:  465   top_y:  206   width:  104   height:   29)\n",
            "person: 99%\t(left_x:  662   top_y:  214   width:   55   height:  162)\n",
            "car: 58%\t(left_x:  747   top_y:  207   width:   58   height:   19)\n",
            "car: 90%\t(left_x:  869   top_y:  204   width:  346   height:  192)\n",
            "motorbike: 81%\t(left_x: 1045   top_y:  234   width:  154   height:  195)\n",
            "person: 69%\t(left_x: 1096   top_y:  207   width:   87   height:  166)\n",
            "car: 59%\t(left_x: 1245   top_y:  188   width:   86   height:   48)\n",
            "car: 29%\t(left_x: 1287   top_y:  191   width:   75   height:   50)\n",
            "car: 99%\t(left_x: 1307   top_y:  191   width:  171   height:   69)\n",
            "motorbike: 84%\t(left_x: 1357   top_y:  487   width:  279   height:  320)\n",
            "person: 99%\t(left_x: 1391   top_y:  133   width:  290   height:  554)\n",
            "car: 95%\t(left_x: 1559   top_y:  176   width:  206   height:   81)\n",
            "motorbike: 96%\t(left_x: 1701   top_y:  274   width:  180   height:  198)\n",
            "person: 95%\t(left_x: 1721   top_y:  156   width:  178   height:  241)\n",
            "car: 48%\t(left_x: 1860   top_y:  148   width:   62   height:   93)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/227.jpg: Predicted in 54.903000 milli-seconds.\n",
            "person: 75%\t(left_x:  519   top_y:  204   width:  526   height:  877)\n",
            "motorbike: 85%\t(left_x:  779   top_y:  257   width:  204   height:  209)\n",
            "car: 96%\t(left_x:  898   top_y:  212   width:  201   height:  179)\n",
            "car: 33%\t(left_x: 1108   top_y:  188   width:   59   height:   73)\n",
            "person: 66%\t(left_x: 1109   top_y:  184   width:   43   height:   84)\n",
            "car: 48%\t(left_x: 1134   top_y:  192   width:   74   height:   51)\n",
            "motorbike: 42%\t(left_x: 1247   top_y:  222   width:   53   height:   56)\n",
            "person: 26%\t(left_x: 1265   top_y:  182   width:   33   height:   48)\n",
            "car: 88%\t(left_x: 1340   top_y:  187   width:   77   height:   43)\n",
            "car: 99%\t(left_x: 1373   top_y:  182   width:  177   height:   74)\n",
            "person: 34%\t(left_x: 1534   top_y:  172   width:   28   height:   42)\n",
            "car: 49%\t(left_x: 1556   top_y:  173   width:  114   height:   68)\n",
            "car: 71%\t(left_x: 1558   top_y:  174   width:  296   height:   73)\n",
            "person: 96%\t(left_x: 1598   top_y:  123   width:  234   height:  421)\n",
            "motorbike: 89%\t(left_x: 1603   top_y:  406   width:  160   height:  224)\n",
            "car: 91%\t(left_x: 1743   top_y:  166   width:  137   height:   84)\n",
            "car: 51%\t(left_x: 1813   top_y:  153   width:  109   height:   57)\n",
            "car: 59%\t(left_x: 1886   top_y:  169   width:   35   height:   68)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/228.jpg: Predicted in 54.827000 milli-seconds.\n",
            "motorbike: 95%\t(left_x:  178   top_y:  319   width:  400   height:  283)\n",
            "person: 68%\t(left_x:  289   top_y:  212   width:  167   height:  301)\n",
            "car: 94%\t(left_x:  426   top_y:  210   width:  508   height:  256)\n",
            "person: 46%\t(left_x:  989   top_y:  185   width:   50   height:   72)\n",
            "motorbike: 80%\t(left_x: 1074   top_y:  455   width:  423   height:  425)\n",
            "car: 28%\t(left_x: 1118   top_y:  182   width:   60   height:   83)\n",
            "person: 80%\t(left_x: 1132   top_y:  183   width:   39   height:   86)\n",
            "person: 90%\t(left_x: 1194   top_y:  181   width:  297   height:  491)\n",
            "car: 89%\t(left_x: 1361   top_y:  187   width:   88   height:   47)\n",
            "car: 100%\t(left_x: 1412   top_y:  185   width:  185   height:   75)\n",
            "person: 33%\t(left_x: 1574   top_y:  173   width:   25   height:   38)\n",
            "car: 96%\t(left_x: 1594   top_y:  172   width:  128   height:   76)\n",
            "car: 90%\t(left_x: 1674   top_y:  175   width:  251   height:   77)\n",
            "person: 99%\t(left_x: 1712   top_y:  141   width:  191   height:  329)\n",
            "motorbike: 94%\t(left_x: 1714   top_y:  348   width:  133   height:  190)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/229.jpg: Predicted in 54.958000 milli-seconds.\n",
            "car: 99%\t(left_x:    5   top_y:  201   width:  682   height:  316)\n",
            "car: 41%\t(left_x:  611   top_y:  167   width:   48   height:   28)\n",
            "person: 96%\t(left_x:  685   top_y:  180   width:   53   height:  165)\n",
            "car: 36%\t(left_x:  764   top_y:  171   width:   68   height:   19)\n",
            "person: 81%\t(left_x:  998   top_y:  157   width:   31   height:   71)\n",
            "car: 51%\t(left_x: 1072   top_y:  164   width:   75   height:   57)\n",
            "person: 92%\t(left_x: 1160   top_y:  161   width:   37   height:   86)\n",
            "car: 25%\t(left_x: 1251   top_y:  160   width:   81   height:   57)\n",
            "motorbike: 58%\t(left_x: 1290   top_y:  180   width:   89   height:   51)\n",
            "person: 56%\t(left_x: 1325   top_y:  161   width:   43   height:   66)\n",
            "person: 34%\t(left_x: 1333   top_y:  161   width:   24   height:   39)\n",
            "car: 95%\t(left_x: 1391   top_y:  160   width:   99   height:   51)\n",
            "motorbike: 88%\t(left_x: 1416   top_y:  340   width:  256   height:  312)\n",
            "car: 96%\t(left_x: 1445   top_y:  153   width:  216   height:   83)\n",
            "person: 94%\t(left_x: 1460   top_y:  136   width:  233   height:  393)\n",
            "car: 96%\t(left_x: 1619   top_y:  147   width:  135   height:   73)\n",
            "car: 94%\t(left_x: 1723   top_y:  144   width:  146   height:   88)\n",
            "motorbike: 89%\t(left_x: 1795   top_y:  296   width:  120   height:  155)\n",
            "person: 97%\t(left_x: 1805   top_y:  115   width:  117   height:  304)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/230.jpg: Predicted in 54.695000 milli-seconds.\n",
            "motorbike: 31%\t(left_x:   21   top_y:  308   width:  862   height:  786)\n",
            "person: 88%\t(left_x:   21   top_y:  216   width:  854   height:  857)\n",
            "person: 99%\t(left_x:  666   top_y:  137   width:   53   height:  164)\n",
            "car: 31%\t(left_x:  740   top_y:  130   width:   73   height:   16)\n",
            "car: 35%\t(left_x:  979   top_y:  124   width:  121   height:   60)\n",
            "person: 79%\t(left_x:  998   top_y:  116   width:   31   height:   68)\n",
            "person: 27%\t(left_x: 1182   top_y:  115   width:   75   height:  100)\n",
            "motorbike: 35%\t(left_x: 1213   top_y:  152   width:   78   height:   61)\n",
            "car: 79%\t(left_x: 1239   top_y:  116   width:  122   height:   64)\n",
            "motorbike: 80%\t(left_x: 1340   top_y:  139   width:   63   height:   50)\n",
            "person: 56%\t(left_x: 1351   top_y:  117   width:   48   height:   66)\n",
            "car: 86%\t(left_x: 1400   top_y:  118   width:  100   height:   52)\n",
            "car: 99%\t(left_x: 1471   top_y:  112   width:  204   height:   83)\n",
            "motorbike: 93%\t(left_x: 1580   top_y:  256   width:  192   height:  242)\n",
            "person: 93%\t(left_x: 1610   top_y:   92   width:  183   height:  318)\n",
            "car: 98%\t(left_x: 1739   top_y:   97   width:  182   height:   97)\n",
            "motorbike: 87%\t(left_x: 1862   top_y:  221   width:   58   height:  140)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/231.jpg: Predicted in 54.894000 milli-seconds.\n",
            "motorbike: 76%\t(left_x:   -6   top_y:  346   width:  599   height:  638)\n",
            "person: 66%\t(left_x:   -5   top_y:  123   width:  380   height:  690)\n",
            "person: 99%\t(left_x:  664   top_y:  135   width:   56   height:  169)\n",
            "car: 53%\t(left_x:  746   top_y:  131   width:   62   height:   18)\n",
            "suitcase: 42%\t(left_x:  827   top_y:  358   width:  316   height:  258)\n",
            "car: 38%\t(left_x:  964   top_y:  118   width:   48   height:   53)\n",
            "car: 65%\t(left_x:  989   top_y:  119   width:   86   height:   71)\n",
            "person: 38%\t(left_x:  989   top_y:  119   width:   86   height:   71)\n",
            "person: 91%\t(left_x:  990   top_y:  161   width:  375   height:  642)\n",
            "person: 93%\t(left_x: 1007   top_y:  113   width:   33   height:   90)\n",
            "car: 37%\t(left_x: 1061   top_y:  134   width:   62   height:   35)\n",
            "person: 59%\t(left_x: 1112   top_y:  132   width:   26   height:   35)\n",
            "person: 31%\t(left_x: 1139   top_y:  125   width:   27   height:   44)\n",
            "person: 27%\t(left_x: 1159   top_y:  125   width:   24   height:   45)\n",
            "motorbike: 28%\t(left_x: 1228   top_y:  154   width:   54   height:   56)\n",
            "car: 94%\t(left_x: 1268   top_y:  116   width:  137   height:   63)\n",
            "motorbike: 30%\t(left_x: 1378   top_y:  134   width:   60   height:   54)\n",
            "person: 36%\t(left_x: 1389   top_y:  118   width:   34   height:   64)\n",
            "person: 28%\t(left_x: 1394   top_y:  115   width:   23   height:   44)\n",
            "motorbike: 30%\t(left_x: 1395   top_y:  135   width:   65   height:   52)\n",
            "person: 28%\t(left_x: 1410   top_y:  122   width:   48   height:   60)\n",
            "motorbike: 41%\t(left_x: 1420   top_y:  135   width:   56   height:   47)\n",
            "motorbike: 42%\t(left_x: 1438   top_y:  123   width:   41   height:   57)\n",
            "person: 41%\t(left_x: 1438   top_y:  123   width:   41   height:   57)\n",
            "car: 59%\t(left_x: 1455   top_y:  117   width:   98   height:   45)\n",
            "car: 99%\t(left_x: 1523   top_y:  108   width:  248   height:   91)\n",
            "motorbike: 86%\t(left_x: 1698   top_y:  240   width:  175   height:  184)\n",
            "person: 97%\t(left_x: 1729   top_y:   96   width:  165   height:  275)\n",
            "truck: 34%\t(left_x: 1840   top_y:  101   width:   82   height:   90)\n",
            "car: 54%\t(left_x: 1841   top_y:   99   width:   81   height:   95)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/232.jpg: Predicted in 54.900000 milli-seconds.\n",
            "person: 98%\t(left_x:  667   top_y:  133   width:   54   height:  173)\n",
            "car: 30%\t(left_x:  671   top_y:  120   width:   52   height:   32)\n",
            "motorbike: 99%\t(left_x:  675   top_y:  313   width:  399   height:  348)\n",
            "person: 96%\t(left_x:  745   top_y:  109   width:  270   height:  439)\n",
            "car: 36%\t(left_x:  747   top_y:  130   width:   54   height:   20)\n",
            "person: 58%\t(left_x: 1019   top_y:  121   width:   30   height:   78)\n",
            "car: 95%\t(left_x: 1061   top_y:  134   width:  118   height:   47)\n",
            "motorbike: 69%\t(left_x: 1154   top_y:  149   width:  129   height:   64)\n",
            "person: 51%\t(left_x: 1167   top_y:  118   width:  103   height:   93)\n",
            "motorbike: 28%\t(left_x: 1271   top_y:  378   width:  259   height:  293)\n",
            "car: 95%\t(left_x: 1281   top_y:  114   width:  154   height:   65)\n",
            "motorbike: 68%\t(left_x: 1287   top_y:  180   width:  341   height:  489)\n",
            "suitcase: 58%\t(left_x: 1314   top_y:  254   width:  188   height:  149)\n",
            "person: 89%\t(left_x: 1386   top_y:  125   width:  227   height:  417)\n",
            "person: 43%\t(left_x: 1435   top_y:  112   width:   25   height:   38)\n",
            "car: 91%\t(left_x: 1456   top_y:  113   width:  145   height:   49)\n",
            "car: 41%\t(left_x: 1535   top_y:  110   width:   73   height:   25)\n",
            "car: 98%\t(left_x: 1589   top_y:  103   width:  264   height:   96)\n",
            "car: 75%\t(left_x: 1807   top_y:   96   width:  103   height:   63)\n",
            "motorbike: 93%\t(left_x: 1808   top_y:  227   width:  110   height:  147)\n",
            "person: 68%\t(left_x: 1842   top_y:   78   width:   77   height:  212)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/233.jpg: Predicted in 54.842000 milli-seconds.\n",
            "motorbike: 74%\t(left_x:  132   top_y:  371   width:  761   height:  558)\n",
            "person: 97%\t(left_x:  404   top_y:  144   width:  356   height:  538)\n",
            "person: 97%\t(left_x:  670   top_y:  135   width:   50   height:  173)\n",
            "car: 54%\t(left_x:  692   top_y:  121   width:   55   height:   32)\n",
            "car: 41%\t(left_x:  756   top_y:  132   width:   64   height:   18)\n",
            "person: 87%\t(left_x: 1024   top_y:  116   width:   35   height:   91)\n",
            "car: 96%\t(left_x: 1091   top_y:  132   width:  102   height:   49)\n",
            "motorbike: 98%\t(left_x: 1107   top_y:  243   width:  243   height:  270)\n",
            "person: 98%\t(left_x: 1147   top_y:   98   width:  203   height:  329)\n",
            "motorbike: 71%\t(left_x: 1261   top_y:  139   width:   73   height:   49)\n",
            "person: 40%\t(left_x: 1269   top_y:  121   width:   52   height:   62)\n",
            "car: 81%\t(left_x: 1318   top_y:  112   width:  109   height:   67)\n",
            "motorbike: 75%\t(left_x: 1409   top_y:  135   width:  107   height:   55)\n",
            "person: 35%\t(left_x: 1409   top_y:  117   width:   98   height:   70)\n",
            "person: 60%\t(left_x: 1413   top_y:  114   width:   39   height:   70)\n",
            "car: 89%\t(left_x: 1489   top_y:  115   width:  117   height:   48)\n",
            "motorbike: 71%\t(left_x: 1518   top_y:  195   width:  238   height:  320)\n",
            "person: 90%\t(left_x: 1578   top_y:  112   width:  176   height:  323)\n",
            "car: 95%\t(left_x: 1675   top_y:  102   width:  212   height:   99)\n",
            "motorbike: 90%\t(left_x: 1847   top_y:  132   width:   75   height:  107)\n",
            "person: 68%\t(left_x: 1859   top_y:   84   width:   62   height:  133)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/20210112_173758/234.jpg: Predicted in 54.790000 milli-seconds.\n",
            "person: 96%\t(left_x:  673   top_y:  141   width:   56   height:  165)\n",
            "truck: 31%\t(left_x:  678   top_y:  121   width:  102   height:   32)\n",
            "motorbike: 86%\t(left_x:  927   top_y:  360   width:  351   height:  280)\n",
            "person: 98%\t(left_x: 1036   top_y:  108   width:  220   height:  396)\n",
            "car: 79%\t(left_x: 1130   top_y:  134   width:   71   height:   50)\n",
            "motorbike: 40%\t(left_x: 1171   top_y:  154   width:  117   height:   61)\n",
            "motorbike: 41%\t(left_x: 1242   top_y:  150   width:   59   height:   62)\n",
            "person: 40%\t(left_x: 1267   top_y:  115   width:   34   height:   65)\n",
            "person: 35%\t(left_x: 1293   top_y:  122   width:   31   height:   56)\n",
            "person: 34%\t(left_x: 1317   top_y:  123   width:   24   height:   55)\n",
            "motorbike: 80%\t(left_x: 1326   top_y:  144   width:   62   height:   45)\n",
            "person: 58%\t(left_x: 1329   top_y:  120   width:   45   height:   64)\n",
            "car: 44%\t(left_x: 1363   top_y:  114   width:   90   height:   41)\n",
            "motorbike: 93%\t(left_x: 1377   top_y:  232   width:  176   height:  191)\n",
            "motorbike: 27%\t(left_x: 1400   top_y:  133   width:   35   height:   62)\n",
            "person: 98%\t(left_x: 1409   top_y:  106   width:  150   height:  263)\n",
            "motorbike: 35%\t(left_x: 1507   top_y:  129   width:   52   height:   67)\n",
            "car: 50%\t(left_x: 1523   top_y:  116   width:   97   height:   42)\n",
            "motorbike: 55%\t(left_x: 1610   top_y:  117   width:   80   height:   66)\n",
            "person: 45%\t(left_x: 1614   top_y:  112   width:   75   height:   68)\n",
            "person: 31%\t(left_x: 1634   top_y:  107   width:   31   height:   61)\n",
            "motorbike: 28%\t(left_x: 1647   top_y:  116   width:   61   height:   66)\n",
            "motorbike: 69%\t(left_x: 1666   top_y:  185   width:  174   height:  254)\n",
            "car: 46%\t(left_x: 1689   top_y:  109   width:  205   height:   92)\n",
            "person: 47%\t(left_x: 1702   top_y:   98   width:   28   height:   39)\n",
            "person: 30%\t(left_x: 1704   top_y:   87   width:  104   height:   99)\n",
            "person: 73%\t(left_x: 1714   top_y:  112   width:  154   height:  265)\n",
            "motorbike: 74%\t(left_x: 1858   top_y:  138   width:   62   height:   79)\n",
            "person: 71%\t(left_x: 1861   top_y:   86   width:   60   height:  125)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/1.jpg: Predicted in 54.647000 milli-seconds.\n",
            "car: 96%\t(left_x:    3   top_y:  283   width:  418   height:  376)\n",
            "car: 64%\t(left_x:   46   top_y:  254   width:  155   height:   63)\n",
            "truck: 53%\t(left_x:   51   top_y:  255   width:  149   height:   55)\n",
            "car: 87%\t(left_x:  417   top_y:  274   width:   95   height:   44)\n",
            "traffic light: 89%\t(left_x:  543   top_y:  247   width:   11   height:   22)\n",
            "car: 94%\t(left_x:  547   top_y:  285   width:   66   height:   29)\n",
            "car: 32%\t(left_x:  801   top_y:  280   width:   66   height:   14)\n",
            "car: 28%\t(left_x:  889   top_y:  287   width:   64   height:   17)\n",
            "car: 26%\t(left_x:  941   top_y:  286   width:   24   height:   12)\n",
            "person: 92%\t(left_x:  957   top_y:  280   width:   49   height:   67)\n",
            "motorbike: 93%\t(left_x:  967   top_y:  319   width:   36   height:   38)\n",
            "car: 51%\t(left_x:  987   top_y:  277   width:   63   height:   50)\n",
            "motorbike: 47%\t(left_x: 1030   top_y:  309   width:   24   height:   32)\n",
            "motorbike: 27%\t(left_x: 1033   top_y:  294   width:   27   height:   46)\n",
            "person: 58%\t(left_x: 1034   top_y:  283   width:   24   height:   50)\n",
            "person: 30%\t(left_x: 1056   top_y:  290   width:   21   height:   21)\n",
            "person: 39%\t(left_x: 1057   top_y:  289   width:   19   height:   36)\n",
            "person: 42%\t(left_x: 1071   top_y:  287   width:   23   height:   42)\n",
            "motorbike: 81%\t(left_x: 1072   top_y:  300   width:   20   height:   37)\n",
            "person: 26%\t(left_x: 1094   top_y:  290   width:   24   height:   22)\n",
            "motorbike: 33%\t(left_x: 1095   top_y:  293   width:   21   height:   22)\n",
            "person: 29%\t(left_x: 1112   top_y:  290   width:   31   height:   38)\n",
            "motorbike: 78%\t(left_x: 1116   top_y:  299   width:   27   height:   38)\n",
            "bus: 35%\t(left_x: 1143   top_y:  271   width:  111   height:   36)\n",
            "motorbike: 30%\t(left_x: 1143   top_y:  297   width:   17   height:   16)\n",
            "person: 58%\t(left_x: 1146   top_y:  291   width:   17   height:   20)\n",
            "person: 43%\t(left_x: 1161   top_y:  289   width:   21   height:   20)\n",
            "motorbike: 42%\t(left_x: 1168   top_y:  306   width:   19   height:   20)\n",
            "person: 60%\t(left_x: 1170   top_y:  290   width:   23   height:   35)\n",
            "motorbike: 55%\t(left_x: 1193   top_y:  297   width:   36   height:   62)\n",
            "person: 51%\t(left_x: 1194   top_y:  292   width:   41   height:   57)\n",
            "car: 35%\t(left_x: 1252   top_y:  320   width:   28   height:  138)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/2.jpg: Predicted in 54.869000 milli-seconds.\n",
            "car: 100%\t(left_x:   -7   top_y:  279   width:  623   height:  261)\n",
            "motorbike: 47%\t(left_x:    1   top_y:  285   width:  117   height:   59)\n",
            "car: 49%\t(left_x:   32   top_y:  264   width:  155   height:   53)\n",
            "truck: 32%\t(left_x:   32   top_y:  264   width:  154   height:   53)\n",
            "person: 33%\t(left_x:  230   top_y:  258   width:   14   height:   32)\n",
            "car: 86%\t(left_x:  417   top_y:  275   width:   81   height:   36)\n",
            "car: 98%\t(left_x:  517   top_y:  284   width:   80   height:   32)\n",
            "traffic light: 83%\t(left_x:  540   top_y:  245   width:   11   height:   25)\n",
            "car: 60%\t(left_x:  782   top_y:  274   width:  101   height:   25)\n",
            "car: 48%\t(left_x:  939   top_y:  277   width:   25   height:   13)\n",
            "car: 36%\t(left_x:  962   top_y:  263   width:   47   height:   30)\n",
            "person: 90%\t(left_x:  998   top_y:  270   width:   50   height:   56)\n",
            "motorbike: 47%\t(left_x: 1000   top_y:  290   width:   50   height:   50)\n",
            "motorbike: 58%\t(left_x: 1008   top_y:  305   width:   33   height:   36)\n",
            "person: 36%\t(left_x: 1039   top_y:  273   width:   27   height:   31)\n",
            "person: 30%\t(left_x: 1045   top_y:  274   width:   25   height:   45)\n",
            "motorbike: 40%\t(left_x: 1046   top_y:  293   width:   26   height:   34)\n",
            "person: 33%\t(left_x: 1057   top_y:  275   width:   21   height:   43)\n",
            "person: 31%\t(left_x: 1060   top_y:  274   width:   23   height:   32)\n",
            "person: 29%\t(left_x: 1074   top_y:  276   width:   17   height:   24)\n",
            "motorbike: 32%\t(left_x: 1085   top_y:  275   width:   23   height:   47)\n",
            "person: 57%\t(left_x: 1085   top_y:  270   width:   26   height:   41)\n",
            "motorbike: 77%\t(left_x: 1087   top_y:  290   width:   19   height:   33)\n",
            "car: 63%\t(left_x: 1118   top_y:  295   width:  162   height:  305)\n",
            "truck: 25%\t(left_x: 1118   top_y:  295   width:  162   height:  305)\n",
            "person: 45%\t(left_x: 1127   top_y:  275   width:   26   height:   29)\n",
            "person: 44%\t(left_x: 1127   top_y:  280   width:   25   height:   39)\n",
            "motorbike: 85%\t(left_x: 1128   top_y:  289   width:   25   height:   32)\n",
            "car: 45%\t(left_x: 1168   top_y:  278   width:   31   height:   25)\n",
            "person: 30%\t(left_x: 1168   top_y:  278   width:   31   height:   25)\n",
            "motorbike: 35%\t(left_x: 1176   top_y:  283   width:   23   height:   28)\n",
            "motorbike: 72%\t(left_x: 1190   top_y:  281   width:   38   height:   58)\n",
            "person: 62%\t(left_x: 1192   top_y:  280   width:   36   height:   56)\n",
            "motorbike: 25%\t(left_x: 1195   top_y:  303   width:   41   height:   34)\n",
            "car: 58%\t(left_x: 1222   top_y:  277   width:   36   height:   44)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/3.jpg: Predicted in 54.705000 milli-seconds.\n",
            "motorbike: 76%\t(left_x:   -2   top_y:  385   width:  283   height:  273)\n",
            "car: 95%\t(left_x:   -1   top_y:  246   width:  285   height:  175)\n",
            "person: 53%\t(left_x:  174   top_y:  281   width:   14   height:   19)\n",
            "person: 53%\t(left_x:  187   top_y:  279   width:   19   height:   23)\n",
            "car: 100%\t(left_x:  299   top_y:  275   width:  420   height:  190)\n",
            "traffic light: 75%\t(left_x:  532   top_y:  242   width:   10   height:   23)\n",
            "bus: 31%\t(left_x:  563   top_y:  262   width:  100   height:   29)\n",
            "traffic light: 28%\t(left_x:  778   top_y:  168   width:   16   height:   16)\n",
            "car: 67%\t(left_x:  912   top_y:  279   width:   43   height:   15)\n",
            "car: 35%\t(left_x:  957   top_y:  279   width:   20   height:   16)\n",
            "car: 96%\t(left_x: 1005   top_y:  255   width:  276   height:  338)\n",
            "car: 63%\t(left_x: 1016   top_y:  272   width:   49   height:   46)\n",
            "person: 30%\t(left_x: 1019   top_y:  269   width:   58   height:   53)\n",
            "motorbike: 35%\t(left_x: 1027   top_y:  292   width:   54   height:   44)\n",
            "motorbike: 59%\t(left_x: 1033   top_y:  304   width:   37   height:   32)\n",
            "motorbike: 33%\t(left_x: 1057   top_y:  292   width:   25   height:   34)\n",
            "person: 42%\t(left_x: 1059   top_y:  276   width:   23   height:   45)\n",
            "person: 47%\t(left_x: 1086   top_y:  271   width:   26   height:   39)\n",
            "motorbike: 56%\t(left_x: 1087   top_y:  284   width:   22   height:   28)\n",
            "car: 52%\t(left_x: 1103   top_y:  276   width:   27   height:   24)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/4.jpg: Predicted in 54.809000 milli-seconds.\n",
            "car: 31%\t(left_x:   -3   top_y:  269   width:  105   height:   37)\n",
            "car: 88%\t(left_x:   -0   top_y:  287   width:   50   height:   60)\n",
            "car: 100%\t(left_x:   34   top_y:  265   width:  363   height:  163)\n",
            "motorbike: 95%\t(left_x:  342   top_y:  391   width:  216   height:  155)\n",
            "person: 93%\t(left_x:  375   top_y:  274   width:  159   height:  202)\n",
            "car: 98%\t(left_x:  457   top_y:  289   width:   68   height:   37)\n",
            "car: 100%\t(left_x:  501   top_y:  286   width:  285   height:  149)\n",
            "traffic light: 65%\t(left_x:  518   top_y:  251   width:   12   height:   22)\n",
            "bus: 65%\t(left_x:  522   top_y:  270   width:  108   height:   50)\n",
            "car: 31%\t(left_x:  736   top_y:  281   width:   56   height:   20)\n",
            "traffic light: 34%\t(left_x:  763   top_y:  174   width:   16   height:   17)\n",
            "car: 25%\t(left_x:  781   top_y:  277   width:   75   height:   26)\n",
            "car: 27%\t(left_x:  794   top_y:  276   width:   39   height:   14)\n",
            "car: 37%\t(left_x:  901   top_y:  282   width:   42   height:   14)\n",
            "car: 99%\t(left_x:  943   top_y:  257   width:  336   height:  266)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/5.jpg: Predicted in 53.563000 milli-seconds.\n",
            "truck: 83%\t(left_x:   -5   top_y:  261   width:  117   height:   79)\n",
            "car: 84%\t(left_x:   -1   top_y:  288   width:   53   height:   55)\n",
            "person: 45%\t(left_x:  138   top_y:  281   width:   24   height:   42)\n",
            "person: 69%\t(left_x:  191   top_y:  261   width:   15   height:   35)\n",
            "car: 100%\t(left_x:  258   top_y:  262   width:  309   height:  134)\n",
            "person: 44%\t(left_x:  524   top_y:  278   width:   19   height:   26)\n",
            "car: 37%\t(left_x:  540   top_y:  285   width:   53   height:   62)\n",
            "motorbike: 83%\t(left_x:  565   top_y:  359   width:  122   height:  108)\n",
            "person: 99%\t(left_x:  574   top_y:  262   width:  104   height:  166)\n",
            "car: 99%\t(left_x:  642   top_y:  278   width:  191   height:  130)\n",
            "car: 30%\t(left_x:  779   top_y:  276   width:   72   height:   25)\n",
            "car: 36%\t(left_x:  883   top_y:  279   width:   44   height:   16)\n",
            "car: 99%\t(left_x:  895   top_y:  262   width:  388   height:  224)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/6.jpg: Predicted in 53.628000 milli-seconds.\n",
            "truck: 70%\t(left_x:   -1   top_y:  262   width:   89   height:   75)\n",
            "car: 87%\t(left_x:   -1   top_y:  309   width:  182   height:  167)\n",
            "motorbike: 28%\t(left_x:   -1   top_y:  294   width:   23   height:   43)\n",
            "motorbike: 72%\t(left_x:   -0   top_y:  411   width:  251   height:  290)\n",
            "person: 56%\t(left_x:  131   top_y:  290   width:   19   height:   17)\n",
            "person: 45%\t(left_x:  182   top_y:  259   width:   13   height:   28)\n",
            "car: 55%\t(left_x:  344   top_y:  276   width:   68   height:   24)\n",
            "car: 53%\t(left_x:  376   top_y:  287   width:   50   height:   28)\n",
            "car: 99%\t(left_x:  409   top_y:  267   width:  241   height:  113)\n",
            "traffic light: 31%\t(left_x:  499   top_y:  248   width:   11   height:   20)\n",
            "motorbike: 85%\t(left_x:  671   top_y:  351   width:   68   height:   76)\n",
            "person: 98%\t(left_x:  676   top_y:  268   width:   73   height:  125)\n",
            "car: 100%\t(left_x:  724   top_y:  284   width:  156   height:  108)\n",
            "traffic light: 35%\t(left_x:  746   top_y:  175   width:   15   height:   17)\n",
            "car: 100%\t(left_x:  884   top_y:  269   width:  307   height:  194)\n",
            "car: 71%\t(left_x: 1168   top_y:  286   width:   34   height:   44)\n",
            "car: 92%\t(left_x: 1195   top_y:  292   width:   86   height:  156)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/7.jpg: Predicted in 46.675000 milli-seconds.\n",
            "car: 88%\t(left_x:   -7   top_y:  271   width:  319   height:  224)\n",
            "motorbike: 97%\t(left_x:  188   top_y:  399   width:  355   height:  223)\n",
            "person: 88%\t(left_x:  282   top_y:  256   width:  211   height:  297)\n",
            "car: 70%\t(left_x:  378   top_y:  279   width:   57   height:   33)\n",
            "bus: 79%\t(left_x:  383   top_y:  255   width:  139   height:   55)\n",
            "person: 68%\t(left_x:  453   top_y:  279   width:   29   height:   33)\n",
            "car: 83%\t(left_x:  483   top_y:  280   width:   54   height:   33)\n",
            "traffic light: 75%\t(left_x:  494   top_y:  240   width:   10   height:   20)\n",
            "car: 99%\t(left_x:  522   top_y:  262   width:  190   height:   96)\n",
            "person: 97%\t(left_x:  728   top_y:  268   width:   56   height:   94)\n",
            "motorbike: 81%\t(left_x:  729   top_y:  332   width:   45   height:   60)\n",
            "traffic light: 53%\t(left_x:  738   top_y:  165   width:   18   height:   20)\n",
            "car: 99%\t(left_x:  769   top_y:  276   width:  130   height:   88)\n",
            "car: 100%\t(left_x:  878   top_y:  261   width:  234   height:  174)\n",
            "motorbike: 36%\t(left_x: 1107   top_y:  284   width:   24   height:   31)\n",
            "car: 36%\t(left_x: 1131   top_y:  280   width:   39   height:   63)\n",
            "person: 75%\t(left_x: 1131   top_y:  278   width:   36   height:   63)\n",
            "motorbike: 67%\t(left_x: 1132   top_y:  308   width:   37   height:   41)\n",
            "car: 94%\t(left_x: 1189   top_y:  289   width:   92   height:  152)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/8.jpg: Predicted in 45.912000 milli-seconds.\n",
            "truck: 36%\t(left_x:   -1   top_y:  240   width:   30   height:   83)\n",
            "car: 100%\t(left_x:   87   top_y:  261   width:  421   height:  178)\n",
            "person: 60%\t(left_x:   95   top_y:  264   width:   31   height:   28)\n",
            "person: 51%\t(left_x:  174   top_y:  243   width:   14   height:   28)\n",
            "bus: 40%\t(left_x:  336   top_y:  246   width:  147   height:   54)\n",
            "bus: 54%\t(left_x:  338   top_y:  248   width:  146   height:   29)\n",
            "person: 72%\t(left_x:  438   top_y:  270   width:   23   height:   35)\n",
            "car: 91%\t(left_x:  456   top_y:  273   width:   68   height:   32)\n",
            "traffic light: 67%\t(left_x:  495   top_y:  235   width:    9   height:   20)\n",
            "motorbike: 93%\t(left_x:  503   top_y:  347   width:  221   height:  193)\n",
            "car: 77%\t(left_x:  521   top_y:  278   width:   32   height:   18)\n",
            "person: 87%\t(left_x:  555   top_y:  256   width:  144   height:  226)\n",
            "car: 98%\t(left_x:  621   top_y:  258   width:  148   height:   82)\n",
            "traffic light: 28%\t(left_x:  739   top_y:  159   width:   17   height:   31)\n",
            "traffic light: 36%\t(left_x:  740   top_y:  160   width:   16   height:   18)\n",
            "motorbike: 88%\t(left_x:  766   top_y:  312   width:   42   height:   53)\n",
            "person: 97%\t(left_x:  768   top_y:  263   width:   51   height:   75)\n",
            "car: 98%\t(left_x:  805   top_y:  271   width:  101   height:   76)\n",
            "car: 99%\t(left_x:  883   top_y:  256   width:  179   height:  146)\n",
            "car: 38%\t(left_x: 1042   top_y:  268   width:   50   height:   36)\n",
            "motorbike: 32%\t(left_x: 1045   top_y:  270   width:   47   height:   33)\n",
            "motorbike: 66%\t(left_x: 1112   top_y:  275   width:   25   height:   31)\n",
            "motorbike: 78%\t(left_x: 1132   top_y:  276   width:   39   height:   67)\n",
            "person: 74%\t(left_x: 1133   top_y:  271   width:   37   height:   60)\n",
            "car: 43%\t(left_x: 1163   top_y:  273   width:   35   height:   54)\n",
            "car: 94%\t(left_x: 1192   top_y:  279   width:   88   height:  156)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/9.jpg: Predicted in 45.861000 milli-seconds.\n",
            "motorbike: 47%\t(left_x:   -0   top_y:  290   width:   50   height:   34)\n",
            "person: 78%\t(left_x:    9   top_y:  267   width:   40   height:   57)\n",
            "car: 96%\t(left_x:   44   top_y:  271   width:  143   height:   45)\n",
            "motorbike: 86%\t(left_x:  182   top_y:  346   width:  214   height:  131)\n",
            "person: 51%\t(left_x:  223   top_y:  306   width:  154   height:  123)\n",
            "bus: 36%\t(left_x:  285   top_y:  247   width:  163   height:   45)\n",
            "car: 100%\t(left_x:  312   top_y:  264   width:  297   height:  145)\n",
            "traffic light: 65%\t(left_x:  489   top_y:  234   width:   12   height:   23)\n",
            "car: 77%\t(left_x:  673   top_y:  261   width:   85   height:   73)\n",
            "car: 30%\t(left_x:  682   top_y:  261   width:  129   height:   73)\n",
            "motorbike: 94%\t(left_x:  689   top_y:  358   width:  147   height:  128)\n",
            "person: 95%\t(left_x:  719   top_y:  256   width:   83   height:  191)\n",
            "traffic light: 37%\t(left_x:  735   top_y:  163   width:   16   height:   17)\n",
            "car: 32%\t(left_x:  779   top_y:  268   width:   28   height:   19)\n",
            "person: 85%\t(left_x:  797   top_y:  264   width:   40   height:   63)\n",
            "car: 97%\t(left_x:  838   top_y:  273   width:   72   height:   71)\n",
            "car: 94%\t(left_x:  888   top_y:  265   width:  147   height:  121)\n",
            "motorbike: 36%\t(left_x: 1019   top_y:  275   width:   24   height:   27)\n",
            "motorbike: 48%\t(left_x: 1051   top_y:  274   width:   35   height:   30)\n",
            "motorbike: 27%\t(left_x: 1069   top_y:  287   width:   24   height:   18)\n",
            "person: 34%\t(left_x: 1073   top_y:  272   width:   20   height:   31)\n",
            "person: 26%\t(left_x: 1091   top_y:  269   width:   17   height:   24)\n",
            "motorbike: 28%\t(left_x: 1113   top_y:  275   width:   20   height:   30)\n",
            "person: 60%\t(left_x: 1128   top_y:  276   width:   38   height:   63)\n",
            "motorbike: 69%\t(left_x: 1129   top_y:  296   width:   40   height:   47)\n",
            "car: 92%\t(left_x: 1184   top_y:  285   width:   95   height:  153)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/10.jpg: Predicted in 42.225000 milli-seconds.\n",
            "car: 99%\t(left_x:    0   top_y:  270   width:  159   height:   54)\n",
            "bus: 64%\t(left_x:  229   top_y:  247   width:  165   height:   49)\n",
            "person: 47%\t(left_x:  374   top_y:  272   width:   20   height:   34)\n",
            "person: 41%\t(left_x:  386   top_y:  271   width:   22   height:   34)\n",
            "car: 92%\t(left_x:  407   top_y:  277   width:   68   height:   32)\n",
            "car: 96%\t(left_x:  441   top_y:  269   width:  232   height:  115)\n",
            "motorbike: 87%\t(left_x:  478   top_y:  327   width:  117   height:   92)\n",
            "traffic light: 82%\t(left_x:  479   top_y:  237   width:   11   height:   23)\n",
            "car: 78%\t(left_x:  505   top_y:  271   width:   93   height:  114)\n",
            "person: 91%\t(left_x:  518   top_y:  272   width:   68   height:  114)\n",
            "car: 94%\t(left_x:  721   top_y:  267   width:   97   height:   64)\n",
            "traffic light: 43%\t(left_x:  725   top_y:  164   width:   16   height:   19)\n",
            "motorbike: 84%\t(left_x:  813   top_y:  336   width:   95   height:  119)\n",
            "person: 98%\t(left_x:  818   top_y:  266   width:   93   height:  158)\n",
            "car: 60%\t(left_x:  869   top_y:  277   width:   37   height:   28)\n",
            "car: 99%\t(left_x:  881   top_y:  268   width:  130   height:  104)\n",
            "car: 69%\t(left_x: 1008   top_y:  278   width:   24   height:   27)\n",
            "car: 29%\t(left_x: 1043   top_y:  279   width:   44   height:   27)\n",
            "motorbike: 28%\t(left_x: 1046   top_y:  282   width:   42   height:   25)\n",
            "person: 31%\t(left_x: 1076   top_y:  278   width:   20   height:   26)\n",
            "person: 74%\t(left_x: 1113   top_y:  280   width:   36   height:   62)\n",
            "motorbike: 28%\t(left_x: 1113   top_y:  280   width:   36   height:   62)\n",
            "motorbike: 61%\t(left_x: 1114   top_y:  306   width:   36   height:   40)\n",
            "car: 57%\t(left_x: 1139   top_y:  279   width:   36   height:   57)\n",
            "car: 98%\t(left_x: 1169   top_y:  289   width:  111   height:  150)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/11.jpg: Predicted in 42.291000 milli-seconds.\n",
            "motorbike: 74%\t(left_x:   -1   top_y:  381   width:  228   height:  259)\n",
            "person: 60%\t(left_x:    1   top_y:  249   width:  191   height:  307)\n",
            "car: 71%\t(left_x:   30   top_y:  271   width:  113   height:   46)\n",
            "bus: 34%\t(left_x:  170   top_y:  244   width:  181   height:   37)\n",
            "car: 96%\t(left_x:  377   top_y:  276   width:   92   height:   33)\n",
            "traffic light: 89%\t(left_x:  465   top_y:  238   width:   10   height:   23)\n",
            "car: 90%\t(left_x:  478   top_y:  280   width:   48   height:   21)\n",
            "car: 93%\t(left_x:  546   top_y:  279   width:  192   height:   84)\n",
            "person: 50%\t(left_x:  572   top_y:  271   width:  159   height:   94)\n",
            "motorbike: 62%\t(left_x:  639   top_y:  312   width:   64   height:   75)\n",
            "person: 66%\t(left_x:  651   top_y:  266   width:   54   height:  107)\n",
            "traffic light: 31%\t(left_x:  709   top_y:  167   width:   19   height:   16)\n",
            "car: 87%\t(left_x:  749   top_y:  268   width:   86   height:   60)\n",
            "truck: 33%\t(left_x:  752   top_y:  268   width:   84   height:   61)\n",
            "motorbike: 72%\t(left_x:  830   top_y:  300   width:   26   height:   37)\n",
            "person: 89%\t(left_x:  831   top_y:  272   width:   31   height:   53)\n",
            "motorbike: 80%\t(left_x:  882   top_y:  341   width:   64   height:   86)\n",
            "person: 98%\t(left_x:  884   top_y:  277   width:   72   height:  115)\n",
            "car: 86%\t(left_x:  920   top_y:  267   width:   78   height:   98)\n",
            "motorbike: 27%\t(left_x: 1053   top_y:  282   width:   31   height:   27)\n",
            "person: 36%\t(left_x: 1056   top_y:  277   width:   26   height:   30)\n",
            "motorbike: 30%\t(left_x: 1096   top_y:  285   width:   39   height:   62)\n",
            "person: 66%\t(left_x: 1096   top_y:  286   width:   40   height:   57)\n",
            "motorbike: 70%\t(left_x: 1098   top_y:  308   width:   37   height:   41)\n",
            "car: 32%\t(left_x: 1126   top_y:  285   width:   30   height:   49)\n",
            "car: 97%\t(left_x: 1150   top_y:  287   width:  129   height:  155)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/12.jpg: Predicted in 41.740000 milli-seconds.\n",
            "car: 79%\t(left_x:   -1   top_y:  262   width:  124   height:   53)\n",
            "car: 56%\t(left_x:  119   top_y:  237   width:  198   height:   47)\n",
            "person: 51%\t(left_x:  348   top_y:  262   width:   18   height:   20)\n",
            "motorbike: 31%\t(left_x:  352   top_y:  344   width:   74   height:   93)\n",
            "motorbike: 75%\t(left_x:  363   top_y:  331   width:  180   height:  150)\n",
            "car: 96%\t(left_x:  369   top_y:  270   width:   60   height:   33)\n",
            "person: 78%\t(left_x:  374   top_y:  267   width:  169   height:  183)\n",
            "car: 83%\t(left_x:  476   top_y:  272   width:   53   height:   23)\n",
            "car: 99%\t(left_x:  637   top_y:  264   width:  124   height:   86)\n",
            "traffic light: 37%\t(left_x:  715   top_y:  157   width:   15   height:   18)\n",
            "motorbike: 84%\t(left_x:  745   top_y:  302   width:   46   height:   55)\n",
            "person: 93%\t(left_x:  751   top_y:  266   width:   41   height:   80)\n",
            "car: 27%\t(left_x:  753   top_y:  262   width:   32   height:   13)\n",
            "car: 90%\t(left_x:  791   top_y:  261   width:   74   height:   54)\n",
            "motorbike: 90%\t(left_x:  861   top_y:  290   width:   24   height:   31)\n",
            "person: 52%\t(left_x:  863   top_y:  262   width:   29   height:   53)\n",
            "car: 70%\t(left_x:  897   top_y:  263   width:  112   height:   77)\n",
            "person: 95%\t(left_x:  929   top_y:  259   width:   67   height:  107)\n",
            "motorbike: 87%\t(left_x:  936   top_y:  319   width:   56   height:   76)\n",
            "motorbike: 36%\t(left_x: 1011   top_y:  277   width:   21   height:   19)\n",
            "motorbike: 39%\t(left_x: 1053   top_y:  273   width:   34   height:   26)\n",
            "motorbike: 84%\t(left_x: 1100   top_y:  281   width:   38   height:   58)\n",
            "person: 57%\t(left_x: 1101   top_y:  273   width:   35   height:   56)\n",
            "car: 33%\t(left_x: 1129   top_y:  274   width:   36   height:   50)\n",
            "car: 97%\t(left_x: 1156   top_y:  270   width:  123   height:  163)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/13.jpg: Predicted in 41.748000 milli-seconds.\n",
            "motorbike: 91%\t(left_x:   -2   top_y:  300   width:  252   height:  179)\n",
            "person: 51%\t(left_x:   54   top_y:  232   width:  144   height:  197)\n",
            "person: 47%\t(left_x:  322   top_y:  256   width:   20   height:   20)\n",
            "car: 98%\t(left_x:  348   top_y:  262   width:   85   height:   34)\n",
            "traffic light: 80%\t(left_x:  454   top_y:  223   width:   11   height:   23)\n",
            "car: 86%\t(left_x:  460   top_y:  267   width:   60   height:   23)\n",
            "motorbike: 82%\t(left_x:  600   top_y:  323   width:  101   height:   92)\n",
            "person: 79%\t(left_x:  605   top_y:  255   width:   92   height:  127)\n",
            "car: 99%\t(left_x:  690   top_y:  260   width:  118   height:   71)\n",
            "motorbike: 84%\t(left_x:  798   top_y:  295   width:   30   height:   45)\n",
            "person: 94%\t(left_x:  800   top_y:  261   width:   34   height:   71)\n",
            "car: 84%\t(left_x:  818   top_y:  257   width:   65   height:   50)\n",
            "motorbike: 78%\t(left_x:  877   top_y:  285   width:   21   height:   28)\n",
            "person: 58%\t(left_x:  879   top_y:  260   width:   23   height:   52)\n",
            "car: 78%\t(left_x:  901   top_y:  258   width:   77   height:   77)\n",
            "motorbike: 55%\t(left_x:  959   top_y:  312   width:   44   height:   63)\n",
            "person: 95%\t(left_x:  960   top_y:  260   width:   54   height:   92)\n",
            "car: 27%\t(left_x: 1007   top_y:  266   width:   22   height:   25)\n",
            "car: 69%\t(left_x: 1039   top_y:  271   width:   33   height:   23)\n",
            "motorbike: 79%\t(left_x: 1087   top_y:  296   width:   35   height:   40)\n",
            "person: 80%\t(left_x: 1088   top_y:  270   width:   35   height:   58)\n",
            "car: 97%\t(left_x: 1139   top_y:  265   width:  140   height:  169)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/14.jpg: Predicted in 41.705000 milli-seconds.\n",
            "truck: 95%\t(left_x:   -5   top_y:  210   width:  319   height:  214)\n",
            "motorbike: 95%\t(left_x:  269   top_y:  320   width:  157   height:  103)\n",
            "person: 71%\t(left_x:  274   top_y:  243   width:   90   height:  153)\n",
            "person: 80%\t(left_x:  314   top_y:  242   width:  100   height:  154)\n",
            "car: 68%\t(left_x:  358   top_y:  261   width:   41   height:   34)\n",
            "traffic light: 90%\t(left_x:  428   top_y:  221   width:   11   height:   23)\n",
            "car: 68%\t(left_x:  431   top_y:  265   width:   51   height:   25)\n",
            "car: 27%\t(left_x:  624   top_y:  246   width:   40   height:   16)\n",
            "car: 34%\t(left_x:  661   top_y:  250   width:   40   height:   19)\n",
            "motorbike: 85%\t(left_x:  702   top_y:  311   width:   59   height:   71)\n",
            "person: 84%\t(left_x:  710   top_y:  257   width:   56   height:  107)\n",
            "person: 36%\t(left_x:  734   top_y:  254   width:   55   height:   88)\n",
            "person: 30%\t(left_x:  749   top_y:  257   width:   39   height:   42)\n",
            "motorbike: 43%\t(left_x:  764   top_y:  300   width:   28   height:   54)\n",
            "car: 41%\t(left_x:  779   top_y:  263   width:   37   height:   63)\n",
            "person: 31%\t(left_x:  780   top_y:  265   width:   35   height:   54)\n",
            "person: 71%\t(left_x:  808   top_y:  265   width:   33   height:   58)\n",
            "motorbike: 68%\t(left_x:  810   top_y:  289   width:   25   height:   40)\n",
            "car: 83%\t(left_x:  818   top_y:  259   width:   65   height:   47)\n",
            "car: 92%\t(left_x:  889   top_y:  262   width:   78   height:   67)\n",
            "motorbike: 81%\t(left_x:  951   top_y:  306   width:   46   height:   55)\n",
            "person: 84%\t(left_x:  956   top_y:  261   width:   46   height:   80)\n",
            "car: 39%\t(left_x:  991   top_y:  271   width:   25   height:   20)\n",
            "car: 74%\t(left_x: 1013   top_y:  275   width:   38   height:   20)\n",
            "motorbike: 77%\t(left_x: 1055   top_y:  297   width:   35   height:   40)\n",
            "person: 77%\t(left_x: 1056   top_y:  272   width:   33   height:   58)\n",
            "car: 27%\t(left_x: 1081   top_y:  275   width:   32   height:   28)\n",
            "car: 98%\t(left_x: 1106   top_y:  260   width:  174   height:  180)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/15.jpg: Predicted in 41.653000 milli-seconds.\n",
            "truck: 80%\t(left_x:    8   top_y:  204   width:  419   height:  154)\n",
            "motorbike: 92%\t(left_x:   41   top_y:  320   width:  274   height:  212)\n",
            "person: 93%\t(left_x:  108   top_y:  211   width:  169   height:  269)\n",
            "truck: 34%\t(left_x:  203   top_y:  209   width:  223   height:  156)\n",
            "traffic light: 60%\t(left_x:  374   top_y:  209   width:   12   height:   15)\n",
            "motorbike: 86%\t(left_x:  409   top_y:  305   width:  114   height:   78)\n",
            "person: 64%\t(left_x:  414   top_y:  244   width:   68   height:  106)\n",
            "person: 70%\t(left_x:  456   top_y:  256   width:   59   height:  102)\n",
            "traffic light: 51%\t(left_x:  628   top_y:  144   width:   18   height:   19)\n",
            "person: 91%\t(left_x:  733   top_y:  252   width:   59   height:   88)\n",
            "car: 28%\t(left_x:  733   top_y:  252   width:   59   height:   88)\n",
            "motorbike: 57%\t(left_x:  736   top_y:  299   width:   44   height:   55)\n",
            "motorbike: 60%\t(left_x:  781   top_y:  284   width:   38   height:   55)\n",
            "person: 37%\t(left_x:  785   top_y:  262   width:   30   height:   70)\n",
            "car: 87%\t(left_x:  790   top_y:  253   width:   63   height:   45)\n",
            "car: 87%\t(left_x:  850   top_y:  257   width:   85   height:   64)\n",
            "person: 94%\t(left_x:  914   top_y:  258   width:   47   height:   78)\n",
            "motorbike: 77%\t(left_x:  920   top_y:  299   width:   36   height:   49)\n",
            "car: 72%\t(left_x:  962   top_y:  268   width:   37   height:   23)\n",
            "person: 77%\t(left_x:  998   top_y:  268   width:   31   height:   60)\n",
            "motorbike: 55%\t(left_x: 1000   top_y:  296   width:   34   height:   37)\n",
            "car: 97%\t(left_x: 1044   top_y:  252   width:  238   height:  191)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/16.jpg: Predicted in 41.732000 milli-seconds.\n",
            "person: 56%\t(left_x:   -2   top_y:  210   width:  175   height:  301)\n",
            "motorbike: 46%\t(left_x:   -1   top_y:  402   width:  179   height:  211)\n",
            "truck: 92%\t(left_x:  132   top_y:  207   width:  366   height:  151)\n",
            "motorbike: 86%\t(left_x:  392   top_y:  334   width:  137   height:  104)\n",
            "person: 83%\t(left_x:  409   top_y:  232   width:  114   height:  173)\n",
            "motorbike: 88%\t(left_x:  532   top_y:  296   width:   69   height:   66)\n",
            "person: 36%\t(left_x:  534   top_y:  241   width:   64   height:   99)\n",
            "person: 83%\t(left_x:  560   top_y:  238   width:   48   height:  107)\n",
            "car: 94%\t(left_x:  741   top_y:  254   width:   55   height:   48)\n",
            "motorbike: 79%\t(left_x:  780   top_y:  283   width:   41   height:   52)\n",
            "person: 70%\t(left_x:  781   top_y:  252   width:   38   height:   71)\n",
            "person: 34%\t(left_x:  804   top_y:  252   width:   26   height:   57)\n",
            "car: 28%\t(left_x:  808   top_y:  248   width:   40   height:   38)\n",
            "motorbike: 86%\t(left_x:  834   top_y:  287   width:   31   height:   35)\n",
            "person: 71%\t(left_x:  836   top_y:  260   width:   33   height:   56)\n",
            "truck: 31%\t(left_x:  857   top_y:  249   width:   84   height:   58)\n",
            "car: 65%\t(left_x:  861   top_y:  250   width:   68   height:   59)\n",
            "person: 92%\t(left_x:  917   top_y:  255   width:   36   height:   67)\n",
            "motorbike: 75%\t(left_x:  918   top_y:  287   width:   33   height:   45)\n",
            "car: 90%\t(left_x:  953   top_y:  258   width:   37   height:   26)\n",
            "person: 77%\t(left_x:  987   top_y:  262   width:   32   height:   55)\n",
            "motorbike: 57%\t(left_x:  987   top_y:  288   width:   26   height:   38)\n",
            "car: 94%\t(left_x: 1034   top_y:  233   width:  244   height:  205)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/17.jpg: Predicted in 41.162000 milli-seconds.\n",
            "car: 41%\t(left_x:   -2   top_y:  234   width:   92   height:   36)\n",
            "car: 42%\t(left_x:   -1   top_y:  311   width:   44   height:  195)\n",
            "car: 93%\t(left_x:  215   top_y:  252   width:   79   height:   35)\n",
            "truck: 90%\t(left_x:  287   top_y:  218   width:  285   height:  129)\n",
            "motorbike: 85%\t(left_x:  367   top_y:  337   width:  149   height:  131)\n",
            "traffic light: 75%\t(left_x:  367   top_y:  211   width:    9   height:   20)\n",
            "person: 96%\t(left_x:  406   top_y:  235   width:  108   height:  179)\n",
            "motorbike: 75%\t(left_x:  586   top_y:  309   width:   81   height:   86)\n",
            "person: 97%\t(left_x:  596   top_y:  239   width:   69   height:  139)\n",
            "traffic light: 29%\t(left_x:  618   top_y:  181   width:   16   height:   15)\n",
            "traffic light: 51%\t(left_x:  620   top_y:  143   width:   16   height:   20)\n",
            "person: 34%\t(left_x:  639   top_y:  241   width:   43   height:  101)\n",
            "motorbike: 46%\t(left_x:  657   top_y:  292   width:   26   height:   49)\n",
            "car: 44%\t(left_x:  752   top_y:  256   width:   35   height:   16)\n",
            "car: 93%\t(left_x:  775   top_y:  255   width:   58   height:   44)\n",
            "person: 67%\t(left_x:  825   top_y:  251   width:   42   height:   60)\n",
            "motorbike: 74%\t(left_x:  826   top_y:  284   width:   36   height:   42)\n",
            "car: 31%\t(left_x:  850   top_y:  253   width:   27   height:   32)\n",
            "car: 25%\t(left_x:  873   top_y:  252   width:   47   height:   50)\n",
            "motorbike: 33%\t(left_x:  873   top_y:  267   width:   29   height:   38)\n",
            "motorbike: 30%\t(left_x:  896   top_y:  267   width:   42   height:   48)\n",
            "motorbike: 78%\t(left_x:  898   top_y:  283   width:   32   height:   32)\n",
            "person: 38%\t(left_x:  898   top_y:  256   width:   31   height:   47)\n",
            "person: 54%\t(left_x:  929   top_y:  252   width:   33   height:   60)\n",
            "motorbike: 77%\t(left_x:  932   top_y:  285   width:   28   height:   41)\n",
            "car: 84%\t(left_x:  962   top_y:  256   width:   37   height:   27)\n",
            "motorbike: 34%\t(left_x:  991   top_y:  263   width:   33   height:   57)\n",
            "person: 66%\t(left_x:  992   top_y:  259   width:   31   height:   60)\n",
            "motorbike: 45%\t(left_x:  993   top_y:  286   width:   30   height:   38)\n",
            "car: 97%\t(left_x: 1041   top_y:  230   width:  239   height:  203)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/18.jpg: Predicted in 41.506000 milli-seconds.\n",
            "motorbike: 63%\t(left_x:   -3   top_y:  394   width:  305   height:  234)\n",
            "car: 64%\t(left_x:    0   top_y:  194   width:  291   height:  241)\n",
            "truck: 28%\t(left_x:    1   top_y:  195   width:  290   height:  239)\n",
            "car: 69%\t(left_x:  196   top_y:  249   width:   69   height:   29)\n",
            "car: 87%\t(left_x:  256   top_y:  250   width:   60   height:   33)\n",
            "car: 89%\t(left_x:  307   top_y:  242   width:   84   height:   42)\n",
            "traffic light: 88%\t(left_x:  361   top_y:  210   width:   11   height:   24)\n",
            "truck: 94%\t(left_x:  387   top_y:  225   width:  218   height:  114)\n",
            "motorbike: 76%\t(left_x:  577   top_y:  322   width:   86   height:   83)\n",
            "person: 98%\t(left_x:  592   top_y:  243   width:   76   height:  134)\n",
            "person: 46%\t(left_x:  687   top_y:  250   width:   66   height:   98)\n",
            "motorbike: 70%\t(left_x:  694   top_y:  295   width:   56   height:   68)\n",
            "car: 97%\t(left_x:  791   top_y:  252   width:   60   height:   42)\n",
            "person: 31%\t(left_x:  835   top_y:  251   width:   24   height:   45)\n",
            "person: 84%\t(left_x:  848   top_y:  250   width:   41   height:   56)\n",
            "motorbike: 87%\t(left_x:  849   top_y:  280   width:   36   height:   36)\n",
            "car: 26%\t(left_x:  882   top_y:  262   width:   47   height:   35)\n",
            "car: 60%\t(left_x:  886   top_y:  250   width:   57   height:   23)\n",
            "person: 68%\t(left_x:  927   top_y:  252   width:   35   height:   55)\n",
            "motorbike: 73%\t(left_x:  929   top_y:  280   width:   31   height:   40)\n",
            "car: 47%\t(left_x:  963   top_y:  255   width:   32   height:   24)\n",
            "person: 62%\t(left_x:  985   top_y:  256   width:   32   height:   62)\n",
            "motorbike: 65%\t(left_x:  986   top_y:  258   width:   35   height:   63)\n",
            "motorbike: 31%\t(left_x:  987   top_y:  285   width:   32   height:   39)\n",
            "car: 97%\t(left_x: 1033   top_y:  233   width:  248   height:  192)\n",
            "car: 29%\t(left_x: 1118   top_y:  258   width:   40   height:   23)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/19.jpg: Predicted in 41.191000 milli-seconds.\n",
            "truck: 30%\t(left_x:   -1   top_y:  192   width:  463   height:  286)\n",
            "car: 81%\t(left_x:    1   top_y:  191   width:  458   height:  288)\n",
            "car: 27%\t(left_x:  352   top_y:  238   width:   42   height:   27)\n",
            "traffic light: 76%\t(left_x:  364   top_y:  207   width:   11   height:   27)\n",
            "motorbike: 94%\t(left_x:  402   top_y:  325   width:  169   height:  148)\n",
            "person: 83%\t(left_x:  453   top_y:  241   width:   99   height:  177)\n",
            "truck: 62%\t(left_x:  554   top_y:  227   width:  114   height:  100)\n",
            "traffic light: 27%\t(left_x:  617   top_y:  140   width:   17   height:   16)\n",
            "motorbike: 95%\t(left_x:  692   top_y:  299   width:   52   height:   70)\n",
            "person: 97%\t(left_x:  696   top_y:  243   width:   52   height:  107)\n",
            "person: 26%\t(left_x:  734   top_y:  247   width:   42   height:   61)\n",
            "motorbike: 64%\t(left_x:  742   top_y:  279   width:   36   height:   41)\n",
            "person: 46%\t(left_x:  774   top_y:  258   width:   45   height:   80)\n",
            "motorbike: 77%\t(left_x:  778   top_y:  291   width:   39   height:   52)\n",
            "person: 43%\t(left_x:  784   top_y:  284   width:   34   height:   53)\n",
            "car: 77%\t(left_x:  814   top_y:  249   width:   62   height:   41)\n",
            "person: 76%\t(left_x:  876   top_y:  246   width:   37   height:   47)\n",
            "motorbike: 83%\t(left_x:  880   top_y:  272   width:   32   height:   35)\n",
            "car: 32%\t(left_x:  906   top_y:  249   width:   46   height:   21)\n",
            "person: 55%\t(left_x:  935   top_y:  249   width:   32   height:   56)\n",
            "motorbike: 77%\t(left_x:  938   top_y:  277   width:   26   height:   37)\n",
            "person: 28%\t(left_x:  968   top_y:  251   width:   27   height:   42)\n",
            "motorbike: 59%\t(left_x:  987   top_y:  259   width:   36   height:   59)\n",
            "person: 62%\t(left_x:  990   top_y:  252   width:   32   height:   58)\n",
            "motorbike: 61%\t(left_x:  991   top_y:  279   width:   29   height:   40)\n",
            "car: 98%\t(left_x: 1039   top_y:  230   width:  241   height:  183)\n",
            "car: 32%\t(left_x: 1116   top_y:  254   width:   52   height:   26)\n",
            "car: 35%\t(left_x: 1122   top_y:  251   width:   57   height:   23)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/20.jpg: Predicted in 41.227000 milli-seconds.\n",
            "car: 97%\t(left_x:  109   top_y:  204   width:  474   height:  214)\n",
            "truck: 82%\t(left_x:  537   top_y:  230   width:  178   height:   84)\n",
            "traffic light: 26%\t(left_x:  620   top_y:  140   width:   19   height:   34)\n",
            "motorbike: 70%\t(left_x:  624   top_y:  319   width:   94   height:   90)\n",
            "person: 95%\t(left_x:  649   top_y:  250   width:   67   height:  122)\n",
            "motorbike: 76%\t(left_x:  757   top_y:  289   width:   41   height:   57)\n",
            "person: 94%\t(left_x:  758   top_y:  246   width:   44   height:   84)\n",
            "person: 30%\t(left_x:  788   top_y:  244   width:   24   height:   34)\n",
            "person: 40%\t(left_x:  790   top_y:  251   width:   26   height:   59)\n",
            "person: 70%\t(left_x:  833   top_y:  251   width:   43   height:   74)\n",
            "motorbike: 30%\t(left_x:  835   top_y:  255   width:   38   height:   71)\n",
            "motorbike: 74%\t(left_x:  836   top_y:  283   width:   37   height:   46)\n",
            "person: 45%\t(left_x:  874   top_y:  250   width:   21   height:   38)\n",
            "person: 28%\t(left_x:  875   top_y:  251   width:   21   height:   20)\n",
            "person: 63%\t(left_x:  908   top_y:  244   width:   29   height:   53)\n",
            "motorbike: 92%\t(left_x:  909   top_y:  270   width:   26   height:   34)\n",
            "person: 33%\t(left_x:  909   top_y:  246   width:   27   height:   30)\n",
            "person: 47%\t(left_x:  957   top_y:  250   width:   31   height:   59)\n",
            "motorbike: 52%\t(left_x:  964   top_y:  267   width:   63   height:   50)\n",
            "person: 33%\t(left_x:  965   top_y:  251   width:   47   height:   58)\n",
            "motorbike: 32%\t(left_x:  995   top_y:  260   width:   35   height:   57)\n",
            "person: 56%\t(left_x:  997   top_y:  252   width:   32   height:   59)\n",
            "car: 98%\t(left_x: 1043   top_y:  229   width:  238   height:  186)\n",
            "car: 51%\t(left_x: 1124   top_y:  254   width:   50   height:   29)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/21.jpg: Predicted in 41.163000 milli-seconds.\n",
            "car: 87%\t(left_x:  253   top_y:  241   width:   84   height:   44)\n",
            "car: 99%\t(left_x:  318   top_y:  218   width:  343   height:  167)\n",
            "truck: 93%\t(left_x:  589   top_y:  234   width:  156   height:   82)\n",
            "traffic light: 45%\t(left_x:  626   top_y:  142   width:   17   height:   16)\n",
            "motorbike: 69%\t(left_x:  749   top_y:  301   width:   62   height:   76)\n",
            "person: 97%\t(left_x:  754   top_y:  254   width:   52   height:  106)\n",
            "motorbike: 80%\t(left_x:  804   top_y:  283   width:   34   height:   51)\n",
            "person: 90%\t(left_x:  804   top_y:  249   width:   36   height:   80)\n",
            "car: 62%\t(left_x:  851   top_y:  254   width:   29   height:   34)\n",
            "person: 66%\t(left_x:  870   top_y:  248   width:   33   height:   67)\n",
            "motorbike: 61%\t(left_x:  871   top_y:  280   width:   35   height:   42)\n",
            "car: 61%\t(left_x:  902   top_y:  258   width:   32   height:   26)\n",
            "person: 63%\t(left_x:  933   top_y:  250   width:   25   height:   41)\n",
            "motorbike: 84%\t(left_x:  934   top_y:  273   width:   26   height:   30)\n",
            "person: 61%\t(left_x:  963   top_y:  255   width:   20   height:   36)\n",
            "car: 25%\t(left_x:  973   top_y:  257   width:   32   height:   25)\n",
            "motorbike: 32%\t(left_x:  987   top_y:  277   width:   34   height:   40)\n",
            "motorbike: 77%\t(left_x:  991   top_y:  268   width:   47   height:   51)\n",
            "person: 64%\t(left_x:  999   top_y:  254   width:   34   height:   57)\n",
            "car: 98%\t(left_x: 1048   top_y:  233   width:  231   height:  185)\n",
            "car: 34%\t(left_x: 1135   top_y:  259   width:   37   height:   19)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/22.jpg: Predicted in 41.156000 milli-seconds.\n",
            "car: 91%\t(left_x:   -1   top_y:  266   width:  210   height:  258)\n",
            "car: 86%\t(left_x:  239   top_y:  245   width:   99   height:   54)\n",
            "person: 27%\t(left_x:  335   top_y:  253   width:   19   height:   33)\n",
            "person: 47%\t(left_x:  337   top_y:  252   width:   17   height:   19)\n",
            "car: 50%\t(left_x:  355   top_y:  258   width:   83   height:   29)\n",
            "car: 31%\t(left_x:  383   top_y:  260   width:   61   height:   21)\n",
            "car: 99%\t(left_x:  456   top_y:  231   width:  269   height:  139)\n",
            "traffic light: 60%\t(left_x:  629   top_y:  144   width:   17   height:   18)\n",
            "truck: 67%\t(left_x:  693   top_y:  241   width:   74   height:   70)\n",
            "car: 48%\t(left_x:  698   top_y:  241   width:   67   height:   72)\n",
            "motorbike: 86%\t(left_x:  819   top_y:  302   width:   42   height:   56)\n",
            "person: 98%\t(left_x:  821   top_y:  256   width:   51   height:   76)\n",
            "person: 55%\t(left_x:  849   top_y:  255   width:   26   height:   67)\n",
            "person: 25%\t(left_x:  850   top_y:  254   width:   24   height:   37)\n",
            "car: 87%\t(left_x:  871   top_y:  257   width:   30   height:   30)\n",
            "motorbike: 72%\t(left_x:  893   top_y:  282   width:   30   height:   35)\n",
            "person: 72%\t(left_x:  893   top_y:  252   width:   28   height:   57)\n",
            "car: 27%\t(left_x:  916   top_y:  256   width:   24   height:   23)\n",
            "person: 26%\t(left_x:  916   top_y:  256   width:   24   height:   23)\n",
            "motorbike: 88%\t(left_x:  954   top_y:  275   width:   26   height:   28)\n",
            "person: 70%\t(left_x:  957   top_y:  255   width:   17   height:   29)\n",
            "person: 34%\t(left_x:  973   top_y:  258   width:   17   height:   25)\n",
            "car: 44%\t(left_x:  988   top_y:  259   width:   23   height:   21)\n",
            "motorbike: 55%\t(left_x: 1002   top_y:  259   width:   36   height:   63)\n",
            "person: 81%\t(left_x: 1003   top_y:  258   width:   34   height:   59)\n",
            "motorbike: 48%\t(left_x: 1003   top_y:  286   width:   37   height:   40)\n",
            "car: 98%\t(left_x: 1050   top_y:  235   width:  230   height:  189)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/23.jpg: Predicted in 41.182000 milli-seconds.\n",
            "motorbike: 74%\t(left_x:   -2   top_y:  342   width:  266   height:  269)\n",
            "person: 61%\t(left_x:    1   top_y:  222   width:  237   height:  347)\n",
            "car: 98%\t(left_x:    5   top_y:  217   width:  413   height:  222)\n",
            "car: 81%\t(left_x:  245   top_y:  247   width:   73   height:   42)\n",
            "car: 87%\t(left_x:  348   top_y:  261   width:   70   height:   29)\n",
            "traffic light: 72%\t(left_x:  383   top_y:  219   width:   11   height:   24)\n",
            "car: 79%\t(left_x:  409   top_y:  263   width:   35   height:   19)\n",
            "car: 100%\t(left_x:  558   top_y:  236   width:  215   height:  124)\n",
            "car: 71%\t(left_x:  738   top_y:  247   width:   55   height:   62)\n",
            "person: 94%\t(left_x:  862   top_y:  256   width:   42   height:   68)\n",
            "motorbike: 91%\t(left_x:  866   top_y:  292   width:   33   height:   52)\n",
            "person: 79%\t(left_x:  915   top_y:  254   width:   30   height:   50)\n",
            "motorbike: 85%\t(left_x:  916   top_y:  282   width:   27   height:   32)\n",
            "motorbike: 89%\t(left_x:  974   top_y:  273   width:   25   height:   30)\n",
            "person: 78%\t(left_x:  975   top_y:  257   width:   21   height:   26)\n",
            "car: 36%\t(left_x:  996   top_y:  260   width:   24   height:   18)\n",
            "person: 84%\t(left_x: 1008   top_y:  261   width:   33   height:   57)\n",
            "motorbike: 36%\t(left_x: 1009   top_y:  287   width:   30   height:   38)\n",
            "car: 98%\t(left_x: 1059   top_y:  237   width:  221   height:  188)\n",
            "car: 31%\t(left_x: 1145   top_y:  262   width:   44   height:   22)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/24.jpg: Predicted in 41.243000 milli-seconds.\n",
            "person: 37%\t(left_x:   -1   top_y:  253   width:   28   height:   41)\n",
            "person: 38%\t(left_x:   64   top_y:  226   width:   16   height:   33)\n",
            "car: 73%\t(left_x:   93   top_y:  228   width:  409   height:  216)\n",
            "motorbike: 81%\t(left_x:  318   top_y:  319   width:  241   height:  178)\n",
            "person: 41%\t(left_x:  375   top_y:  238   width:  146   height:  220)\n",
            "traffic light: 47%\t(left_x:  407   top_y:  217   width:   10   height:   16)\n",
            "car: 37%\t(left_x:  606   top_y:  241   width:   25   height:   15)\n",
            "car: 99%\t(left_x:  645   top_y:  240   width:  188   height:  105)\n",
            "traffic light: 50%\t(left_x:  655   top_y:  146   width:   17   height:   17)\n",
            "person: 86%\t(left_x:  901   top_y:  254   width:   43   height:   56)\n",
            "motorbike: 91%\t(left_x:  904   top_y:  285   width:   34   height:   45)\n",
            "person: 84%\t(left_x:  950   top_y:  253   width:   32   height:   51)\n",
            "motorbike: 71%\t(left_x:  955   top_y:  281   width:   26   height:   28)\n",
            "person: 61%\t(left_x: 1009   top_y:  256   width:   19   height:   28)\n",
            "motorbike: 51%\t(left_x: 1010   top_y:  274   width:   22   height:   27)\n",
            "person: 83%\t(left_x: 1033   top_y:  261   width:   33   height:   58)\n",
            "motorbike: 28%\t(left_x: 1034   top_y:  268   width:   32   height:   57)\n",
            "motorbike: 68%\t(left_x: 1036   top_y:  287   width:   26   height:   39)\n",
            "car: 38%\t(left_x: 1059   top_y:  259   width:   32   height:   59)\n",
            "car: 97%\t(left_x: 1082   top_y:  239   width:  200   height:  187)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/25.jpg: Predicted in 41.334000 milli-seconds.\n",
            "car: 68%\t(left_x:    6   top_y:  252   width:  104   height:   37)\n",
            "car: 62%\t(left_x:  202   top_y:  239   width:  110   height:   27)\n",
            "car: 99%\t(left_x:  320   top_y:  227   width:  283   height:  172)\n",
            "traffic light: 35%\t(left_x:  417   top_y:  213   width:   10   height:   16)\n",
            "motorbike: 88%\t(left_x:  578   top_y:  310   width:  134   height:  115)\n",
            "person: 91%\t(left_x:  587   top_y:  238   width:  101   height:  147)\n",
            "person: 33%\t(left_x:  625   top_y:  232   width:   73   height:  127)\n",
            "car: 28%\t(left_x:  662   top_y:  241   width:   41   height:   22)\n",
            "traffic light: 47%\t(left_x:  667   top_y:  143   width:   17   height:   16)\n",
            "car: 99%\t(left_x:  709   top_y:  239   width:  164   height:   92)\n",
            "person: 49%\t(left_x:  927   top_y:  248   width:   29   height:   60)\n",
            "motorbike: 41%\t(left_x:  928   top_y:  274   width:   26   height:   43)\n",
            "motorbike: 44%\t(left_x:  943   top_y:  273   width:   25   height:   34)\n",
            "person: 61%\t(left_x:  975   top_y:  253   width:   26   height:   34)\n",
            "motorbike: 51%\t(left_x:  982   top_y:  273   width:   21   height:   29)\n",
            "person: 41%\t(left_x:  988   top_y:  254   width:   20   height:   31)\n",
            "car: 36%\t(left_x: 1001   top_y:  258   width:   29   height:   28)\n",
            "motorbike: 38%\t(left_x: 1028   top_y:  264   width:   20   height:   31)\n",
            "person: 40%\t(left_x: 1028   top_y:  254   width:   19   height:   35)\n",
            "person: 28%\t(left_x: 1029   top_y:  253   width:   16   height:   20)\n",
            "motorbike: 68%\t(left_x: 1046   top_y:  259   width:   37   height:   62)\n",
            "person: 55%\t(left_x: 1046   top_y:  251   width:   34   height:   63)\n",
            "car: 65%\t(left_x: 1071   top_y:  254   width:   33   height:   55)\n",
            "car: 99%\t(left_x: 1095   top_y:  236   width:  185   height:  187)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/26.jpg: Predicted in 41.340000 milli-seconds.\n",
            "car: 82%\t(left_x:   -2   top_y:  319   width:  196   height:  312)\n",
            "car: 84%\t(left_x:   -0   top_y:  258   width:   84   height:   37)\n",
            "motorbike: 95%\t(left_x:  105   top_y:  301   width:  250   height:  131)\n",
            "person: 91%\t(left_x:  192   top_y:  251   width:  113   height:  142)\n",
            "car: 90%\t(left_x:  323   top_y:  260   width:   89   height:   31)\n",
            "person: 35%\t(left_x:  333   top_y:  255   width:   80   height:   36)\n",
            "car: 30%\t(left_x:  412   top_y:  254   width:   48   height:   36)\n",
            "traffic light: 73%\t(left_x:  418   top_y:  218   width:   11   height:   24)\n",
            "car: 75%\t(left_x:  418   top_y:  253   width:   67   height:   39)\n",
            "car: 100%\t(left_x:  459   top_y:  239   width:  258   height:  143)\n",
            "traffic light: 42%\t(left_x:  667   top_y:  147   width:   16   height:   17)\n",
            "person: 46%\t(left_x:  691   top_y:  243   width:   86   height:  125)\n",
            "motorbike: 82%\t(left_x:  706   top_y:  306   width:   90   height:   94)\n",
            "person: 62%\t(left_x:  737   top_y:  241   width:   55   height:  131)\n",
            "car: 96%\t(left_x:  763   top_y:  246   width:  139   height:   83)\n",
            "person: 77%\t(left_x:  937   top_y:  253   width:   29   height:   54)\n",
            "motorbike: 62%\t(left_x:  939   top_y:  278   width:   25   height:   36)\n",
            "person: 51%\t(left_x:  959   top_y:  254   width:   25   height:   33)\n",
            "motorbike: 47%\t(left_x:  960   top_y:  274   width:   20   height:   31)\n",
            "person: 33%\t(left_x:  975   top_y:  258   width:   17   height:   26)\n",
            "person: 58%\t(left_x:  991   top_y:  255   width:   23   height:   44)\n",
            "motorbike: 69%\t(left_x:  992   top_y:  277   width:   22   height:   26)\n",
            "motorbike: 28%\t(left_x: 1033   top_y:  261   width:   18   height:   34)\n",
            "person: 26%\t(left_x: 1034   top_y:  258   width:   18   height:   29)\n",
            "person: 68%\t(left_x: 1046   top_y:  257   width:   36   height:   64)\n",
            "motorbike: 34%\t(left_x: 1048   top_y:  258   width:   36   height:   64)\n",
            "motorbike: 56%\t(left_x: 1048   top_y:  287   width:   38   height:   38)\n",
            "car: 35%\t(left_x: 1072   top_y:  259   width:   34   height:   57)\n",
            "car: 98%\t(left_x: 1095   top_y:  240   width:  186   height:  184)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173626_764/27.jpg: Predicted in 41.178000 milli-seconds.\n",
            "truck: 87%\t(left_x:   -2   top_y:  234   width:  454   height:  380)\n",
            "car: 32%\t(left_x:   -0   top_y:  222   width:  453   height:  383)\n",
            "car: 80%\t(left_x:  312   top_y:  254   width:   82   height:   34)\n",
            "person: 44%\t(left_x:  324   top_y:  252   width:   44   height:   32)\n",
            "person: 30%\t(left_x:  332   top_y:  245   width:   17   height:   35)\n",
            "car: 48%\t(left_x:  349   top_y:  256   width:   48   height:   32)\n",
            "car: 48%\t(left_x:  386   top_y:  250   width:   82   height:   37)\n",
            "car: 35%\t(left_x:  412   top_y:  247   width:   67   height:   33)\n",
            "traffic light: 69%\t(left_x:  416   top_y:  210   width:   12   height:   30)\n",
            "motorbike: 92%\t(left_x:  438   top_y:  297   width:  143   height:   98)\n",
            "motorbike: 39%\t(left_x:  458   top_y:  250   width:  114   height:  128)\n",
            "person: 83%\t(left_x:  478   top_y:  243   width:   79   height:  116)\n",
            "car: 100%\t(left_x:  545   top_y:  236   width:  228   height:  124)\n",
            "person: 95%\t(left_x:  789   top_y:  243   width:   69   height:   96)\n",
            "motorbike: 85%\t(left_x:  793   top_y:  291   width:   63   height:   78)\n",
            "car: 94%\t(left_x:  827   top_y:  243   width:   91   height:   76)\n",
            "person: 79%\t(left_x:  943   top_y:  249   width:   24   height:   49)\n",
            "motorbike: 89%\t(left_x:  944   top_y:  273   width:   22   height:   31)\n",
            "motorbike: 59%\t(left_x:  972   top_y:  268   width:   19   height:   27)\n",
            "person: 48%\t(left_x:  994   top_y:  254   width:   22   height:   34)\n",
            "car: 32%\t(left_x: 1013   top_y:  259   width:   32   height:   28)\n",
            "motorbike: 71%\t(left_x: 1043   top_y:  262   width:   41   height:   59)\n",
            "person: 55%\t(left_x: 1046   top_y:  251   width:   38   height:   62)\n",
            "car: 41%\t(left_x: 1068   top_y:  253   width:   33   height:   56)\n",
            "car: 99%\t(left_x: 1095   top_y:  236   width:  186   height:  189)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/1.jpg: Predicted in 41.172000 milli-seconds.\n",
            "car: 50%\t(left_x:   -1   top_y:  261   width:   11   height:   18)\n",
            "car: 57%\t(left_x:    8   top_y:  263   width:   23   height:   14)\n",
            "person: 54%\t(left_x:   36   top_y:  265   width:   18   height:   42)\n",
            "car: 56%\t(left_x:   67   top_y:  266   width:   62   height:   40)\n",
            "car: 73%\t(left_x:  131   top_y:  269   width:   27   height:   22)\n",
            "car: 49%\t(left_x:  146   top_y:  267   width:   29   height:   29)\n",
            "car: 58%\t(left_x:  153   top_y:  268   width:   40   height:   34)\n",
            "car: 99%\t(left_x:  182   top_y:  265   width:   65   height:   43)\n",
            "bus: 53%\t(left_x:  243   top_y:  251   width:  100   height:   42)\n",
            "truck: 46%\t(left_x:  243   top_y:  251   width:  100   height:   42)\n",
            "car: 99%\t(left_x:  270   top_y:  274   width:   81   height:   38)\n",
            "person: 60%\t(left_x:  334   top_y:  270   width:   14   height:   21)\n",
            "person: 40%\t(left_x:  348   top_y:  268   width:   14   height:   25)\n",
            "truck: 79%\t(left_x:  380   top_y:  266   width:  103   height:   44)\n",
            "car: 31%\t(left_x:  382   top_y:  266   width:  100   height:   44)\n",
            "car: 99%\t(left_x:  510   top_y:  279   width:  105   height:   54)\n",
            "motorbike: 73%\t(left_x:  593   top_y:  298   width:   55   height:   37)\n",
            "person: 80%\t(left_x:  611   top_y:  275   width:   33   height:   52)\n",
            "motorbike: 95%\t(left_x:  631   top_y:  305   width:   89   height:   54)\n",
            "person: 27%\t(left_x:  638   top_y:  278   width:   14   height:   24)\n",
            "person: 76%\t(left_x:  643   top_y:  274   width:   52   height:   69)\n",
            "car: 100%\t(left_x:  768   top_y:  287   width:  504   height:  312)\n",
            "motorbike: 55%\t(left_x:  779   top_y:  290   width:   37   height:   32)\n",
            "person: 35%\t(left_x:  785   top_y:  284   width:   23   height:   36)\n",
            "car: 66%\t(left_x: 1037   top_y:  287   width:  135   height:   47)\n",
            "person: 28%\t(left_x: 1043   top_y:  280   width:   25   height:   19)\n",
            "motorbike: 64%\t(left_x: 1092   top_y:  509   width:  188   height:  216)\n",
            "car: 98%\t(left_x: 1175   top_y:  292   width:  104   height:   67)\n",
            "person: 49%\t(left_x: 1176   top_y:  290   width:   22   height:   32)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/2.jpg: Predicted in 41.273000 milli-seconds.\n",
            "person: 49%\t(left_x:   -1   top_y:  265   width:    9   height:   46)\n",
            "car: 38%\t(left_x:    0   top_y:  261   width:   26   height:   19)\n",
            "motorbike: 98%\t(left_x:   27   top_y:  330   width:  224   height:  122)\n",
            "person: 72%\t(left_x:   57   top_y:  288   width:   96   height:  130)\n",
            "car: 32%\t(left_x:   75   top_y:  267   width:   63   height:   26)\n",
            "car: 29%\t(left_x:  104   top_y:  270   width:   37   height:   23)\n",
            "person: 38%\t(left_x:  105   top_y:  284   width:   83   height:  140)\n",
            "car: 26%\t(left_x:  106   top_y:  272   width:   37   height:   31)\n",
            "car: 61%\t(left_x:  147   top_y:  268   width:   29   height:   28)\n",
            "car: 84%\t(left_x:  160   top_y:  270   width:   32   height:   32)\n",
            "car: 98%\t(left_x:  184   top_y:  266   width:   70   height:   42)\n",
            "bus: 47%\t(left_x:  225   top_y:  251   width:   83   height:   41)\n",
            "car: 99%\t(left_x:  273   top_y:  276   width:   88   height:   37)\n",
            "person: 28%\t(left_x:  343   top_y:  270   width:   17   height:   19)\n",
            "car: 61%\t(left_x:  357   top_y:  264   width:   98   height:   44)\n",
            "truck: 54%\t(left_x:  361   top_y:  265   width:   93   height:   44)\n",
            "motorbike: 87%\t(left_x:  493   top_y:  298   width:  107   height:   61)\n",
            "motorbike: 28%\t(left_x:  519   top_y:  274   width:   57   height:   71)\n",
            "person: 92%\t(left_x:  525   top_y:  274   width:   46   height:   71)\n",
            "motorbike: 73%\t(left_x:  603   top_y:  293   width:   78   height:   42)\n",
            "person: 27%\t(left_x:  623   top_y:  273   width:   23   height:   37)\n",
            "person: 69%\t(left_x:  650   top_y:  270   width:   31   height:   39)\n",
            "car: 99%\t(left_x:  862   top_y:  290   width:  414   height:  289)\n",
            "motorbike: 65%\t(left_x:  896   top_y:  299   width:   38   height:   33)\n",
            "person: 58%\t(left_x:  903   top_y:  281   width:   24   height:   38)\n",
            "car: 48%\t(left_x:  947   top_y:  288   width:   39   height:   14)\n",
            "car: 34%\t(left_x: 1024   top_y:  282   width:  102   height:   14)\n",
            "motorbike: 54%\t(left_x: 1089   top_y:  463   width:  190   height:  256)\n",
            "car: 39%\t(left_x: 1218   top_y:  288   width:   63   height:   48)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/3.jpg: Predicted in 41.183000 milli-seconds.\n",
            "car: 72%\t(left_x:   -1   top_y:  255   width:   22   height:   18)\n",
            "car: 54%\t(left_x:   62   top_y:  259   width:   32   height:   39)\n",
            "car: 56%\t(left_x:   97   top_y:  262   width:   39   height:   33)\n",
            "car: 42%\t(left_x:  142   top_y:  261   width:   35   height:   30)\n",
            "car: 76%\t(left_x:  158   top_y:  262   width:   35   height:   34)\n",
            "car: 98%\t(left_x:  182   top_y:  259   width:   67   height:   44)\n",
            "bus: 55%\t(left_x:  192   top_y:  244   width:   80   height:   40)\n",
            "motorbike: 97%\t(left_x:  264   top_y:  321   width:  215   height:  129)\n",
            "person: 76%\t(left_x:  273   top_y:  287   width:   95   height:  132)\n",
            "car: 67%\t(left_x:  274   top_y:  268   width:   94   height:   35)\n",
            "person: 52%\t(left_x:  322   top_y:  294   width:  111   height:  131)\n",
            "person: 68%\t(left_x:  364   top_y:  264   width:   43   height:   58)\n",
            "car: 54%\t(left_x:  409   top_y:  273   width:   44   height:   26)\n",
            "motorbike: 53%\t(left_x:  469   top_y:  273   width:   28   height:   32)\n",
            "car: 99%\t(left_x:  487   top_y:  273   width:  108   height:   57)\n",
            "motorbike: 68%\t(left_x:  604   top_y:  287   width:   79   height:   41)\n",
            "motorbike: 36%\t(left_x:  627   top_y:  267   width:   50   height:   59)\n",
            "person: 73%\t(left_x:  637   top_y:  265   width:   33   height:   53)\n",
            "person: 39%\t(left_x:  683   top_y:  272   width:   21   height:   30)\n",
            "motorbike: 44%\t(left_x:  856   top_y:  278   width:   64   height:   46)\n",
            "car: 99%\t(left_x:  880   top_y:  283   width:  142   height:   50)\n",
            "person: 39%\t(left_x:  902   top_y:  277   width:   20   height:   20)\n",
            "car: 97%\t(left_x:  977   top_y:  292   width:  306   height:  285)\n",
            "car: 98%\t(left_x:  994   top_y:  281   width:  136   height:   99)\n",
            "motorbike: 79%\t(left_x: 1074   top_y:  470   width:  206   height:  249)\n",
            "car: 41%\t(left_x: 1177   top_y:  281   width:  100   height:   18)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/4.jpg: Predicted in 41.267000 milli-seconds.\n",
            "car: 47%\t(left_x:   59   top_y:  256   width:   25   height:   30)\n",
            "car: 89%\t(left_x:   85   top_y:  257   width:   50   height:   33)\n",
            "motorbike: 90%\t(left_x:  107   top_y:  296   width:  130   height:   59)\n",
            "car: 39%\t(left_x:  118   top_y:  255   width:   26   height:   17)\n",
            "person: 75%\t(left_x:  143   top_y:  254   width:   65   height:   86)\n",
            "car: 26%\t(left_x:  145   top_y:  256   width:   27   height:   31)\n",
            "car: 95%\t(left_x:  184   top_y:  256   width:   58   height:   45)\n",
            "car: 97%\t(left_x:  272   top_y:  263   width:   85   height:   39)\n",
            "car: 26%\t(left_x:  293   top_y:  251   width:   69   height:   25)\n",
            "motorbike: 73%\t(left_x:  359   top_y:  278   width:   57   height:   38)\n",
            "person: 25%\t(left_x:  365   top_y:  270   width:   51   height:   40)\n",
            "car: 31%\t(left_x:  397   top_y:  267   width:   40   height:   23)\n",
            "motorbike: 38%\t(left_x:  454   top_y:  280   width:   29   height:   36)\n",
            "car: 76%\t(left_x:  473   top_y:  267   width:   82   height:   59)\n",
            "motorbike: 98%\t(left_x:  480   top_y:  330   width:  223   height:  125)\n",
            "person: 82%\t(left_x:  514   top_y:  278   width:   85   height:  145)\n",
            "car: 52%\t(left_x:  545   top_y:  270   width:   49   height:   32)\n",
            "motorbike: 77%\t(left_x:  591   top_y:  282   width:   73   height:   39)\n",
            "person: 29%\t(left_x:  592   top_y:  279   width:   69   height:   41)\n",
            "person: 33%\t(left_x:  605   top_y:  261   width:   43   height:   55)\n",
            "person: 37%\t(left_x:  610   top_y:  260   width:   32   height:   38)\n",
            "person: 41%\t(left_x:  641   top_y:  265   width:   35   height:   41)\n",
            "motorbike: 28%\t(left_x:  809   top_y:  283   width:   28   height:   34)\n",
            "car: 99%\t(left_x:  833   top_y:  276   width:  159   height:   51)\n",
            "person: 46%\t(left_x:  874   top_y:  271   width:   15   height:   17)\n",
            "person: 45%\t(left_x:  893   top_y:  271   width:   17   height:   13)\n",
            "car: 30%\t(left_x:  952   top_y:  276   width:   37   height:   13)\n",
            "car: 82%\t(left_x:  974   top_y:  279   width:   52   height:   38)\n",
            "car: 100%\t(left_x:  993   top_y:  271   width:  153   height:  126)\n",
            "motorbike: 56%\t(left_x: 1060   top_y:  462   width:  220   height:  257)\n",
            "car: 99%\t(left_x: 1122   top_y:  276   width:  139   height:   67)\n",
            "motorbike: 33%\t(left_x: 1138   top_y:  290   width:  141   height:  283)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/5.jpg: Predicted in 42.159000 milli-seconds.\n",
            "car: 95%\t(left_x:   82   top_y:  253   width:   51   height:   34)\n",
            "car: 76%\t(left_x:  145   top_y:  252   width:   32   height:   36)\n",
            "car: 72%\t(left_x:  173   top_y:  251   width:   65   height:   42)\n",
            "person: 52%\t(left_x:  174   top_y:  249   width:   64   height:   47)\n",
            "motorbike: 70%\t(left_x:  175   top_y:  278   width:   75   height:   41)\n",
            "car: 79%\t(left_x:  241   top_y:  247   width:   74   height:   34)\n",
            "car: 99%\t(left_x:  271   top_y:  259   width:   88   height:   41)\n",
            "person: 58%\t(left_x:  342   top_y:  254   width:   17   height:   29)\n",
            "motorbike: 91%\t(left_x:  355   top_y:  271   width:   59   height:   46)\n",
            "person: 53%\t(left_x:  356   top_y:  261   width:   58   height:   54)\n",
            "car: 99%\t(left_x:  458   top_y:  265   width:  100   height:   61)\n",
            "motorbike: 80%\t(left_x:  565   top_y:  277   width:   74   height:   41)\n",
            "person: 32%\t(left_x:  566   top_y:  262   width:   17   height:   36)\n",
            "motorbike: 40%\t(left_x:  593   top_y:  270   width:   43   height:   46)\n",
            "person: 56%\t(left_x:  595   top_y:  257   width:   41   height:   59)\n",
            "motorbike: 98%\t(left_x:  726   top_y:  334   width:  261   height:  145)\n",
            "backpack: 27%\t(left_x:  737   top_y:  301   width:   54   height:   61)\n",
            "person: 76%\t(left_x:  761   top_y:  274   width:  109   height:  165)\n",
            "car: 93%\t(left_x:  846   top_y:  274   width:   89   height:   45)\n",
            "motorbike: 67%\t(left_x:  913   top_y:  292   width:   82   height:   36)\n",
            "car: 72%\t(left_x:  926   top_y:  277   width:   93   height:   44)\n",
            "car: 100%\t(left_x:  992   top_y:  269   width:  176   height:  137)\n",
            "motorbike: 82%\t(left_x: 1054   top_y:  512   width:  228   height:  211)\n",
            "car: 97%\t(left_x: 1124   top_y:  275   width:   99   height:   67)\n",
            "person: 54%\t(left_x: 1206   top_y:  276   width:   21   height:   45)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/6.jpg: Predicted in 42.286000 milli-seconds.\n",
            "car: 96%\t(left_x:   83   top_y:  258   width:   58   height:   36)\n",
            "car: 78%\t(left_x:  150   top_y:  256   width:   30   height:   35)\n",
            "car: 98%\t(left_x:  173   top_y:  255   width:   72   height:   47)\n",
            "motorbike: 74%\t(left_x:  243   top_y:  289   width:   63   height:   33)\n",
            "person: 53%\t(left_x:  244   top_y:  275   width:   60   height:   46)\n",
            "car: 89%\t(left_x:  290   top_y:  262   width:   85   height:   42)\n",
            "person: 52%\t(left_x:  350   top_y:  260   width:   18   height:   21)\n",
            "car: 80%\t(left_x:  379   top_y:  268   width:   57   height:   26)\n",
            "person: 25%\t(left_x:  384   top_y:  260   width:   13   height:   15)\n",
            "motorbike: 26%\t(left_x:  446   top_y:  292   width:   24   height:   28)\n",
            "motorbike: 51%\t(left_x:  446   top_y:  277   width:   29   height:   43)\n",
            "car: 96%\t(left_x:  465   top_y:  267   width:   84   height:   70)\n",
            "motorbike: 79%\t(left_x:  551   top_y:  282   width:   69   height:   40)\n",
            "person: 33%\t(left_x:  557   top_y:  277   width:   59   height:   46)\n",
            "person: 66%\t(left_x:  560   top_y:  266   width:   13   height:   25)\n",
            "person: 51%\t(left_x:  580   top_y:  259   width:   33   height:   57)\n",
            "pottedplant: 28%\t(left_x:  659   top_y:  271   width:  110   height:   44)\n",
            "car: 98%\t(left_x:  754   top_y:  277   width:  129   height:   45)\n",
            "motorbike: 83%\t(left_x:  845   top_y:  292   width:   79   height:   36)\n",
            "person: 44%\t(left_x:  868   top_y:  274   width:   36   height:   49)\n",
            "person: 48%\t(left_x:  872   top_y:  273   width:   29   height:   31)\n",
            "person: 43%\t(left_x:  906   top_y:  269   width:   21   height:   23)\n",
            "car: 84%\t(left_x:  912   top_y:  279   width:  103   height:   46)\n",
            "car: 83%\t(left_x:  997   top_y:  272   width:  191   height:  130)\n",
            "motorbike: 83%\t(left_x: 1035   top_y:  367   width:  242   height:  144)\n",
            "person: 46%\t(left_x: 1043   top_y:  284   width:  111   height:  121)\n",
            "motorbike: 76%\t(left_x: 1056   top_y:  513   width:  224   height:  210)\n",
            "person: 70%\t(left_x: 1112   top_y:  311   width:   81   height:  157)\n",
            "car: 32%\t(left_x: 1257   top_y:  282   width:   24   height:   54)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/7.jpg: Predicted in 41.142000 milli-seconds.\n",
            "car: 44%\t(left_x:   41   top_y:  255   width:   33   height:   34)\n",
            "motorbike: 39%\t(left_x:   83   top_y:  277   width:   79   height:   44)\n",
            "car: 65%\t(left_x:   84   top_y:  254   width:   67   height:   38)\n",
            "bus: 45%\t(left_x:   86   top_y:  236   width:   69   height:   32)\n",
            "car: 83%\t(left_x:  159   top_y:  254   width:   28   height:   35)\n",
            "car: 98%\t(left_x:  177   top_y:  254   width:   75   height:   45)\n",
            "car: 80%\t(left_x:  258   top_y:  257   width:   35   height:   27)\n",
            "car: 99%\t(left_x:  288   top_y:  259   width:   87   height:   42)\n",
            "person: 59%\t(left_x:  362   top_y:  257   width:   13   height:   21)\n",
            "motorbike: 81%\t(left_x:  365   top_y:  273   width:   98   height:   44)\n",
            "person: 47%\t(left_x:  372   top_y:  266   width:   77   height:   48)\n",
            "person: 49%\t(left_x:  373   top_y:  256   width:   15   height:   23)\n",
            "motorbike: 29%\t(left_x:  421   top_y:  268   width:   53   height:   41)\n",
            "car: 29%\t(left_x:  421   top_y:  264   width:   61   height:   32)\n",
            "person: 27%\t(left_x:  422   top_y:  264   width:   56   height:   30)\n",
            "car: 96%\t(left_x:  473   top_y:  263   width:   90   height:   73)\n",
            "person: 60%\t(left_x:  546   top_y:  254   width:   30   height:   54)\n",
            "motorbike: 77%\t(left_x:  551   top_y:  278   width:   30   height:   39)\n",
            "car: 36%\t(left_x:  751   top_y:  269   width:   71   height:   38)\n",
            "car: 37%\t(left_x:  754   top_y:  269   width:   69   height:   20)\n",
            "motorbike: 81%\t(left_x:  785   top_y:  281   width:   80   height:   37)\n",
            "person: 26%\t(left_x:  798   top_y:  265   width:   62   height:   49)\n",
            "car: 94%\t(left_x:  864   top_y:  271   width:  103   height:   42)\n",
            "motorbike: 79%\t(left_x:  923   top_y:  288   width:   68   height:   35)\n",
            "person: 69%\t(left_x:  933   top_y:  269   width:   46   height:   51)\n",
            "car: 47%\t(left_x:  991   top_y:  273   width:   50   height:   54)\n",
            "car: 100%\t(left_x: 1005   top_y:  268   width:  273   height:  153)\n",
            "motorbike: 73%\t(left_x: 1056   top_y:  457   width:  224   height:  264)\n",
            "car: 54%\t(left_x: 1225   top_y:  286   width:   55   height:   55)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/8.jpg: Predicted in 41.190000 milli-seconds.\n",
            "motorbike: 47%\t(left_x:   -1   top_y:  365   width:   37   height:   82)\n",
            "car: 38%\t(left_x:   35   top_y:  253   width:   34   height:   35)\n",
            "person: 48%\t(left_x:   70   top_y:  252   width:   18   height:   40)\n",
            "car: 92%\t(left_x:   96   top_y:  254   width:   52   height:   35)\n",
            "car: 85%\t(left_x:  160   top_y:  252   width:   26   height:   37)\n",
            "car: 97%\t(left_x:  172   top_y:  251   width:   78   height:   47)\n",
            "motorbike: 81%\t(left_x:  245   top_y:  274   width:   76   height:   45)\n",
            "person: 48%\t(left_x:  250   top_y:  271   width:   58   height:   42)\n",
            "car: 63%\t(left_x:  301   top_y:  257   width:   63   height:   22)\n",
            "car: 33%\t(left_x:  304   top_y:  260   width:   74   height:   41)\n",
            "motorbike: 36%\t(left_x:  315   top_y:  272   width:   65   height:   31)\n",
            "motorbike: 61%\t(left_x:  363   top_y:  276   width:   50   height:   40)\n",
            "motorbike: 55%\t(left_x:  435   top_y:  272   width:   48   height:   49)\n",
            "car: 98%\t(left_x:  473   top_y:  262   width:  106   height:   78)\n",
            "traffic light: 29%\t(left_x:  566   top_y:  228   width:    9   height:   23)\n",
            "motorbike: 57%\t(left_x:  613   top_y:  273   width:   35   height:   32)\n",
            "person: 49%\t(left_x:  636   top_y:  259   width:   22   height:   40)\n",
            "car: 41%\t(left_x:  716   top_y:  270   width:   94   height:   42)\n",
            "motorbike: 36%\t(left_x:  750   top_y:  283   width:   61   height:   31)\n",
            "motorbike: 30%\t(left_x:  824   top_y:  264   width:  125   height:   53)\n",
            "car: 54%\t(left_x:  835   top_y:  266   width:  104   height:   51)\n",
            "person: 70%\t(left_x:  835   top_y:  265   width:  103   height:   52)\n",
            "motorbike: 65%\t(left_x:  848   top_y:  279   width:   96   height:   41)\n",
            "person: 76%\t(left_x:  871   top_y:  265   width:   49   height:   51)\n",
            "person: 27%\t(left_x:  939   top_y:  269   width:   17   height:   39)\n",
            "car: 100%\t(left_x:  948   top_y:  268   width:  135   height:   57)\n",
            "car: 100%\t(left_x: 1021   top_y:  267   width:  258   height:  166)\n",
            "motorbike: 76%\t(left_x: 1052   top_y:  458   width:  228   height:  262)\n",
            "car: 59%\t(left_x: 1242   top_y:  261   width:   39   height:   64)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/9.jpg: Predicted in 41.220000 milli-seconds.\n",
            "car: 56%\t(left_x:   35   top_y:  258   width:   48   height:   38)\n",
            "motorbike: 41%\t(left_x:   85   top_y:  286   width:   86   height:   41)\n",
            "car: 51%\t(left_x:  103   top_y:  259   width:   39   height:   27)\n",
            "motorbike: 98%\t(left_x:  103   top_y:  318   width:  241   height:  165)\n",
            "person: 43%\t(left_x:  124   top_y:  264   width:   52   height:   58)\n",
            "car: 48%\t(left_x:  126   top_y:  250   width:   46   height:   25)\n",
            "person: 64%\t(left_x:  154   top_y:  268   width:  135   height:  188)\n",
            "car: 97%\t(left_x:  167   top_y:  255   width:   88   height:   49)\n",
            "motorbike: 71%\t(left_x:  268   top_y:  279   width:   62   height:   42)\n",
            "person: 48%\t(left_x:  280   top_y:  262   width:   40   height:   54)\n",
            "car: 64%\t(left_x:  310   top_y:  264   width:   65   height:   29)\n",
            "motorbike: 85%\t(left_x:  334   top_y:  282   width:   90   height:   49)\n",
            "motorbike: 33%\t(left_x:  347   top_y:  255   width:   68   height:   71)\n",
            "person: 73%\t(left_x:  348   top_y:  255   width:   66   height:   71)\n",
            "person: 32%\t(left_x:  415   top_y:  264   width:   18   height:   27)\n",
            "car: 100%\t(left_x:  479   top_y:  267   width:  131   height:   84)\n",
            "traffic light: 38%\t(left_x:  565   top_y:  232   width:    9   height:   22)\n",
            "motorbike: 63%\t(left_x:  616   top_y:  285   width:   36   height:   31)\n",
            "person: 64%\t(left_x:  617   top_y:  263   width:   20   height:   39)\n",
            "car: 27%\t(left_x:  662   top_y:  273   width:  105   height:   30)\n",
            "motorbike: 35%\t(left_x:  742   top_y:  286   width:   38   height:   29)\n",
            "motorbike: 89%\t(left_x:  786   top_y:  290   width:   70   height:   33)\n",
            "person: 71%\t(left_x:  793   top_y:  272   width:   48   height:   49)\n",
            "person: 41%\t(left_x:  814   top_y:  267   width:   26   height:   49)\n",
            "car: 89%\t(left_x:  822   top_y:  274   width:   87   height:   43)\n",
            "car: 100%\t(left_x:  913   top_y:  270   width:  152   height:   62)\n",
            "car: 100%\t(left_x: 1045   top_y:  275   width:  235   height:  176)\n",
            "motorbike: 73%\t(left_x: 1053   top_y:  455   width:  227   height:  265)\n",
            "car: 29%\t(left_x: 1196   top_y:  262   width:   84   height:   63)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/10.jpg: Predicted in 41.307000 milli-seconds.\n",
            "car: 36%\t(left_x:   28   top_y:  260   width:   33   height:   38)\n",
            "person: 27%\t(left_x:   65   top_y:  262   width:   17   height:   36)\n",
            "car: 28%\t(left_x:   68   top_y:  260   width:   40   height:   41)\n",
            "car: 95%\t(left_x:  100   top_y:  263   width:   54   height:   36)\n",
            "car: 43%\t(left_x:  107   top_y:  253   width:   36   height:   13)\n",
            "motorbike: 67%\t(left_x:  154   top_y:  285   width:  127   height:   56)\n",
            "person: 28%\t(left_x:  170   top_y:  257   width:  100   height:   65)\n",
            "car: 46%\t(left_x:  179   top_y:  258   width:   83   height:   38)\n",
            "motorbike: 77%\t(left_x:  281   top_y:  288   width:   65   height:   32)\n",
            "person: 42%\t(left_x:  286   top_y:  279   width:   65   height:   42)\n",
            "person: 42%\t(left_x:  302   top_y:  265   width:   30   height:   28)\n",
            "car: 64%\t(left_x:  307   top_y:  269   width:   84   height:   40)\n",
            "person: 44%\t(left_x:  378   top_y:  267   width:   17   height:   27)\n",
            "motorbike: 31%\t(left_x:  396   top_y:  273   width:   24   height:   28)\n",
            "person: 27%\t(left_x:  398   top_y:  267   width:   19   height:   30)\n",
            "motorbike: 99%\t(left_x:  452   top_y:  362   width:  277   height:  172)\n",
            "car: 95%\t(left_x:  490   top_y:  274   width:  159   height:   81)\n",
            "person: 75%\t(left_x:  522   top_y:  289   width:  118   height:  192)\n",
            "traffic light: 27%\t(left_x:  563   top_y:  238   width:    7   height:   22)\n",
            "car: 74%\t(left_x:  614   top_y:  276   width:   82   height:   31)\n",
            "motorbike: 65%\t(left_x:  740   top_y:  293   width:   43   height:   34)\n",
            "person: 43%\t(left_x:  744   top_y:  274   width:   21   height:   26)\n",
            "car: 95%\t(left_x:  761   top_y:  278   width:  105   height:   44)\n",
            "car: 99%\t(left_x:  875   top_y:  277   width:  147   height:   58)\n",
            "car: 29%\t(left_x: 1018   top_y:  285   width:   39   height:   26)\n",
            "car: 89%\t(left_x: 1036   top_y:  270   width:  240   height:   75)\n",
            "motorbike: 69%\t(left_x: 1048   top_y:  467   width:  233   height:  261)\n",
            "car: 98%\t(left_x: 1085   top_y:  283   width:  196   height:  170)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/11.jpg: Predicted in 41.148000 milli-seconds.\n",
            "person: 42%\t(left_x:   -1   top_y:  280   width:   94   height:  171)\n",
            "motorbike: 90%\t(left_x:    0   top_y:  334   width:  169   height:  142)\n",
            "motorbike: 45%\t(left_x:    3   top_y:  288   width:   93   height:   50)\n",
            "car: 33%\t(left_x:   73   top_y:  260   width:   43   height:   21)\n",
            "person: 25%\t(left_x:   77   top_y:  261   width:   33   height:   33)\n",
            "car: 90%\t(left_x:  102   top_y:  263   width:   62   height:   38)\n",
            "car: 39%\t(left_x:  156   top_y:  262   width:   37   height:   23)\n",
            "motorbike: 73%\t(left_x:  163   top_y:  286   width:   89   height:   43)\n",
            "car: 50%\t(left_x:  179   top_y:  259   width:   77   height:   38)\n",
            "person: 30%\t(left_x:  180   top_y:  273   width:   70   height:   44)\n",
            "person: 36%\t(left_x:  189   top_y:  264   width:   35   height:   47)\n",
            "person: 31%\t(left_x:  195   top_y:  261   width:   25   height:   34)\n",
            "car: 85%\t(left_x:  279   top_y:  268   width:   40   height:   27)\n",
            "car: 99%\t(left_x:  302   top_y:  269   width:   98   height:   46)\n",
            "person: 54%\t(left_x:  387   top_y:  267   width:   16   height:   29)\n",
            "motorbike: 94%\t(left_x:  413   top_y:  291   width:   76   height:   41)\n",
            "person: 55%\t(left_x:  492   top_y:  270   width:   17   height:   33)\n",
            "car: 99%\t(left_x:  510   top_y:  277   width:  183   height:   94)\n",
            "car: 96%\t(left_x:  725   top_y:  278   width:   91   height:   42)\n",
            "car: 99%\t(left_x:  841   top_y:  277   width:  135   height:   57)\n",
            "person: 28%\t(left_x:  881   top_y:  273   width:   15   height:   13)\n",
            "motorbike: 81%\t(left_x:  943   top_y:  358   width:  337   height:  230)\n",
            "car: 99%\t(left_x:  978   top_y:  271   width:  211   height:   74)\n",
            "person: 35%\t(left_x:  986   top_y:  284   width:   20   height:   14)\n",
            "motorbike: 55%\t(left_x: 1055   top_y:  453   width:  227   height:  269)\n",
            "car: 83%\t(left_x: 1153   top_y:  289   width:  128   height:  137)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/12.jpg: Predicted in 41.119000 milli-seconds.\n",
            "motorbike: 33%\t(left_x:   -1   top_y:  376   width:   45   height:  102)\n",
            "motorbike: 63%\t(left_x:   17   top_y:  290   width:   88   height:   41)\n",
            "car: 38%\t(left_x:   28   top_y:  260   width:   27   height:   24)\n",
            "car: 29%\t(left_x:   94   top_y:  260   width:   31   height:   21)\n",
            "car: 99%\t(left_x:  106   top_y:  264   width:   67   height:   37)\n",
            "car: 46%\t(left_x:  156   top_y:  261   width:   31   height:   21)\n",
            "car: 95%\t(left_x:  182   top_y:  256   width:   86   height:   55)\n",
            "motorbike: 30%\t(left_x:  263   top_y:  291   width:   46   height:   40)\n",
            "motorbike: 78%\t(left_x:  265   top_y:  303   width:   34   height:   31)\n",
            "motorbike: 98%\t(left_x:  300   top_y:  374   width:  242   height:  132)\n",
            "person: 60%\t(left_x:  311   top_y:  304   width:  148   height:  165)\n",
            "car: 79%\t(left_x:  313   top_y:  268   width:   86   height:   39)\n",
            "person: 44%\t(left_x:  398   top_y:  267   width:   15   height:   27)\n",
            "person: 28%\t(left_x:  423   top_y:  266   width:   16   height:   26)\n",
            "person: 55%\t(left_x:  480   top_y:  266   width:   15   height:   32)\n",
            "motorbike: 31%\t(left_x:  522   top_y:  280   width:   41   height:   32)\n",
            "car: 100%\t(left_x:  541   top_y:  274   width:  213   height:  105)\n",
            "person: 66%\t(left_x:  544   top_y:  266   width:   16   height:   26)\n",
            "car: 63%\t(left_x:  685   top_y:  276   width:   78   height:   35)\n",
            "car: 97%\t(left_x:  804   top_y:  275   width:  129   height:   54)\n",
            "person: 31%\t(left_x:  836   top_y:  268   width:   19   height:   17)\n",
            "car: 78%\t(left_x:  918   top_y:  268   width:  206   height:   73)\n",
            "motorbike: 91%\t(left_x: 1032   top_y:  297   width:   98   height:   62)\n",
            "motorbike: 61%\t(left_x: 1050   top_y:  454   width:  229   height:  267)\n",
            "person: 76%\t(left_x: 1065   top_y:  269   width:   47   height:   77)\n",
            "car: 97%\t(left_x: 1116   top_y:  290   width:  161   height:   52)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/13.jpg: Predicted in 41.434000 milli-seconds.\n",
            "car: 45%\t(left_x:   17   top_y:  257   width:   43   height:   29)\n",
            "motorbike: 39%\t(left_x:   80   top_y:  288   width:   79   height:   47)\n",
            "car: 45%\t(left_x:   90   top_y:  259   width:   42   height:   23)\n",
            "motorbike: 36%\t(left_x:  118   top_y:  298   width:   45   height:   36)\n",
            "car: 44%\t(left_x:  138   top_y:  263   width:   32   height:   32)\n",
            "motorbike: 97%\t(left_x:  151   top_y:  356   width:  246   height:  147)\n",
            "person: 86%\t(left_x:  154   top_y:  275   width:  162   height:  189)\n",
            "car: 89%\t(left_x:  194   top_y:  256   width:   79   height:   52)\n",
            "car: 99%\t(left_x:  314   top_y:  266   width:  100   height:   48)\n",
            "person: 70%\t(left_x:  403   top_y:  265   width:   16   height:   28)\n",
            "person: 35%\t(left_x:  422   top_y:  264   width:   18   height:   31)\n",
            "person: 50%\t(left_x:  471   top_y:  270   width:   12   height:   26)\n",
            "motorbike: 94%\t(left_x:  484   top_y:  286   width:   64   height:   46)\n",
            "person: 59%\t(left_x:  498   top_y:  268   width:   48   height:   48)\n",
            "car: 69%\t(left_x:  527   top_y:  272   width:   58   height:   35)\n",
            "car: 98%\t(left_x:  575   top_y:  271   width:  186   height:  113)\n",
            "motorbike: 95%\t(left_x:  725   top_y:  384   width:  314   height:  178)\n",
            "person: 40%\t(left_x:  744   top_y:  311   width:  211   height:  192)\n",
            "car: 95%\t(left_x:  776   top_y:  275   width:  113   height:   47)\n",
            "car: 85%\t(left_x:  887   top_y:  264   width:  156   height:   71)\n",
            "motorbike: 76%\t(left_x:  889   top_y:  301   width:  100   height:   54)\n",
            "person: 41%\t(left_x:  897   top_y:  283   width:   79   height:   60)\n",
            "car: 98%\t(left_x: 1043   top_y:  285   width:  132   height:   51)\n",
            "motorbike: 80%\t(left_x: 1044   top_y:  467   width:  238   height:  258)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/14.jpg: Predicted in 41.261000 milli-seconds.\n",
            "motorbike: 97%\t(left_x:   -2   top_y:  346   width:  126   height:  127)\n",
            "person: 30%\t(left_x:   -1   top_y:  296   width:   48   height:  144)\n",
            "person: 32%\t(left_x:   -0   top_y:  251   width:   14   height:   52)\n",
            "car: 66%\t(left_x:   20   top_y:  254   width:   44   height:   36)\n",
            "car: 82%\t(left_x:   94   top_y:  257   width:   37   height:   33)\n",
            "car: 99%\t(left_x:  119   top_y:  260   width:   66   height:   39)\n",
            "car: 100%\t(left_x:  188   top_y:  253   width:   90   height:   57)\n",
            "car: 74%\t(left_x:  254   top_y:  257   width:   41   height:   44)\n",
            "person: 29%\t(left_x:  293   top_y:  256   width:   15   height:   24)\n",
            "car: 97%\t(left_x:  318   top_y:  264   width:   84   height:   45)\n",
            "motorbike: 90%\t(left_x:  362   top_y:  285   width:   79   height:   49)\n",
            "person: 75%\t(left_x:  394   top_y:  259   width:   32   height:   60)\n",
            "motorbike: 76%\t(left_x:  451   top_y:  273   width:   82   height:   32)\n",
            "person: 41%\t(left_x:  473   top_y:  263   width:   46   height:   39)\n",
            "motorbike: 97%\t(left_x:  545   top_y:  377   width:  312   height:  178)\n",
            "person: 76%\t(left_x:  548   top_y:  283   width:  208   height:  220)\n",
            "car: 99%\t(left_x:  639   top_y:  272   width:  266   height:  120)\n",
            "car: 52%\t(left_x:  785   top_y:  272   width:   63   height:   18)\n",
            "car: 91%\t(left_x:  813   top_y:  259   width:  170   height:   73)\n",
            "car: 97%\t(left_x:  977   top_y:  277   width:  114   height:   50)\n",
            "motorbike: 72%\t(left_x: 1046   top_y:  455   width:  232   height:  265)\n",
            "car: 37%\t(left_x: 1061   top_y:  271   width:   85   height:   34)\n",
            "car: 86%\t(left_x: 1222   top_y:  272   width:   58   height:   78)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/15.jpg: Predicted in 41.260000 milli-seconds.\n",
            "motorbike: 74%\t(left_x:   -1   top_y:  366   width:   53   height:  112)\n",
            "person: 35%\t(left_x:    0   top_y:  249   width:   16   height:   58)\n",
            "car: 58%\t(left_x:   20   top_y:  254   width:   43   height:   36)\n",
            "person: 32%\t(left_x:   61   top_y:  256   width:   19   height:   25)\n",
            "person: 26%\t(left_x:   61   top_y:  254   width:   33   height:   46)\n",
            "person: 46%\t(left_x:   78   top_y:  254   width:   19   height:   45)\n",
            "car: 71%\t(left_x:   99   top_y:  255   width:   50   height:   34)\n",
            "car: 98%\t(left_x:  120   top_y:  259   width:   73   height:   41)\n",
            "motorbike: 94%\t(left_x:  136   top_y:  355   width:  234   height:  149)\n",
            "person: 68%\t(left_x:  169   top_y:  281   width:  137   height:  180)\n",
            "car: 66%\t(left_x:  192   top_y:  252   width:  104   height:   53)\n",
            "person: 27%\t(left_x:  227   top_y:  298   width:  113   height:  169)\n",
            "car: 99%\t(left_x:  323   top_y:  264   width:  107   height:   49)\n",
            "person: 28%\t(left_x:  411   top_y:  265   width:   31   height:   31)\n",
            "car: 59%\t(left_x:  422   top_y:  268   width:   89   height:   35)\n",
            "motorbike: 46%\t(left_x:  440   top_y:  269   width:   79   height:   35)\n",
            "car: 96%\t(left_x:  528   top_y:  271   width:   67   height:   33)\n",
            "motorbike: 85%\t(left_x:  563   top_y:  299   width:  101   height:   52)\n",
            "person: 38%\t(left_x:  567   top_y:  283   width:   93   height:   68)\n",
            "person: 31%\t(left_x:  590   top_y:  271   width:   56   height:   59)\n",
            "car: 100%\t(left_x:  681   top_y:  270   width:  309   height:  136)\n",
            "car: 56%\t(left_x:  805   top_y:  260   width:  194   height:   64)\n",
            "car: 45%\t(left_x:  806   top_y:  259   width:  123   height:   54)\n",
            "car: 69%\t(left_x:  924   top_y:  277   width:   84   height:   46)\n",
            "motorbike: 59%\t(left_x: 1043   top_y:  451   width:  236   height:  271)\n",
            "car: 85%\t(left_x: 1158   top_y:  267   width:  121   height:   81)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/16.jpg: Predicted in 41.212000 milli-seconds.\n",
            "motorbike: 48%\t(left_x:   13   top_y:  285   width:   75   height:   51)\n",
            "car: 35%\t(left_x:   20   top_y:  257   width:   38   height:   22)\n",
            "person: 26%\t(left_x:   34   top_y:  257   width:   54   height:   69)\n",
            "person: 25%\t(left_x:   44   top_y:  258   width:   38   height:   29)\n",
            "person: 28%\t(left_x:   76   top_y:  257   width:   23   height:   40)\n",
            "motorbike: 97%\t(left_x:   80   top_y:  344   width:  251   height:  159)\n",
            "person: 92%\t(left_x:   85   top_y:  258   width:  171   height:  205)\n",
            "car: 35%\t(left_x:   94   top_y:  255   width:   20   height:   13)\n",
            "car: 77%\t(left_x:  144   top_y:  259   width:   69   height:   41)\n",
            "car: 94%\t(left_x:  202   top_y:  251   width:   91   height:   62)\n",
            "car: 94%\t(left_x:  263   top_y:  256   width:   55   height:   48)\n",
            "person: 54%\t(left_x:  316   top_y:  258   width:   17   height:   30)\n",
            "car: 93%\t(left_x:  329   top_y:  263   width:  101   height:   49)\n",
            "motorbike: 73%\t(left_x:  367   top_y:  302   width:  100   height:   48)\n",
            "motorbike: 94%\t(left_x:  388   top_y:  361   width:  275   height:  182)\n",
            "person: 74%\t(left_x:  414   top_y:  279   width:  193   height:  216)\n",
            "car: 32%\t(left_x:  490   top_y:  270   width:   77   height:   26)\n",
            "motorbike: 62%\t(left_x:  537   top_y:  284   width:   54   height:   28)\n",
            "car: 55%\t(left_x:  674   top_y:  269   width:   75   height:   18)\n",
            "car: 57%\t(left_x:  731   top_y:  261   width:  128   height:   53)\n",
            "car: 100%\t(left_x:  746   top_y:  270   width:  367   height:  151)\n",
            "person: 31%\t(left_x: 1023   top_y:  278   width:   13   height:   29)\n",
            "motorbike: 64%\t(left_x: 1040   top_y:  450   width:  240   height:  271)\n",
            "car: 99%\t(left_x: 1071   top_y:  271   width:  214   height:   75)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/17.jpg: Predicted in 41.240000 milli-seconds.\n",
            "car: 49%\t(left_x:   23   top_y:  254   width:   61   height:   36)\n",
            "car: 42%\t(left_x:   23   top_y:  255   width:   31   height:   34)\n",
            "car: 63%\t(left_x:   59   top_y:  255   width:   32   height:   27)\n",
            "person: 70%\t(left_x:   87   top_y:  255   width:   20   height:   43)\n",
            "car: 30%\t(left_x:   99   top_y:  254   width:   25   height:   16)\n",
            "car: 61%\t(left_x:  121   top_y:  256   width:   31   height:   31)\n",
            "motorbike: 68%\t(left_x:  134   top_y:  295   width:  134   height:   58)\n",
            "car: 95%\t(left_x:  135   top_y:  257   width:   62   height:   44)\n",
            "person: 26%\t(left_x:  185   top_y:  253   width:   14   height:   19)\n",
            "person: 65%\t(left_x:  192   top_y:  257   width:   65   height:   75)\n",
            "car: 91%\t(left_x:  217   top_y:  251   width:   86   height:   64)\n",
            "car: 93%\t(left_x:  275   top_y:  256   width:   62   height:   47)\n",
            "motorbike: 26%\t(left_x:  342   top_y:  266   width:   48   height:   47)\n",
            "car: 64%\t(left_x:  344   top_y:  264   width:   60   height:   48)\n",
            "motorbike: 98%\t(left_x:  350   top_y:  352   width:  284   height:  183)\n",
            "person: 94%\t(left_x:  367   top_y:  251   width:  112   height:  225)\n",
            "person: 86%\t(left_x:  436   top_y:  255   width:  171   height:  228)\n",
            "car: 62%\t(left_x:  494   top_y:  269   width:   51   height:   36)\n",
            "motorbike: 89%\t(left_x:  521   top_y:  283   width:   53   height:   29)\n",
            "person: 59%\t(left_x:  542   top_y:  262   width:   19   height:   34)\n",
            "person: 28%\t(left_x:  543   top_y:  262   width:   17   height:   22)\n",
            "person: 40%\t(left_x:  603   top_y:  270   width:   17   height:   18)\n",
            "car: 97%\t(left_x:  610   top_y:  268   width:   96   height:   40)\n",
            "motorbike: 96%\t(left_x:  710   top_y:  381   width:  407   height:  238)\n",
            "car: 94%\t(left_x:  713   top_y:  258   width:  113   height:   64)\n",
            "person: 42%\t(left_x:  799   top_y:  316   width:  186   height:  222)\n",
            "car: 30%\t(left_x:  802   top_y:  259   width:   66   height:   47)\n",
            "car: 100%\t(left_x:  880   top_y:  272   width:  379   height:  164)\n",
            "motorbike: 74%\t(left_x: 1050   top_y:  460   width:  230   height:  259)\n",
            "car: 99%\t(left_x: 1080   top_y:  264   width:  170   height:   75)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/18.jpg: Predicted in 41.162000 milli-seconds.\n",
            "car: 43%\t(left_x:   23   top_y:  253   width:   43   height:   33)\n",
            "car: 51%\t(left_x:   61   top_y:  254   width:   32   height:   29)\n",
            "person: 52%\t(left_x:   90   top_y:  252   width:   32   height:   37)\n",
            "car: 44%\t(left_x:  116   top_y:  253   width:   27   height:   21)\n",
            "car: 25%\t(left_x:  124   top_y:  252   width:   34   height:   21)\n",
            "car: 99%\t(left_x:  135   top_y:  255   width:   70   height:   50)\n",
            "car: 99%\t(left_x:  207   top_y:  247   width:  105   height:   68)\n",
            "car: 96%\t(left_x:  284   top_y:  253   width:   67   height:   47)\n",
            "car: 100%\t(left_x:  351   top_y:  261   width:  111   height:   53)\n",
            "car: 96%\t(left_x:  440   top_y:  263   width:   73   height:   33)\n",
            "bicycle: 32%\t(left_x:  498   top_y:  282   width:   55   height:   28)\n",
            "motorbike: 76%\t(left_x:  498   top_y:  282   width:   54   height:   27)\n",
            "person: 58%\t(left_x:  520   top_y:  259   width:   20   height:   37)\n",
            "car: 91%\t(left_x:  568   top_y:  264   width:   89   height:   43)\n",
            "car: 54%\t(left_x:  632   top_y:  252   width:  123   height:   54)\n",
            "motorbike: 93%\t(left_x:  679   top_y:  380   width:  351   height:  203)\n",
            "person: 37%\t(left_x:  708   top_y:  268   width:  136   height:  237)\n",
            "person: 66%\t(left_x:  758   top_y:  276   width:  168   height:  236)\n",
            "motorbike: 67%\t(left_x:  883   top_y:  291   width:   59   height:   28)\n",
            "person: 45%\t(left_x:  884   top_y:  282   width:   31   height:   32)\n",
            "person: 28%\t(left_x:  906   top_y:  272   width:   19   height:   31)\n",
            "car: 100%\t(left_x:  945   top_y:  267   width:  336   height:  167)\n",
            "car: 32%\t(left_x:  979   top_y:  282   width:   48   height:   18)\n",
            "motorbike: 92%\t(left_x: 1050   top_y:  510   width:  232   height:  214)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/19.jpg: Predicted in 41.181000 milli-seconds.\n",
            "motorbike: 86%\t(left_x:   42   top_y:  303   width:  172   height:   82)\n",
            "car: 71%\t(left_x:   60   top_y:  254   width:   31   height:   28)\n",
            "person: 28%\t(left_x:   80   top_y:  269   width:   96   height:   82)\n",
            "person: 41%\t(left_x:  117   top_y:  252   width:   19   height:   39)\n",
            "person: 26%\t(left_x:  131   top_y:  253   width:   21   height:   33)\n",
            "person: 49%\t(left_x:  147   top_y:  253   width:   18   height:   35)\n",
            "car: 98%\t(left_x:  159   top_y:  255   width:   72   height:   51)\n",
            "car: 38%\t(left_x:  214   top_y:  258   width:   26   height:   38)\n",
            "car: 97%\t(left_x:  239   top_y:  247   width:  108   height:   68)\n",
            "car: 96%\t(left_x:  313   top_y:  252   width:   73   height:   50)\n",
            "car: 100%\t(left_x:  386   top_y:  259   width:  110   height:   56)\n",
            "car: 53%\t(left_x:  456   top_y:  260   width:   46   height:   27)\n",
            "motorbike: 80%\t(left_x:  502   top_y:  271   width:   61   height:   37)\n",
            "person: 38%\t(left_x:  528   top_y:  256   width:   16   height:   25)\n",
            "car: 96%\t(left_x:  545   top_y:  262   width:   86   height:   39)\n",
            "car: 93%\t(left_x:  621   top_y:  251   width:  158   height:   61)\n",
            "person: 33%\t(left_x:  760   top_y:  251   width:   19   height:   54)\n",
            "motorbike: 84%\t(left_x:  824   top_y:  275   width:   61   height:   37)\n",
            "person: 71%\t(left_x:  836   top_y:  250   width:   34   height:   59)\n",
            "car: 99%\t(left_x:  946   top_y:  256   width:  191   height:   72)\n",
            "motorbike: 69%\t(left_x: 1091   top_y:  510   width:  189   height:  212)\n",
            "car: 98%\t(left_x: 1109   top_y:  272   width:  171   height:  158)\n",
            "motorbike: 26%\t(left_x: 1187   top_y:  417   width:   93   height:  116)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/20.jpg: Predicted in 41.235000 milli-seconds.\n",
            "car: 59%\t(left_x:   -0   top_y:  241   width:   22   height:   18)\n",
            "motorbike: 95%\t(left_x:   16   top_y:  327   width:  218   height:  129)\n",
            "person: 28%\t(left_x:   20   top_y:  245   width:   22   height:   32)\n",
            "person: 76%\t(left_x:   42   top_y:  257   width:  135   height:  149)\n",
            "car: 57%\t(left_x:   66   top_y:  247   width:   28   height:   25)\n",
            "car: 29%\t(left_x:  111   top_y:  247   width:   37   height:   28)\n",
            "car: 52%\t(left_x:  126   top_y:  246   width:   37   height:   32)\n",
            "car: 99%\t(left_x:  164   top_y:  249   width:   72   height:   56)\n",
            "car: 73%\t(left_x:  213   top_y:  250   width:   38   height:   41)\n",
            "motorbike: 96%\t(left_x:  249   top_y:  287   width:  155   height:   83)\n",
            "car: 74%\t(left_x:  255   top_y:  243   width:  110   height:   60)\n",
            "person: 41%\t(left_x:  284   top_y:  264   width:   89   height:  102)\n",
            "person: 28%\t(left_x:  293   top_y:  249   width:   66   height:   97)\n",
            "car: 84%\t(left_x:  331   top_y:  248   width:   70   height:   47)\n",
            "car: 99%\t(left_x:  406   top_y:  254   width:  109   height:   59)\n",
            "motorbike: 66%\t(left_x:  508   top_y:  272   width:   44   height:   32)\n",
            "person: 52%\t(left_x:  517   top_y:  251   width:   22   height:   39)\n",
            "car: 73%\t(left_x:  530   top_y:  255   width:   64   height:   40)\n",
            "truck: 78%\t(left_x:  598   top_y:  244   width:  164   height:   65)\n",
            "car: 69%\t(left_x:  599   top_y:  245   width:  170   height:   64)\n",
            "motorbike: 35%\t(left_x:  776   top_y:  275   width:   50   height:   29)\n",
            "motorbike: 32%\t(left_x:  791   top_y:  277   width:   43   height:   23)\n",
            "person: 43%\t(left_x:  819   top_y:  258   width:   18   height:   39)\n",
            "car: 99%\t(left_x:  893   top_y:  250   width:  201   height:   70)\n",
            "motorbike: 65%\t(left_x: 1089   top_y:  458   width:  192   height:  260)\n",
            "motorbike: 86%\t(left_x: 1156   top_y:  285   width:   92   height:   46)\n",
            "person: 47%\t(left_x: 1194   top_y:  262   width:   33   height:   55)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173654_487/21.jpg: Predicted in 41.145000 milli-seconds.\n",
            "car: 72%\t(left_x:   -1   top_y:  242   width:   15   height:   20)\n",
            "person: 36%\t(left_x:   34   top_y:  244   width:   22   height:   51)\n",
            "car: 35%\t(left_x:   57   top_y:  249   width:   32   height:   39)\n",
            "car: 35%\t(left_x:   57   top_y:  250   width:   29   height:   22)\n",
            "person: 36%\t(left_x:   94   top_y:  250   width:   28   height:   42)\n",
            "person: 46%\t(left_x:  118   top_y:  251   width:   19   height:   39)\n",
            "car: 65%\t(left_x:  125   top_y:  251   width:   35   height:   32)\n",
            "car: 100%\t(left_x:  153   top_y:  251   width:   79   height:   60)\n",
            "car: 52%\t(left_x:  213   top_y:  252   width:   31   height:   39)\n",
            "car: 69%\t(left_x:  221   top_y:  252   width:   39   height:   32)\n",
            "car: 99%\t(left_x:  257   top_y:  247   width:  111   height:   68)\n",
            "car: 96%\t(left_x:  335   top_y:  252   width:   75   height:   52)\n",
            "motorbike: 96%\t(left_x:  392   top_y:  370   width:  249   height:  124)\n",
            "car: 45%\t(left_x:  409   top_y:  261   width:  108   height:   52)\n",
            "motorbike: 84%\t(left_x:  426   top_y:  294   width:  120   height:   77)\n",
            "person: 66%\t(left_x:  433   top_y:  258   width:  103   height:  110)\n",
            "person: 30%\t(left_x:  508   top_y:  257   width:   19   height:   27)\n",
            "car: 98%\t(left_x:  568   top_y:  250   width:  185   height:   62)\n",
            "pottedplant: 26%\t(left_x:  669   top_y:  275   width:  104   height:   48)\n",
            "motorbike: 63%\t(left_x:  778   top_y:  270   width:   31   height:   34)\n",
            "person: 47%\t(left_x:  785   top_y:  263   width:   26   height:   39)\n",
            "car: 98%\t(left_x:  841   top_y:  255   width:  192   height:   68)\n",
            "motorbike: 88%\t(left_x: 1084   top_y:  282   width:   87   height:   51)\n",
            "motorbike: 60%\t(left_x: 1085   top_y:  452   width:  196   height:  267)\n",
            "person: 66%\t(left_x: 1100   top_y:  268   width:   58   height:   59)\n",
            "motorbike: 35%\t(left_x: 1162   top_y:  287   width:   67   height:   44)\n",
            "motorbike: 34%\t(left_x: 1204   top_y:  294   width:   66   height:   40)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/1.jpg: Predicted in 42.326000 milli-seconds.\n",
            "stop sign: 27%\t(left_x:   73   top_y:  652   width:   72   height:   70)\n",
            "car: 99%\t(left_x:  197   top_y:  650   width:   91   height:   60)\n",
            "car: 31%\t(left_x:  280   top_y:  646   width:   37   height:   29)\n",
            "car: 28%\t(left_x:  394   top_y:  649   width:   41   height:   44)\n",
            "car: 40%\t(left_x:  476   top_y:  650   width:   38   height:   25)\n",
            "car: 39%\t(left_x:  494   top_y:  652   width:   30   height:   25)\n",
            "person: 41%\t(left_x:  528   top_y:  651   width:   23   height:   27)\n",
            "person: 35%\t(left_x:  552   top_y:  651   width:   23   height:   23)\n",
            "motorbike: 30%\t(left_x:  552   top_y:  651   width:   23   height:   23)\n",
            "car: 32%\t(left_x:  590   top_y:  648   width:   63   height:   35)\n",
            "person: 29%\t(left_x:  592   top_y:  648   width:   54   height:   35)\n",
            "motorbike: 57%\t(left_x:  596   top_y:  653   width:   57   height:   33)\n",
            "car: 26%\t(left_x:  620   top_y:  650   width:   39   height:   29)\n",
            "car: 33%\t(left_x:  672   top_y:  644   width:   48   height:   29)\n",
            "motorbike: 82%\t(left_x:  673   top_y:  660   width:   25   height:   32)\n",
            "person: 32%\t(left_x:  707   top_y:  648   width:   24   height:   25)\n",
            "person: 84%\t(left_x:  833   top_y:  629   width:   45   height:   87)\n",
            "motorbike: 88%\t(left_x:  833   top_y:  670   width:   38   height:   60)\n",
            "motorbike: 42%\t(left_x:  939   top_y:  665   width:   22   height:   43)\n",
            "person: 41%\t(left_x:  946   top_y:  597   width:   93   height:  258)\n",
            "motorbike: 98%\t(left_x:  950   top_y:  708   width:  298   height:  317)\n",
            "person: 91%\t(left_x:  983   top_y:  601   width:  192   height:  321)\n",
            "person: 35%\t(left_x: 1093   top_y:  614   width:   47   height:   68)\n",
            "car: 86%\t(left_x: 1113   top_y:  642   width:  119   height:  105)\n",
            "car: 93%\t(left_x: 1416   top_y:  646   width:  267   height:  110)\n",
            "motorbike: 79%\t(left_x: 1422   top_y:  680   width:  148   height:   83)\n",
            "person: 95%\t(left_x: 1469   top_y:  635   width:   71   height:  112)\n",
            "car: 93%\t(left_x: 1827   top_y:  614   width:   95   height:  175)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/2.jpg: Predicted in 44.104000 milli-seconds.\n",
            "parking meter: 61%\t(left_x:   31   top_y:  636   width:   66   height:   74)\n",
            "car: 98%\t(left_x:  161   top_y:  639   width:   93   height:   58)\n",
            "car: 32%\t(left_x:  247   top_y:  633   width:   36   height:   28)\n",
            "car: 46%\t(left_x:  285   top_y:  626   width:   60   height:   40)\n",
            "car: 70%\t(left_x:  362   top_y:  634   width:   48   height:   49)\n",
            "car: 44%\t(left_x:  437   top_y:  638   width:   25   height:   22)\n",
            "car: 73%\t(left_x:  448   top_y:  640   width:   40   height:   22)\n",
            "car: 47%\t(left_x:  494   top_y:  637   width:   32   height:   26)\n",
            "car: 87%\t(left_x:  564   top_y:  639   width:   47   height:   34)\n",
            "person: 60%\t(left_x:  628   top_y:  641   width:   25   height:   38)\n",
            "motorbike: 52%\t(left_x:  628   top_y:  641   width:   25   height:   38)\n",
            "car: 76%\t(left_x:  649   top_y:  635   width:   44   height:   21)\n",
            "person: 99%\t(left_x:  806   top_y:  612   width:   60   height:  111)\n",
            "motorbike: 56%\t(left_x:  808   top_y:  659   width:   52   height:   78)\n",
            "bicycle: 30%\t(left_x:  813   top_y:  665   width:   45   height:   72)\n",
            "car: 96%\t(left_x:  876   top_y:  628   width:  158   height:   90)\n",
            "person: 85%\t(left_x: 1139   top_y:  632   width:   27   height:   77)\n",
            "motorbike: 55%\t(left_x: 1160   top_y:  663   width:   49   height:   46)\n",
            "person: 36%\t(left_x: 1169   top_y:  640   width:   43   height:   67)\n",
            "motorbike: 92%\t(left_x: 1205   top_y:  656   width:  192   height:  196)\n",
            "person: 84%\t(left_x: 1244   top_y:  587   width:  118   height:  221)\n",
            "person: 25%\t(left_x: 1296   top_y:  604   width:   74   height:  185)\n",
            "person: 37%\t(left_x: 1319   top_y:  624   width:   55   height:   96)\n",
            "car: 93%\t(left_x: 1389   top_y:  641   width:  148   height:   99)\n",
            "motorbike: 65%\t(left_x: 1498   top_y:  829   width:  422   height:  256)\n",
            "person: 33%\t(left_x: 1566   top_y:  560   width:  358   height:  503)\n",
            "car: 80%\t(left_x: 1810   top_y:  604   width:  111   height:  167)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/3.jpg: Predicted in 45.275000 milli-seconds.\n",
            "parking meter: 66%\t(left_x:   35   top_y:  623   width:   66   height:   71)\n",
            "car: 98%\t(left_x:  160   top_y:  623   width:   93   height:   59)\n",
            "car: 31%\t(left_x:  325   top_y:  623   width:   40   height:   27)\n",
            "car: 48%\t(left_x:  443   top_y:  623   width:   41   height:   24)\n",
            "person: 37%\t(left_x:  478   top_y:  625   width:   28   height:   24)\n",
            "car: 25%\t(left_x:  478   top_y:  625   width:   28   height:   24)\n",
            "car: 39%\t(left_x:  500   top_y:  623   width:   37   height:   22)\n",
            "motorbike: 27%\t(left_x:  500   top_y:  623   width:   37   height:   22)\n",
            "car: 85%\t(left_x:  532   top_y:  625   width:   63   height:   32)\n",
            "person: 53%\t(left_x:  598   top_y:  617   width:   41   height:   34)\n",
            "motorbike: 81%\t(left_x:  600   top_y:  629   width:   38   height:   30)\n",
            "car: 84%\t(left_x:  636   top_y:  619   width:   63   height:   23)\n",
            "person: 27%\t(left_x:  694   top_y:  620   width:   15   height:   26)\n",
            "car: 74%\t(left_x:  773   top_y:  614   width:   90   height:   67)\n",
            "motorbike: 40%\t(left_x:  834   top_y:  660   width:   65   height:   87)\n",
            "person: 98%\t(left_x:  836   top_y:  597   width:   63   height:  136)\n",
            "bicycle: 69%\t(left_x:  838   top_y:  660   width:   54   height:   89)\n",
            "person: 39%\t(left_x:  917   top_y:  623   width:   29   height:   47)\n",
            "motorbike: 46%\t(left_x:  922   top_y:  647   width:   30   height:   26)\n",
            "person: 92%\t(left_x: 1117   top_y:  618   width:   31   height:   75)\n",
            "person: 25%\t(left_x: 1155   top_y:  625   width:   45   height:   66)\n",
            "motorbike: 86%\t(left_x: 1163   top_y:  654   width:   75   height:   53)\n",
            "person: 64%\t(left_x: 1163   top_y:  614   width:   66   height:   89)\n",
            "car: 99%\t(left_x: 1380   top_y:  622   width:  278   height:  106)\n",
            "motorbike: 88%\t(left_x: 1570   top_y:  636   width:  346   height:  300)\n",
            "person: 48%\t(left_x: 1652   top_y:  550   width:  176   height:  300)\n",
            "truck: 37%\t(left_x: 1779   top_y:  573   width:  146   height:  189)\n",
            "car: 63%\t(left_x: 1785   top_y:  572   width:  136   height:  193)\n",
            "person: 44%\t(left_x: 1885   top_y:  603   width:   35   height:   36)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/4.jpg: Predicted in 46.686000 milli-seconds.\n",
            "parking meter: 41%\t(left_x:   33   top_y:  639   width:   69   height:   79)\n",
            "car: 97%\t(left_x:  162   top_y:  645   width:   95   height:   62)\n",
            "car: 30%\t(left_x:  297   top_y:  640   width:   43   height:   38)\n",
            "car: 67%\t(left_x:  336   top_y:  642   width:   46   height:   29)\n",
            "car: 60%\t(left_x:  446   top_y:  644   width:   38   height:   24)\n",
            "car: 26%\t(left_x:  480   top_y:  645   width:   28   height:   25)\n",
            "car: 68%\t(left_x:  503   top_y:  644   width:   37   height:   30)\n",
            "car: 85%\t(left_x:  535   top_y:  647   width:   53   height:   30)\n",
            "car: 53%\t(left_x:  603   top_y:  645   width:   35   height:   27)\n",
            "car: 54%\t(left_x:  638   top_y:  641   width:   66   height:   22)\n",
            "car: 96%\t(left_x:  705   top_y:  633   width:  115   height:   64)\n",
            "person: 64%\t(left_x:  807   top_y:  635   width:   24   height:   50)\n",
            "motorbike: 71%\t(left_x:  906   top_y:  679   width:   78   height:  133)\n",
            "person: 99%\t(left_x:  908   top_y:  620   width:   82   height:  153)\n",
            "person: 29%\t(left_x: 1072   top_y:  638   width:   24   height:   55)\n",
            "person: 40%\t(left_x: 1080   top_y:  638   width:   42   height:   74)\n",
            "motorbike: 73%\t(left_x: 1090   top_y:  676   width:   54   height:   46)\n",
            "person: 89%\t(left_x: 1092   top_y:  635   width:   47   height:   80)\n",
            "bicycle: 25%\t(left_x: 1157   top_y:  672   width:   49   height:   42)\n",
            "motorbike: 80%\t(left_x: 1157   top_y:  673   width:   49   height:   40)\n",
            "person: 78%\t(left_x: 1158   top_y:  645   width:   49   height:   64)\n",
            "car: 100%\t(left_x: 1385   top_y:  642   width:  287   height:  109)\n",
            "car: 77%\t(left_x: 1796   top_y:  600   width:  127   height:  188)\n",
            "truck: 37%\t(left_x: 1797   top_y:  595   width:  124   height:  194)\n",
            "person: 25%\t(left_x: 1884   top_y:  628   width:   36   height:   32)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/5.jpg: Predicted in 48.176000 milli-seconds.\n",
            "parking meter: 50%\t(left_x:   27   top_y:  647   width:   73   height:   75)\n",
            "person: 54%\t(left_x:  112   top_y:  640   width:   19   height:   51)\n",
            "car: 98%\t(left_x:  152   top_y:  644   width:   94   height:   64)\n",
            "car: 26%\t(left_x:  242   top_y:  645   width:   32   height:   25)\n",
            "car: 26%\t(left_x:  309   top_y:  649   width:   28   height:   27)\n",
            "car: 82%\t(left_x:  336   top_y:  642   width:   44   height:   30)\n",
            "motorbike: 81%\t(left_x:  401   top_y:  652   width:   37   height:   47)\n",
            "motorbike: 50%\t(left_x:  403   top_y:  670   width:   32   height:   31)\n",
            "motorbike: 42%\t(left_x:  454   top_y:  644   width:   30   height:   26)\n",
            "car: 26%\t(left_x:  454   top_y:  644   width:   30   height:   26)\n",
            "motorbike: 46%\t(left_x:  478   top_y:  647   width:   32   height:   29)\n",
            "car: 41%\t(left_x:  478   top_y:  647   width:   32   height:   29)\n",
            "car: 93%\t(left_x:  518   top_y:  645   width:   43   height:   31)\n",
            "car: 37%\t(left_x:  576   top_y:  644   width:   26   height:   35)\n",
            "person: 30%\t(left_x:  576   top_y:  644   width:   26   height:   35)\n",
            "motorbike: 25%\t(left_x:  576   top_y:  644   width:   26   height:   35)\n",
            "car: 32%\t(left_x:  602   top_y:  645   width:   35   height:   21)\n",
            "car: 91%\t(left_x:  642   top_y:  636   width:   92   height:   53)\n",
            "motorbike: 53%\t(left_x:  760   top_y:  656   width:   29   height:   31)\n",
            "bicycle: 26%\t(left_x:  760   top_y:  656   width:   29   height:   31)\n",
            "person: 65%\t(left_x:  762   top_y:  639   width:   28   height:   48)\n",
            "motorbike: 70%\t(left_x:  912   top_y:  660   width:   34   height:   31)\n",
            "person: 53%\t(left_x:  914   top_y:  642   width:   30   height:   46)\n",
            "motorbike: 83%\t(left_x: 1016   top_y:  669   width:   53   height:   43)\n",
            "person: 63%\t(left_x: 1025   top_y:  633   width:   36   height:   60)\n",
            "motorbike: 96%\t(left_x: 1043   top_y:  682   width:  162   height:  208)\n",
            "person: 98%\t(left_x: 1069   top_y:  611   width:  129   height:  208)\n",
            "car: 99%\t(left_x: 1378   top_y:  639   width:  283   height:  107)\n",
            "car: 76%\t(left_x: 1784   top_y:  599   width:  139   height:  183)\n",
            "truck: 38%\t(left_x: 1789   top_y:  595   width:  132   height:  185)\n",
            "person: 46%\t(left_x: 1881   top_y:  616   width:   39   height:   39)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/6.jpg: Predicted in 49.061000 milli-seconds.\n",
            "stop sign: 81%\t(left_x:    7   top_y:  656   width:   78   height:   66)\n",
            "car: 98%\t(left_x:  136   top_y:  651   width:   93   height:   60)\n",
            "car: 27%\t(left_x:  225   top_y:  644   width:   31   height:   34)\n",
            "car: 78%\t(left_x:  326   top_y:  646   width:   40   height:   32)\n",
            "person: 85%\t(left_x:  402   top_y:  645   width:   43   height:   65)\n",
            "motorbike: 88%\t(left_x:  403   top_y:  666   width:   40   height:   46)\n",
            "person: 33%\t(left_x:  448   top_y:  652   width:   26   height:   26)\n",
            "car: 26%\t(left_x:  448   top_y:  652   width:   26   height:   26)\n",
            "motorbike: 28%\t(left_x:  448   top_y:  652   width:   26   height:   26)\n",
            "car: 84%\t(left_x:  493   top_y:  651   width:   42   height:   29)\n",
            "person: 32%\t(left_x:  530   top_y:  650   width:   33   height:   29)\n",
            "car: 27%\t(left_x:  530   top_y:  650   width:   33   height:   29)\n",
            "person: 40%\t(left_x:  546   top_y:  648   width:   29   height:   32)\n",
            "car: 33%\t(left_x:  546   top_y:  648   width:   29   height:   32)\n",
            "car: 96%\t(left_x:  584   top_y:  647   width:   83   height:   45)\n",
            "person: 44%\t(left_x:  714   top_y:  642   width:   29   height:   45)\n",
            "motorbike: 26%\t(left_x:  717   top_y:  655   width:   26   height:   36)\n",
            "person: 56%\t(left_x:  902   top_y:  646   width:   30   height:   51)\n",
            "motorbike: 27%\t(left_x:  902   top_y:  647   width:   30   height:   50)\n",
            "motorbike: 37%\t(left_x:  904   top_y:  671   width:   27   height:   27)\n",
            "motorbike: 78%\t(left_x:  956   top_y:  667   width:   44   height:   41)\n",
            "person: 85%\t(left_x:  958   top_y:  637   width:   41   height:   70)\n",
            "person: 47%\t(left_x: 1054   top_y:  642   width:   23   height:   62)\n",
            "person: 96%\t(left_x: 1077   top_y:  642   width:   25   height:   67)\n",
            "motorbike: 72%\t(left_x: 1133   top_y:  672   width:   53   height:   42)\n",
            "person: 68%\t(left_x: 1134   top_y:  646   width:   51   height:   62)\n",
            "person: 31%\t(left_x: 1150   top_y:  647   width:   34   height:   29)\n",
            "car: 99%\t(left_x: 1366   top_y:  644   width:  205   height:  102)\n",
            "motorbike: 98%\t(left_x: 1444   top_y:  716   width:  476   height:  363)\n",
            "person: 90%\t(left_x: 1548   top_y:  564   width:  203   height:  417)\n",
            "person: 31%\t(left_x: 1775   top_y:  596   width:  144   height:  201)\n",
            "motorbike: 42%\t(left_x: 1778   top_y:  640   width:  143   height:  173)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/7.jpg: Predicted in 50.649000 milli-seconds.\n",
            "stop sign: 61%\t(left_x:    1   top_y:  656   width:   72   height:   73)\n",
            "car: 99%\t(left_x:  126   top_y:  655   width:   96   height:   62)\n",
            "car: 25%\t(left_x:  215   top_y:  643   width:   36   height:   35)\n",
            "car: 53%\t(left_x:  320   top_y:  657   width:   45   height:   26)\n",
            "car: 26%\t(left_x:  327   top_y:  639   width:   22   height:   11)\n",
            "person: 82%\t(left_x:  411   top_y:  638   width:   50   height:   74)\n",
            "person: 26%\t(left_x:  415   top_y:  658   width:   45   height:   67)\n",
            "motorbike: 92%\t(left_x:  415   top_y:  677   width:   42   height:   50)\n",
            "car: 83%\t(left_x:  476   top_y:  657   width:   39   height:   30)\n",
            "car: 28%\t(left_x:  524   top_y:  657   width:   24   height:   32)\n",
            "car: 93%\t(left_x:  538   top_y:  654   width:   72   height:   41)\n",
            "motorbike: 39%\t(left_x:  610   top_y:  657   width:   24   height:   29)\n",
            "car: 52%\t(left_x:  627   top_y:  653   width:   47   height:   20)\n",
            "motorbike: 47%\t(left_x:  684   top_y:  671   width:   28   height:   26)\n",
            "person: 57%\t(left_x:  684   top_y:  653   width:   28   height:   43)\n",
            "motorbike: 52%\t(left_x:  684   top_y:  653   width:   28   height:   43)\n",
            "motorbike: 87%\t(left_x:  902   top_y:  671   width:   44   height:   39)\n",
            "person: 87%\t(left_x:  906   top_y:  645   width:   40   height:   62)\n",
            "person: 81%\t(left_x: 1059   top_y:  648   width:   28   height:   65)\n",
            "motorbike: 93%\t(left_x: 1127   top_y:  680   width:   53   height:   43)\n",
            "person: 78%\t(left_x: 1128   top_y:  656   width:   53   height:   64)\n",
            "motorbike: 84%\t(left_x: 1340   top_y:  682   width:  132   height:  101)\n",
            "person: 80%\t(left_x: 1364   top_y:  652   width:   71   height:  103)\n",
            "person: 59%\t(left_x: 1405   top_y:  651   width:   71   height:  102)\n",
            "car: 78%\t(left_x: 1433   top_y:  650   width:  189   height:  114)\n",
            "car: 72%\t(left_x: 1758   top_y:  588   width:  164   height:  223)\n",
            "truck: 36%\t(left_x: 1762   top_y:  587   width:  158   height:  219)\n",
            "person: 56%\t(left_x: 1856   top_y:  632   width:   39   height:   39)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/8.jpg: Predicted in 51.615000 milli-seconds.\n",
            "person: 28%\t(left_x:  104   top_y:  649   width:   20   height:   45)\n",
            "car: 98%\t(left_x:  146   top_y:  649   width:   96   height:   61)\n",
            "car: 60%\t(left_x:  234   top_y:  647   width:   29   height:   27)\n",
            "car: 90%\t(left_x:  345   top_y:  648   width:   45   height:   32)\n",
            "person: 26%\t(left_x:  427   top_y:  651   width:   25   height:   24)\n",
            "motorbike: 33%\t(left_x:  449   top_y:  649   width:   52   height:   82)\n",
            "person: 74%\t(left_x:  450   top_y:  637   width:   48   height:   84)\n",
            "motorbike: 92%\t(left_x:  453   top_y:  679   width:   44   height:   53)\n",
            "person: 33%\t(left_x:  510   top_y:  652   width:   25   height:   25)\n",
            "motorbike: 27%\t(left_x:  520   top_y:  652   width:   62   height:   36)\n",
            "car: 77%\t(left_x:  521   top_y:  652   width:   61   height:   35)\n",
            "car: 38%\t(left_x:  532   top_y:  648   width:   57   height:   34)\n",
            "person: 37%\t(left_x:  604   top_y:  651   width:   28   height:   29)\n",
            "motorbike: 45%\t(left_x:  606   top_y:  656   width:   23   height:   26)\n",
            "car: 74%\t(left_x:  643   top_y:  647   width:   41   height:   20)\n",
            "motorbike: 29%\t(left_x:  679   top_y:  651   width:   20   height:   40)\n",
            "person: 73%\t(left_x:  679   top_y:  644   width:   19   height:   43)\n",
            "person: 53%\t(left_x:  857   top_y:  641   width:   22   height:   36)\n",
            "motorbike: 47%\t(left_x:  887   top_y:  669   width:   37   height:   36)\n",
            "person: 54%\t(left_x:  888   top_y:  643   width:   32   height:   60)\n",
            "person: 58%\t(left_x:  892   top_y:  645   width:   25   height:   33)\n",
            "person: 25%\t(left_x:  910   top_y:  646   width:   30   height:   51)\n",
            "person: 32%\t(left_x:  917   top_y:  646   width:   21   height:   30)\n",
            "person: 97%\t(left_x: 1059   top_y:  646   width:   35   height:   67)\n",
            "motorbike: 85%\t(left_x: 1131   top_y:  688   width:   86   height:   68)\n",
            "person: 81%\t(left_x: 1146   top_y:  640   width:   70   height:   98)\n",
            "car: 100%\t(left_x: 1372   top_y:  654   width:  279   height:  106)\n",
            "car: 83%\t(left_x: 1776   top_y:  604   width:  147   height:  197)\n",
            "truck: 30%\t(left_x: 1777   top_y:  601   width:  144   height:  195)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/9.jpg: Predicted in 53.616000 milli-seconds.\n",
            "parking meter: 56%\t(left_x:   28   top_y:  649   width:   73   height:   71)\n",
            "car: 99%\t(left_x:  153   top_y:  647   width:   94   height:   63)\n",
            "car: 48%\t(left_x:  298   top_y:  628   width:   40   height:   15)\n",
            "motorbike: 40%\t(left_x:  432   top_y:  651   width:   26   height:   24)\n",
            "person: 68%\t(left_x:  463   top_y:  632   width:   67   height:   95)\n",
            "motorbike: 66%\t(left_x:  467   top_y:  648   width:   59   height:   93)\n",
            "motorbike: 64%\t(left_x:  472   top_y:  684   width:   51   height:   60)\n",
            "car: 82%\t(left_x:  552   top_y:  651   width:   40   height:   24)\n",
            "motorbike: 53%\t(left_x:  599   top_y:  657   width:   30   height:   25)\n",
            "person: 35%\t(left_x:  599   top_y:  653   width:   29   height:   27)\n",
            "person: 41%\t(left_x:  654   top_y:  648   width:   32   height:   32)\n",
            "motorbike: 81%\t(left_x:  656   top_y:  656   width:   28   height:   35)\n",
            "person: 83%\t(left_x:  860   top_y:  642   width:   32   height:   60)\n",
            "motorbike: 61%\t(left_x:  860   top_y:  670   width:   30   height:   34)\n",
            "motorbike: 67%\t(left_x:  914   top_y:  673   width:   32   height:   31)\n",
            "person: 63%\t(left_x:  916   top_y:  653   width:   28   height:   49)\n",
            "motorbike: 79%\t(left_x:  990   top_y:  679   width:   59   height:   57)\n",
            "person: 29%\t(left_x:  991   top_y:  662   width:   59   height:   74)\n",
            "person: 68%\t(left_x:  996   top_y:  640   width:   51   height:   76)\n",
            "person: 66%\t(left_x: 1055   top_y:  647   width:   28   height:   67)\n",
            "motorbike: 91%\t(left_x: 1148   top_y:  683   width:   51   height:   43)\n",
            "person: 57%\t(left_x: 1153   top_y:  659   width:   46   height:   59)\n",
            "person: 51%\t(left_x: 1156   top_y:  658   width:   41   height:   36)\n",
            "car: 99%\t(left_x: 1381   top_y:  659   width:  278   height:  108)\n",
            "car: 73%\t(left_x: 1788   top_y:  616   width:  134   height:  197)\n",
            "truck: 41%\t(left_x: 1791   top_y:  609   width:  129   height:  196)\n",
            "person: 68%\t(left_x: 1884   top_y:  646   width:   35   height:   31)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/10.jpg: Predicted in 54.698000 milli-seconds.\n",
            "parking meter: 35%\t(left_x:   35   top_y:  652   width:   65   height:   67)\n",
            "car: 99%\t(left_x:  163   top_y:  647   width:   93   height:   63)\n",
            "car: 25%\t(left_x:  252   top_y:  650   width:   27   height:   26)\n",
            "car: 63%\t(left_x:  358   top_y:  644   width:   64   height:   38)\n",
            "car: 33%\t(left_x:  434   top_y:  650   width:   28   height:   20)\n",
            "car: 49%\t(left_x:  453   top_y:  650   width:   31   height:   24)\n",
            "car: 57%\t(left_x:  475   top_y:  651   width:   37   height:   30)\n",
            "motorbike: 29%\t(left_x:  479   top_y:  656   width:   30   height:   27)\n",
            "person: 87%\t(left_x:  496   top_y:  633   width:   68   height:  117)\n",
            "motorbike: 90%\t(left_x:  498   top_y:  672   width:   62   height:   90)\n",
            "car: 39%\t(left_x:  566   top_y:  648   width:   44   height:   30)\n",
            "person: 29%\t(left_x:  566   top_y:  648   width:   44   height:   30)\n",
            "person: 40%\t(left_x:  643   top_y:  648   width:   22   height:   33)\n",
            "motorbike: 60%\t(left_x:  644   top_y:  655   width:   22   height:   32)\n",
            "motorbike: 42%\t(left_x:  841   top_y:  673   width:   30   height:   27)\n",
            "motorbike: 45%\t(left_x:  842   top_y:  650   width:   30   height:   48)\n",
            "person: 47%\t(left_x:  842   top_y:  650   width:   30   height:   48)\n",
            "person: 37%\t(left_x:  851   top_y:  646   width:   28   height:   33)\n",
            "motorbike: 81%\t(left_x:  897   top_y:  679   width:   49   height:   43)\n",
            "person: 25%\t(left_x:  899   top_y:  658   width:   47   height:   62)\n",
            "person: 73%\t(left_x:  911   top_y:  647   width:   33   height:   59)\n",
            "person: 26%\t(left_x:  915   top_y:  648   width:   26   height:   34)\n",
            "person: 91%\t(left_x: 1053   top_y:  648   width:   34   height:   63)\n",
            "motorbike: 88%\t(left_x: 1154   top_y:  679   width:   55   height:   43)\n",
            "person: 70%\t(left_x: 1156   top_y:  655   width:   52   height:   65)\n",
            "car: 100%\t(left_x: 1388   top_y:  654   width:  245   height:  107)\n",
            "truck: 73%\t(left_x: 1599   top_y:  500   width:  324   height:  390)\n",
            "car: 36%\t(left_x: 1603   top_y:  507   width:  316   height:  367)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/11.jpg: Predicted in 54.783000 milli-seconds.\n",
            "stop sign: 45%\t(left_x:   33   top_y:  644   width:   73   height:   67)\n",
            "car: 99%\t(left_x:  160   top_y:  641   width:   94   height:   60)\n",
            "car: 41%\t(left_x:  301   top_y:  644   width:   37   height:   26)\n",
            "car: 39%\t(left_x:  340   top_y:  641   width:   53   height:   47)\n",
            "car: 37%\t(left_x:  349   top_y:  638   width:   72   height:   45)\n",
            "car: 31%\t(left_x:  398   top_y:  645   width:   28   height:   38)\n",
            "motorbike: 34%\t(left_x:  401   top_y:  655   width:   23   height:   32)\n",
            "car: 41%\t(left_x:  451   top_y:  645   width:   41   height:   30)\n",
            "car: 83%\t(left_x:  457   top_y:  645   width:   59   height:   31)\n",
            "person: 91%\t(left_x:  545   top_y:  619   width:   80   height:  141)\n",
            "motorbike: 97%\t(left_x:  545   top_y:  667   width:   80   height:  120)\n",
            "motorbike: 36%\t(left_x:  616   top_y:  643   width:   25   height:   38)\n",
            "person: 30%\t(left_x:  622   top_y:  645   width:   21   height:   34)\n",
            "person: 40%\t(left_x:  754   top_y:  649   width:   15   height:   27)\n",
            "person: 56%\t(left_x:  811   top_y:  640   width:   23   height:   46)\n",
            "motorbike: 28%\t(left_x:  811   top_y:  654   width:   30   height:   47)\n",
            "motorbike: 62%\t(left_x:  813   top_y:  666   width:   38   height:   37)\n",
            "person: 63%\t(left_x:  826   top_y:  637   width:   26   height:   51)\n",
            "motorbike: 53%\t(left_x:  924   top_y:  671   width:   30   height:   27)\n",
            "motorbike: 37%\t(left_x:  924   top_y:  656   width:   28   height:   40)\n",
            "person: 50%\t(left_x:  924   top_y:  644   width:   24   height:   39)\n",
            "person: 97%\t(left_x: 1037   top_y:  645   width:   28   height:   61)\n",
            "motorbike: 72%\t(left_x: 1152   top_y:  677   width:   58   height:   42)\n",
            "person: 34%\t(left_x: 1153   top_y:  664   width:   54   height:   55)\n",
            "person: 35%\t(left_x: 1156   top_y:  654   width:   47   height:   46)\n",
            "truck: 84%\t(left_x: 1213   top_y:  526   width:  596   height:  288)\n",
            "car: 48%\t(left_x: 1805   top_y:  613   width:  117   height:  186)\n",
            "truck: 60%\t(left_x: 1809   top_y:  609   width:  111   height:  187)\n",
            "person: 31%\t(left_x: 1889   top_y:  640   width:   31   height:   31)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/12.jpg: Predicted in 54.759000 milli-seconds.\n",
            "car: 98%\t(left_x:  169   top_y:  639   width:   94   height:   59)\n",
            "car: 59%\t(left_x:  353   top_y:  633   width:   90   height:   52)\n",
            "motorbike: 28%\t(left_x:  355   top_y:  652   width:   36   height:   40)\n",
            "motorbike: 35%\t(left_x:  425   top_y:  650   width:   25   height:   42)\n",
            "car: 69%\t(left_x:  450   top_y:  642   width:   52   height:   29)\n",
            "car: 42%\t(left_x:  501   top_y:  644   width:   30   height:   25)\n",
            "car: 55%\t(left_x:  557   top_y:  643   width:   57   height:   25)\n",
            "motorbike: 40%\t(left_x:  609   top_y:  641   width:   23   height:   31)\n",
            "person: 93%\t(left_x:  637   top_y:  619   width:  106   height:  162)\n",
            "motorbike: 95%\t(left_x:  639   top_y:  669   width:  109   height:  165)\n",
            "motorbike: 68%\t(left_x:  767   top_y:  659   width:   46   height:   34)\n",
            "person: 41%\t(left_x:  770   top_y:  638   width:   33   height:   44)\n",
            "person: 27%\t(left_x:  773   top_y:  634   width:   28   height:   33)\n",
            "motorbike: 53%\t(left_x:  928   top_y:  660   width:   30   height:   35)\n",
            "person: 31%\t(left_x:  930   top_y:  644   width:   24   height:   41)\n",
            "car: 33%\t(left_x: 1009   top_y:  551   width:  399   height:  223)\n",
            "truck: 52%\t(left_x: 1022   top_y:  553   width:  393   height:  219)\n",
            "bus: 41%\t(left_x: 1022   top_y:  553   width:  393   height:  219)\n",
            "car: 100%\t(left_x: 1404   top_y:  650   width:  266   height:  109)\n",
            "car: 86%\t(left_x: 1803   top_y:  612   width:  119   height:  197)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/13.jpg: Predicted in 54.769000 milli-seconds.\n",
            "parking meter: 26%\t(left_x:   51   top_y:  633   width:   76   height:   66)\n",
            "stop sign: 58%\t(left_x:   53   top_y:  633   width:   74   height:   66)\n",
            "car: 94%\t(left_x:  175   top_y:  631   width:   95   height:   62)\n",
            "car: 27%\t(left_x:  295   top_y:  633   width:   32   height:   28)\n",
            "motorbike: 31%\t(left_x:  361   top_y:  636   width:   42   height:   51)\n",
            "car: 67%\t(left_x:  394   top_y:  625   width:   60   height:   47)\n",
            "person: 80%\t(left_x:  445   top_y:  638   width:   28   height:   49)\n",
            "motorbike: 34%\t(left_x:  445   top_y:  638   width:   28   height:   49)\n",
            "car: 78%\t(left_x:  473   top_y:  633   width:   34   height:   29)\n",
            "car: 54%\t(left_x:  503   top_y:  637   width:   33   height:   25)\n",
            "car: 29%\t(left_x:  551   top_y:  636   width:   36   height:   25)\n",
            "car: 34%\t(left_x:  563   top_y:  634   width:   53   height:   30)\n",
            "car: 79%\t(left_x:  661   top_y:  635   width:   57   height:   20)\n",
            "motorbike: 51%\t(left_x:  730   top_y:  644   width:   23   height:   37)\n",
            "car: 41%\t(left_x:  743   top_y:  633   width:   48   height:   24)\n",
            "motorbike: 75%\t(left_x:  777   top_y:  642   width:   24   height:   36)\n",
            "person: 31%\t(left_x:  778   top_y:  631   width:   20   height:   38)\n",
            "motorbike: 96%\t(left_x:  807   top_y:  684   width:  177   height:  253)\n",
            "person: 98%\t(left_x:  808   top_y:  595   width:  144   height:  247)\n",
            "truck: 77%\t(left_x:  924   top_y:  567   width:  261   height:  171)\n",
            "car: 41%\t(left_x:  924   top_y:  567   width:  261   height:  171)\n",
            "motorbike: 53%\t(left_x: 1172   top_y:  660   width:   48   height:   54)\n",
            "person: 36%\t(left_x: 1172   top_y:  644   width:   46   height:   69)\n",
            "car: 100%\t(left_x: 1400   top_y:  642   width:  273   height:  115)\n",
            "car: 85%\t(left_x: 1810   top_y:  604   width:  113   height:  195)\n",
            "truck: 25%\t(left_x: 1811   top_y:  600   width:  110   height:  199)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/14.jpg: Predicted in 54.874000 milli-seconds.\n",
            "car: 98%\t(left_x:  169   top_y:  615   width:   97   height:   64)\n",
            "car: 28%\t(left_x:  259   top_y:  621   width:   28   height:   26)\n",
            "car: 36%\t(left_x:  271   top_y:  621   width:   33   height:   27)\n",
            "car: 52%\t(left_x:  316   top_y:  620   width:   48   height:   29)\n",
            "motorbike: 37%\t(left_x:  357   top_y:  623   width:   41   height:   55)\n",
            "car: 92%\t(left_x:  399   top_y:  611   width:   79   height:   48)\n",
            "person: 34%\t(left_x:  460   top_y:  617   width:   31   height:   62)\n",
            "motorbike: 43%\t(left_x:  462   top_y:  638   width:   28   height:   43)\n",
            "car: 36%\t(left_x:  473   top_y:  618   width:   38   height:   28)\n",
            "car: 43%\t(left_x:  498   top_y:  623   width:   43   height:   25)\n",
            "car: 57%\t(left_x:  522   top_y:  623   width:   32   height:   24)\n",
            "car: 30%\t(left_x:  555   top_y:  623   width:   21   height:   20)\n",
            "car: 53%\t(left_x:  573   top_y:  622   width:   36   height:   29)\n",
            "car: 42%\t(left_x:  601   top_y:  627   width:   44   height:   21)\n",
            "car: 64%\t(left_x:  650   top_y:  621   width:   47   height:   20)\n",
            "car: 38%\t(left_x:  675   top_y:  621   width:   39   height:   24)\n",
            "motorbike: 54%\t(left_x:  691   top_y:  628   width:   23   height:   36)\n",
            "person: 36%\t(left_x:  691   top_y:  628   width:   23   height:   36)\n",
            "motorbike: 79%\t(left_x:  750   top_y:  629   width:   30   height:   35)\n",
            "bus: 78%\t(left_x:  804   top_y:  560   width:  221   height:  143)\n",
            "truck: 42%\t(left_x:  807   top_y:  563   width:  215   height:  139)\n",
            "car: 31%\t(left_x:  807   top_y:  563   width:  215   height:  139)\n",
            "person: 43%\t(left_x: 1011   top_y:  634   width:   22   height:   50)\n",
            "motorbike: 66%\t(left_x: 1162   top_y:  655   width:   56   height:   44)\n",
            "person: 62%\t(left_x: 1169   top_y:  632   width:   44   height:   61)\n",
            "motorbike: 72%\t(left_x: 1254   top_y:  779   width:  655   height:  301)\n",
            "person: 64%\t(left_x: 1267   top_y:  602   width:  126   height:  194)\n",
            "person: 65%\t(left_x: 1383   top_y:  526   width:  190   height:  276)\n",
            "car: 74%\t(left_x: 1483   top_y:  633   width:  187   height:   92)\n",
            "car: 88%\t(left_x: 1802   top_y:  600   width:  120   height:  183)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/15.jpg: Predicted in 54.877000 milli-seconds.\n",
            "car: 99%\t(left_x:  165   top_y:  613   width:   95   height:   63)\n",
            "car: 25%\t(left_x:  255   top_y:  614   width:   33   height:   32)\n",
            "truck: 35%\t(left_x:  312   top_y:  591   width:   57   height:   56)\n",
            "car: 47%\t(left_x:  315   top_y:  616   width:   54   height:   32)\n",
            "motorbike: 49%\t(left_x:  363   top_y:  630   width:   37   height:   55)\n",
            "car: 94%\t(left_x:  407   top_y:  610   width:   67   height:   49)\n",
            "car: 29%\t(left_x:  482   top_y:  612   width:   36   height:   41)\n",
            "person: 32%\t(left_x:  484   top_y:  615   width:   33   height:   64)\n",
            "motorbike: 86%\t(left_x:  485   top_y:  634   width:   32   height:   52)\n",
            "car: 39%\t(left_x:  549   top_y:  621   width:   32   height:   26)\n",
            "person: 27%\t(left_x:  549   top_y:  621   width:   32   height:   26)\n",
            "car: 58%\t(left_x:  566   top_y:  622   width:   39   height:   24)\n",
            "car: 33%\t(left_x:  604   top_y:  625   width:   39   height:   21)\n",
            "car: 50%\t(left_x:  655   top_y:  616   width:   35   height:   26)\n",
            "motorbike: 79%\t(left_x:  656   top_y:  632   width:   20   height:   30)\n",
            "bus: 62%\t(left_x:  727   top_y:  563   width:  189   height:  123)\n",
            "truck: 51%\t(left_x:  737   top_y:  571   width:  171   height:  116)\n",
            "person: 46%\t(left_x:  929   top_y:  621   width:   25   height:   52)\n",
            "bicycle: 33%\t(left_x:  929   top_y:  647   width:   27   height:   29)\n",
            "motorbike: 30%\t(left_x:  929   top_y:  647   width:   27   height:   29)\n",
            "person: 67%\t(left_x: 1000   top_y:  621   width:   25   height:   60)\n",
            "motorbike: 83%\t(left_x: 1154   top_y:  656   width:   56   height:   42)\n",
            "bicycle: 26%\t(left_x: 1155   top_y:  655   width:   55   height:   43)\n",
            "person: 64%\t(left_x: 1157   top_y:  630   width:   53   height:   64)\n",
            "car: 100%\t(left_x: 1391   top_y:  629   width:  268   height:  114)\n",
            "car: 75%\t(left_x: 1796   top_y:  600   width:  126   height:  184)\n",
            "truck: 39%\t(left_x: 1798   top_y:  596   width:  121   height:  185)\n",
            "person: 40%\t(left_x: 1891   top_y:  620   width:   29   height:   31)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/16.jpg: Predicted in 54.775000 milli-seconds.\n",
            "parking meter: 26%\t(left_x:   34   top_y:  608   width:   75   height:   67)\n",
            "car: 99%\t(left_x:  162   top_y:  606   width:   96   height:   58)\n",
            "car: 25%\t(left_x:  246   top_y:  591   width:   32   height:   19)\n",
            "car: 34%\t(left_x:  251   top_y:  601   width:   41   height:   39)\n",
            "car: 28%\t(left_x:  304   top_y:  577   width:   73   height:   63)\n",
            "truck: 62%\t(left_x:  304   top_y:  576   width:   75   height:   62)\n",
            "motorbike: 46%\t(left_x:  371   top_y:  617   width:   47   height:   64)\n",
            "car: 85%\t(left_x:  412   top_y:  596   width:   74   height:   56)\n",
            "car: 26%\t(left_x:  499   top_y:  609   width:   24   height:   21)\n",
            "person: 83%\t(left_x:  513   top_y:  594   width:   46   height:   88)\n",
            "motorbike: 86%\t(left_x:  514   top_y:  632   width:   43   height:   57)\n",
            "car: 58%\t(left_x:  557   top_y:  610   width:   40   height:   22)\n",
            "motorbike: 65%\t(left_x:  625   top_y:  615   width:   20   height:   34)\n",
            "person: 29%\t(left_x:  625   top_y:  615   width:   20   height:   34)\n",
            "car: 52%\t(left_x:  648   top_y:  612   width:   40   height:   17)\n",
            "truck: 82%\t(left_x:  677   top_y:  560   width:  154   height:  109)\n",
            "bus: 27%\t(left_x:  684   top_y:  561   width:  151   height:  108)\n",
            "person: 70%\t(left_x:  925   top_y:  610   width:   26   height:   51)\n",
            "motorbike: 30%\t(left_x:  925   top_y:  631   width:   30   height:   35)\n",
            "person: 89%\t(left_x:  986   top_y:  612   width:   33   height:   58)\n",
            "motorbike: 56%\t(left_x: 1154   top_y:  638   width:   52   height:   48)\n",
            "bicycle: 26%\t(left_x: 1154   top_y:  652   width:   52   height:   36)\n",
            "person: 48%\t(left_x: 1155   top_y:  623   width:   49   height:   54)\n",
            "car: 100%\t(left_x: 1387   top_y:  621   width:  283   height:  109)\n",
            "car: 77%\t(left_x: 1792   top_y:  586   width:  128   height:  204)\n",
            "truck: 37%\t(left_x: 1795   top_y:  581   width:  125   height:  191)\n",
            "person: 41%\t(left_x: 1889   top_y:  611   width:   31   height:   32)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/17.jpg: Predicted in 54.895000 milli-seconds.\n",
            "parking meter: 38%\t(left_x:    7   top_y:  602   width:   78   height:   70)\n",
            "car: 99%\t(left_x:  134   top_y:  600   width:   96   height:   62)\n",
            "car: 31%\t(left_x:  222   top_y:  589   width:   28   height:   22)\n",
            "car: 65%\t(left_x:  286   top_y:  579   width:   73   height:   56)\n",
            "truck: 34%\t(left_x:  287   top_y:  574   width:   67   height:   62)\n",
            "motorbike: 60%\t(left_x:  363   top_y:  623   width:   54   height:   68)\n",
            "car: 92%\t(left_x:  409   top_y:  590   width:   77   height:   64)\n",
            "motorbike: 49%\t(left_x:  495   top_y:  606   width:   31   height:   26)\n",
            "car: 34%\t(left_x:  523   top_y:  608   width:   32   height:   20)\n",
            "motorbike: 69%\t(left_x:  547   top_y:  622   width:   54   height:   82)\n",
            "person: 93%\t(left_x:  550   top_y:  592   width:   50   height:   98)\n",
            "truck: 85%\t(left_x:  614   top_y:  563   width:  139   height:   94)\n",
            "bus: 29%\t(left_x:  615   top_y:  561   width:  148   height:   96)\n",
            "motorbike: 62%\t(left_x:  902   top_y:  628   width:   31   height:   33)\n",
            "person: 34%\t(left_x:  903   top_y:  609   width:   28   height:   49)\n",
            "person: 93%\t(left_x:  955   top_y:  607   width:   27   height:   57)\n",
            "motorbike: 85%\t(left_x: 1132   top_y:  638   width:   53   height:   43)\n",
            "person: 67%\t(left_x: 1133   top_y:  612   width:   52   height:   66)\n",
            "car: 100%\t(left_x: 1363   top_y:  614   width:  270   height:  108)\n",
            "car: 80%\t(left_x: 1765   top_y:  568   width:  157   height:  193)\n",
            "truck: 28%\t(left_x: 1765   top_y:  568   width:  157   height:  193)\n",
            "person: 84%\t(left_x: 1855   top_y:  603   width:   44   height:   34)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/18.jpg: Predicted in 54.815000 milli-seconds.\n",
            "car: 99%\t(left_x:  109   top_y:  620   width:   92   height:   59)\n",
            "car: 37%\t(left_x:  201   top_y:  620   width:   60   height:   33)\n",
            "car: 64%\t(left_x:  258   top_y:  618   width:   56   height:   38)\n",
            "car: 58%\t(left_x:  313   top_y:  621   width:   59   height:   30)\n",
            "motorbike: 80%\t(left_x:  361   top_y:  648   width:   49   height:   75)\n",
            "car: 92%\t(left_x:  399   top_y:  605   width:   90   height:   69)\n",
            "car: 43%\t(left_x:  500   top_y:  623   width:   32   height:   19)\n",
            "car: 47%\t(left_x:  530   top_y:  621   width:   29   height:   24)\n",
            "person: 29%\t(left_x:  530   top_y:  621   width:   29   height:   24)\n",
            "motorbike: 55%\t(left_x:  533   top_y:  631   width:   23   height:   25)\n",
            "car: 35%\t(left_x:  558   top_y:  620   width:   73   height:   46)\n",
            "person: 25%\t(left_x:  561   top_y:  606   width:   24   height:   21)\n",
            "truck: 36%\t(left_x:  564   top_y:  579   width:  121   height:   86)\n",
            "bus: 33%\t(left_x:  564   top_y:  579   width:  121   height:   86)\n",
            "motorbike: 86%\t(left_x:  612   top_y:  648   width:   74   height:  104)\n",
            "person: 84%\t(left_x:  613   top_y:  603   width:   74   height:  134)\n",
            "person: 39%\t(left_x:  830   top_y:  615   width:   15   height:   38)\n",
            "person: 69%\t(left_x:  880   top_y:  622   width:   28   height:   49)\n",
            "bicycle: 53%\t(left_x:  882   top_y:  646   width:   29   height:   27)\n",
            "person: 96%\t(left_x:  926   top_y:  620   width:   23   height:   57)\n",
            "motorbike: 79%\t(left_x: 1112   top_y:  651   width:   53   height:   43)\n",
            "person: 66%\t(left_x: 1115   top_y:  627   width:   48   height:   64)\n",
            "person: 38%\t(left_x: 1122   top_y:  629   width:   39   height:   38)\n",
            "bus: 99%\t(left_x: 1330   top_y:  323   width:  595   height:  528)\n",
            "person: 48%\t(left_x: 1671   top_y:  499   width:   71   height:   59)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/19.jpg: Predicted in 54.738000 milli-seconds.\n",
            "car: 98%\t(left_x:  110   top_y:  623   width:   93   height:   60)\n",
            "car: 74%\t(left_x:  257   top_y:  625   width:   74   height:   36)\n",
            "car: 62%\t(left_x:  330   top_y:  628   width:   57   height:   28)\n",
            "person: 78%\t(left_x:  388   top_y:  607   width:   61   height:  106)\n",
            "motorbike: 95%\t(left_x:  390   top_y:  658   width:   60   height:   92)\n",
            "car: 93%\t(left_x:  432   top_y:  612   width:   87   height:   73)\n",
            "truck: 56%\t(left_x:  532   top_y:  601   width:  105   height:   73)\n",
            "car: 60%\t(left_x:  533   top_y:  622   width:  103   height:   53)\n",
            "person: 52%\t(left_x:  757   top_y:  632   width:   15   height:   32)\n",
            "motorbike: 77%\t(left_x:  778   top_y:  678   width:  123   height:  141)\n",
            "person: 84%\t(left_x:  802   top_y:  608   width:   85   height:  171)\n",
            "person: 67%\t(left_x:  885   top_y:  633   width:   25   height:   48)\n",
            "person: 93%\t(left_x:  917   top_y:  629   width:   23   height:   56)\n",
            "bus: 100%\t(left_x: 1020   top_y:  411   width:  906   height:  406)\n",
            "person: 29%\t(left_x: 1213   top_y:  557   width:   45   height:   39)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/20.jpg: Predicted in 54.724000 milli-seconds.\n",
            "stop sign: 59%\t(left_x:    0   top_y:  622   width:   73   height:   71)\n",
            "car: 99%\t(left_x:  129   top_y:  622   width:   90   height:   60)\n",
            "car: 26%\t(left_x:  214   top_y:  607   width:   35   height:   18)\n",
            "car: 33%\t(left_x:  217   top_y:  619   width:   33   height:   31)\n",
            "car: 87%\t(left_x:  288   top_y:  623   width:   68   height:   39)\n",
            "car: 27%\t(left_x:  359   top_y:  625   width:   50   height:   26)\n",
            "car: 59%\t(left_x:  403   top_y:  623   width:   47   height:   24)\n",
            "person: 64%\t(left_x:  453   top_y:  602   width:   74   height:  120)\n",
            "motorbike: 98%\t(left_x:  455   top_y:  660   width:   77   height:  132)\n",
            "car: 74%\t(left_x:  467   top_y:  604   width:  109   height:   87)\n",
            "truck: 64%\t(left_x:  537   top_y:  592   width:   89   height:   78)\n",
            "car: 34%\t(left_x:  539   top_y:  593   width:   90   height:   74)\n",
            "car: 67%\t(left_x:  618   top_y:  623   width:   57   height:   22)\n",
            "bus: 100%\t(left_x:  873   top_y:  477   width:  582   height:  269)\n",
            "motorbike: 99%\t(left_x: 1173   top_y:  691   width:  331   height:  267)\n",
            "person: 66%\t(left_x: 1235   top_y:  574   width:  121   height:  305)\n",
            "car: 99%\t(left_x: 1450   top_y:  636   width:  171   height:  105)\n",
            "motorbike: 98%\t(left_x: 1601   top_y:  676   width:  167   height:  100)\n",
            "person: 25%\t(left_x: 1644   top_y:  631   width:   78   height:  112)\n",
            "person: 66%\t(left_x: 1670   top_y:  630   width:   67   height:   91)\n",
            "truck: 62%\t(left_x: 1759   top_y:  568   width:  164   height:  203)\n",
            "motorbike: 57%\t(left_x: 1828   top_y:  688   width:   95   height:   93)\n",
            "person: 67%\t(left_x: 1858   top_y:  656   width:   65   height:   92)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/21.jpg: Predicted in 54.776000 milli-seconds.\n",
            "parking meter: 31%\t(left_x:   12   top_y:  641   width:   73   height:   71)\n",
            "car: 98%\t(left_x:  138   top_y:  640   width:   95   height:   62)\n",
            "car: 45%\t(left_x:  307   top_y:  640   width:   56   height:   40)\n",
            "car: 41%\t(left_x:  340   top_y:  643   width:   50   height:   37)\n",
            "car: 37%\t(left_x:  367   top_y:  643   width:   35   height:   38)\n",
            "car: 53%\t(left_x:  488   top_y:  620   width:  104   height:   96)\n",
            "person: 76%\t(left_x:  517   top_y:  620   width:  116   height:   93)\n",
            "car: 40%\t(left_x:  517   top_y:  620   width:  116   height:   93)\n",
            "motorbike: 94%\t(left_x:  543   top_y:  684   width:  110   height:  173)\n",
            "bus: 100%\t(left_x:  776   top_y:  517   width:  405   height:  225)\n",
            "motorbike: 90%\t(left_x: 1370   top_y:  680   width:  134   height:   80)\n",
            "car: 51%\t(left_x: 1376   top_y:  640   width:  230   height:  108)\n",
            "person: 91%\t(left_x: 1405   top_y:  638   width:   75   height:  100)\n",
            "motorbike: 93%\t(left_x: 1543   top_y:  680   width:  124   height:   92)\n",
            "person: 90%\t(left_x: 1558   top_y:  639   width:   89   height:  115)\n",
            "car: 65%\t(left_x: 1768   top_y:  596   width:  154   height:  198)\n",
            "truck: 42%\t(left_x: 1768   top_y:  596   width:  154   height:  198)\n",
            "person: 26%\t(left_x: 1860   top_y:  628   width:   43   height:   38)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/22.jpg: Predicted in 54.768000 milli-seconds.\n",
            "parking meter: 60%\t(left_x:   31   top_y:  647   width:   71   height:   66)\n",
            "car: 98%\t(left_x:  158   top_y:  644   width:   93   height:   59)\n",
            "car: 56%\t(left_x:  242   top_y:  632   width:   35   height:   35)\n",
            "car: 26%\t(left_x:  246   top_y:  642   width:   29   height:   28)\n",
            "motorbike: 25%\t(left_x:  322   top_y:  655   width:   23   height:   34)\n",
            "car: 74%\t(left_x:  325   top_y:  640   width:   67   height:   46)\n",
            "car: 46%\t(left_x:  384   top_y:  635   width:   52   height:   54)\n",
            "car: 37%\t(left_x:  453   top_y:  645   width:   32   height:   21)\n",
            "car: 78%\t(left_x:  478   top_y:  646   width:   31   height:   22)\n",
            "car: 63%\t(left_x:  508   top_y:  646   width:   37   height:   33)\n",
            "car: 99%\t(left_x:  544   top_y:  620   width:  176   height:  116)\n",
            "bus: 99%\t(left_x:  717   top_y:  542   width:  288   height:  176)\n",
            "motorbike: 90%\t(left_x:  723   top_y:  707   width:  181   height:  272)\n",
            "person: 85%\t(left_x:  724   top_y:  609   width:  154   height:  270)\n",
            "motorbike: 74%\t(left_x: 1149   top_y:  665   width:   52   height:   49)\n",
            "person: 67%\t(left_x: 1152   top_y:  647   width:   48   height:   63)\n",
            "motorbike: 82%\t(left_x: 1237   top_y:  666   width:   84   height:   78)\n",
            "person: 76%\t(left_x: 1240   top_y:  642   width:   77   height:   95)\n",
            "motorbike: 64%\t(left_x: 1357   top_y:  683   width:   82   height:   66)\n",
            "person: 83%\t(left_x: 1357   top_y:  639   width:   74   height:  105)\n",
            "car: 98%\t(left_x: 1412   top_y:  646   width:  243   height:  106)\n",
            "car: 88%\t(left_x: 1788   top_y:  605   width:  134   height:  194)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/23.jpg: Predicted in 54.765000 milli-seconds.\n",
            "parking meter: 28%\t(left_x:   31   top_y:  644   width:   66   height:   68)\n",
            "car: 97%\t(left_x:  153   top_y:  641   width:   94   height:   60)\n",
            "car: 28%\t(left_x:  236   top_y:  645   width:   24   height:   23)\n",
            "car: 31%\t(left_x:  239   top_y:  627   width:   35   height:   40)\n",
            "truck: 27%\t(left_x:  318   top_y:  601   width:   81   height:   85)\n",
            "bus: 50%\t(left_x:  320   top_y:  600   width:   76   height:   85)\n",
            "motorbike: 28%\t(left_x:  323   top_y:  653   width:   22   height:   39)\n",
            "car: 30%\t(left_x:  324   top_y:  638   width:   73   height:   47)\n",
            "motorbike: 44%\t(left_x:  416   top_y:  652   width:   38   height:   43)\n",
            "car: 48%\t(left_x:  453   top_y:  641   width:   32   height:   21)\n",
            "car: 28%\t(left_x:  488   top_y:  623   width:  102   height:   53)\n",
            "truck: 71%\t(left_x:  489   top_y:  620   width:  101   height:   57)\n",
            "car: 96%\t(left_x:  601   top_y:  610   width:  225   height:  146)\n",
            "bus: 34%\t(left_x:  613   top_y:  575   width:  221   height:  181)\n",
            "bus: 97%\t(left_x:  652   top_y:  547   width:  239   height:  145)\n",
            "person: 77%\t(left_x:  914   top_y:  632   width:   29   height:   59)\n",
            "motorbike: 56%\t(left_x: 1119   top_y:  674   width:   72   height:   50)\n",
            "person: 80%\t(left_x: 1122   top_y:  634   width:   63   height:   74)\n",
            "motorbike: 51%\t(left_x: 1160   top_y:  791   width:  750   height:  287)\n",
            "person: 59%\t(left_x: 1192   top_y:  551   width:  704   height:  523)\n",
            "motorbike: 62%\t(left_x: 1198   top_y:  678   width:   60   height:   49)\n",
            "person: 72%\t(left_x: 1203   top_y:  633   width:   50   height:   86)\n",
            "car: 99%\t(left_x: 1411   top_y:  644   width:  239   height:  102)\n",
            "motorbike: 97%\t(left_x: 1697   top_y:  691   width:  215   height:  104)\n",
            "person: 76%\t(left_x: 1756   top_y:  628   width:   75   height:  133)\n",
            "person: 82%\t(left_x: 1782   top_y:  624   width:  103   height:  142)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/24.jpg: Predicted in 54.777000 milli-seconds.\n",
            "car: 99%\t(left_x:  159   top_y:  650   width:   92   height:   62)\n",
            "car: 65%\t(left_x:  241   top_y:  638   width:   38   height:   41)\n",
            "motorbike: 49%\t(left_x:  328   top_y:  652   width:   32   height:   50)\n",
            "person: 31%\t(left_x:  329   top_y:  640   width:   26   height:   43)\n",
            "car: 30%\t(left_x:  334   top_y:  651   width:   67   height:   42)\n",
            "person: 75%\t(left_x:  447   top_y:  635   width:   52   height:   82)\n",
            "motorbike: 86%\t(left_x:  449   top_y:  672   width:   49   height:   55)\n",
            "car: 54%\t(left_x:  492   top_y:  630   width:   65   height:   57)\n",
            "truck: 61%\t(left_x:  493   top_y:  633   width:   67   height:   53)\n",
            "car: 53%\t(left_x:  558   top_y:  652   width:   37   height:   24)\n",
            "bus: 95%\t(left_x:  608   top_y:  573   width:  192   height:  129)\n",
            "car: 88%\t(left_x:  695   top_y:  614   width:  307   height:  187)\n",
            "truck: 38%\t(left_x:  695   top_y:  614   width:  307   height:  187)\n",
            "person: 72%\t(left_x: 1032   top_y:  645   width:   51   height:   70)\n",
            "motorbike: 58%\t(left_x: 1038   top_y:  682   width:   67   height:   42)\n",
            "motorbike: 44%\t(left_x: 1063   top_y:  680   width:   71   height:   46)\n",
            "person: 80%\t(left_x: 1081   top_y:  644   width:   49   height:   83)\n",
            "motorbike: 82%\t(left_x: 1151   top_y:  680   width:   53   height:   42)\n",
            "person: 78%\t(left_x: 1151   top_y:  656   width:   51   height:   64)\n",
            "car: 39%\t(left_x: 1407   top_y:  648   width:  253   height:  107)\n",
            "motorbike: 90%\t(left_x: 1411   top_y:  687   width:  140   height:   88)\n",
            "person: 94%\t(left_x: 1453   top_y:  638   width:   76   height:  113)\n",
            "car: 27%\t(left_x: 1521   top_y:  656   width:  125   height:   99)\n",
            "car: 99%\t(left_x: 1600   top_y:  622   width:  319   height:  247)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/25.jpg: Predicted in 54.893000 milli-seconds.\n",
            "car: 97%\t(left_x:  157   top_y:  646   width:   94   height:   59)\n",
            "car: 34%\t(left_x:  244   top_y:  643   width:   30   height:   29)\n",
            "person: 59%\t(left_x:  330   top_y:  635   width:   34   height:   56)\n",
            "motorbike: 50%\t(left_x:  332   top_y:  646   width:   34   height:   55)\n",
            "motorbike: 35%\t(left_x:  334   top_y:  663   width:   30   height:   47)\n",
            "car: 63%\t(left_x:  355   top_y:  645   width:   54   height:   40)\n",
            "car: 26%\t(left_x:  407   top_y:  643   width:   64   height:   35)\n",
            "person: 95%\t(left_x:  492   top_y:  623   width:   61   height:  105)\n",
            "motorbike: 94%\t(left_x:  496   top_y:  666   width:   57   height:   76)\n",
            "bus: 98%\t(left_x:  575   top_y:  576   width:  171   height:  119)\n",
            "car: 99%\t(left_x:  843   top_y:  589   width:  479   height:  267)\n",
            "person: 73%\t(left_x: 1251   top_y:  633   width:   50   height:   48)\n",
            "car: 100%\t(left_x: 1274   top_y:  624   width:  402   height:  178)\n",
            "motorbike: 70%\t(left_x: 1724   top_y:  678   width:  198   height:  131)\n",
            "person: 52%\t(left_x: 1762   top_y:  617   width:  104   height:  147)\n",
            "person: 26%\t(left_x: 1790   top_y:  618   width:   84   height:  112)\n",
            "person: 26%\t(left_x: 1886   top_y:  629   width:   33   height:   32)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/26.jpg: Predicted in 54.740000 milli-seconds.\n",
            "car: 99%\t(left_x:  163   top_y:  646   width:   90   height:   61)\n",
            "car: 27%\t(left_x:  247   top_y:  633   width:   32   height:   29)\n",
            "car: 50%\t(left_x:  248   top_y:  646   width:   30   height:   30)\n",
            "motorbike: 29%\t(left_x:  248   top_y:  646   width:   30   height:   30)\n",
            "bus: 47%\t(left_x:  336   top_y:  593   width:   96   height:   93)\n",
            "person: 48%\t(left_x:  341   top_y:  635   width:   38   height:   57)\n",
            "motorbike: 83%\t(left_x:  341   top_y:  661   width:   41   height:   55)\n",
            "car: 46%\t(left_x:  424   top_y:  641   width:   55   height:   37)\n",
            "car: 83%\t(left_x:  472   top_y:  632   width:   54   height:   47)\n",
            "car: 35%\t(left_x:  525   top_y:  648   width:   26   height:   21)\n",
            "bus: 95%\t(left_x:  549   top_y:  583   width:  156   height:  103)\n",
            "person: 96%\t(left_x:  574   top_y:  629   width:   79   height:  140)\n",
            "motorbike: 85%\t(left_x:  578   top_y:  677   width:   75   height:  117)\n",
            "person: 70%\t(left_x:  690   top_y:  632   width:   25   height:   55)\n",
            "person: 31%\t(left_x:  870   top_y:  638   width:   19   height:   37)\n",
            "person: 82%\t(left_x:  906   top_y:  634   width:   40   height:   50)\n",
            "motorbike: 68%\t(left_x:  910   top_y:  668   width:   43   height:   32)\n",
            "car: 96%\t(left_x: 1020   top_y:  633   width:  139   height:  117)\n",
            "car: 97%\t(left_x: 1133   top_y:  545   width:  778   height:  493)\n",
            "car: 34%\t(left_x: 1822   top_y:  601   width:   99   height:  131)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/27.jpg: Predicted in 54.817000 milli-seconds.\n",
            "stop sign: 51%\t(left_x:   52   top_y:  652   width:   72   height:   69)\n",
            "car: 99%\t(left_x:  179   top_y:  648   width:   88   height:   61)\n",
            "car: 50%\t(left_x:  259   top_y:  647   width:   32   height:   31)\n",
            "bus: 36%\t(left_x:  358   top_y:  585   width:  103   height:  104)\n",
            "motorbike: 80%\t(left_x:  363   top_y:  662   width:   47   height:   59)\n",
            "person: 57%\t(left_x:  364   top_y:  635   width:   40   height:   57)\n",
            "car: 32%\t(left_x:  445   top_y:  645   width:   58   height:   41)\n",
            "car: 28%\t(left_x:  466   top_y:  638   width:   58   height:   43)\n",
            "bus: 95%\t(left_x:  542   top_y:  592   width:  135   height:   92)\n",
            "person: 76%\t(left_x:  662   top_y:  639   width:   23   height:   47)\n",
            "car: 55%\t(left_x:  680   top_y:  639   width:   34   height:   23)\n",
            "motorbike: 82%\t(left_x:  719   top_y:  672   width:   66   height:   85)\n",
            "person: 30%\t(left_x:  727   top_y:  632   width:   47   height:   87)\n",
            "person: 45%\t(left_x:  730   top_y:  635   width:   41   height:   45)\n",
            "person: 36%\t(left_x:  766   top_y:  600   width:   59   height:   83)\n",
            "person: 98%\t(left_x:  776   top_y:  608   width:  132   height:  233)\n",
            "motorbike: 88%\t(left_x:  776   top_y:  706   width:  126   height:  199)\n",
            "car: 100%\t(left_x:  895   top_y:  635   width:  216   height:  102)\n",
            "motorbike: 94%\t(left_x: 1130   top_y:  666   width:   87   height:   69)\n",
            "person: 69%\t(left_x: 1136   top_y:  634   width:   75   height:   83)\n",
            "car: 92%\t(left_x: 1400   top_y:  642   width:  180   height:   98)\n",
            "motorbike: 83%\t(left_x: 1511   top_y:  693   width:  190   height:  107)\n",
            "person: 84%\t(left_x: 1537   top_y:  619   width:  101   height:  134)\n",
            "person: 76%\t(left_x: 1603   top_y:  626   width:   95   height:  131)\n",
            "person: 65%\t(left_x: 1674   top_y:  629   width:   58   height:  126)\n",
            "car: 61%\t(left_x: 1805   top_y:  598   width:  116   height:  185)\n",
            "truck: 52%\t(left_x: 1808   top_y:  598   width:  113   height:  182)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/28.jpg: Predicted in 54.781000 milli-seconds.\n",
            "car: 99%\t(left_x:  176   top_y:  653   width:   89   height:   62)\n",
            "car: 51%\t(left_x:  255   top_y:  646   width:   38   height:   35)\n",
            "person: 33%\t(left_x:  322   top_y:  658   width:   21   height:   29)\n",
            "motorbike: 29%\t(left_x:  322   top_y:  658   width:   21   height:   29)\n",
            "bus: 69%\t(left_x:  369   top_y:  582   width:  117   height:  118)\n",
            "person: 67%\t(left_x:  370   top_y:  637   width:   56   height:   78)\n",
            "person: 44%\t(left_x:  372   top_y:  659   width:   54   height:   80)\n",
            "motorbike: 68%\t(left_x:  374   top_y:  668   width:   50   height:   74)\n",
            "car: 26%\t(left_x:  417   top_y:  648   width:   56   height:   53)\n",
            "bus: 92%\t(left_x:  521   top_y:  599   width:  118   height:   89)\n",
            "truck: 31%\t(left_x:  521   top_y:  599   width:  118   height:   89)\n",
            "person: 50%\t(left_x:  629   top_y:  645   width:   24   height:   40)\n",
            "car: 48%\t(left_x:  662   top_y:  645   width:   50   height:   23)\n",
            "car: 99%\t(left_x:  798   top_y:  637   width:  170   height:   84)\n",
            "person: 43%\t(left_x:  958   top_y:  638   width:   31   height:   71)\n",
            "motorbike: 37%\t(left_x:  960   top_y:  666   width:   31   height:   47)\n",
            "motorbike: 93%\t(left_x:  973   top_y:  683   width:  131   height:  139)\n",
            "person: 79%\t(left_x:  985   top_y:  618   width:   91   height:  156)\n",
            "motorbike: 87%\t(left_x: 1164   top_y:  671   width:   55   height:   44)\n",
            "person: 74%\t(left_x: 1169   top_y:  645   width:   48   height:   61)\n",
            "motorbike: 95%\t(left_x: 1230   top_y:  683   width:  109   height:   82)\n",
            "person: 71%\t(left_x: 1248   top_y:  621   width:   81   height:  114)\n",
            "motorbike: 87%\t(left_x: 1347   top_y:  676   width:  104   height:   79)\n",
            "person: 59%\t(left_x: 1359   top_y:  628   width:   89   height:  102)\n",
            "car: 87%\t(left_x: 1445   top_y:  642   width:  150   height:  101)\n",
            "person: 26%\t(left_x: 1521   top_y:  571   width:  248   height:  414)\n",
            "person: 79%\t(left_x: 1530   top_y:  503   width:  398   height:  571)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/29.jpg: Predicted in 54.708000 milli-seconds.\n",
            "car: 99%\t(left_x:  170   top_y:  655   width:   96   height:   61)\n",
            "car: 32%\t(left_x:  256   top_y:  644   width:   36   height:   37)\n",
            "car: 48%\t(left_x:  257   top_y:  659   width:   34   height:   24)\n",
            "car: 25%\t(left_x:  297   top_y:  659   width:   29   height:   35)\n",
            "motorbike: 35%\t(left_x:  323   top_y:  660   width:   25   height:   31)\n",
            "car: 29%\t(left_x:  327   top_y:  651   width:   28   height:   20)\n",
            "bus: 71%\t(left_x:  367   top_y:  576   width:  145   height:  138)\n",
            "person: 90%\t(left_x:  391   top_y:  641   width:   59   height:  101)\n",
            "motorbike: 93%\t(left_x:  393   top_y:  680   width:   59   height:   87)\n",
            "bus: 94%\t(left_x:  518   top_y:  604   width:   98   height:   86)\n",
            "car: 41%\t(left_x:  606   top_y:  650   width:   30   height:   25)\n",
            "car: 34%\t(left_x:  621   top_y:  653   width:   31   height:   21)\n",
            "car: 32%\t(left_x:  645   top_y:  649   width:   55   height:   22)\n",
            "car: 27%\t(left_x:  662   top_y:  649   width:   50   height:   21)\n",
            "car: 99%\t(left_x:  732   top_y:  644   width:  134   height:   70)\n",
            "person: 42%\t(left_x:  885   top_y:  644   width:   31   height:   58)\n",
            "motorbike: 77%\t(left_x:  895   top_y:  671   width:   62   height:   44)\n",
            "person: 60%\t(left_x:  901   top_y:  638   width:   47   height:   68)\n",
            "person: 47%\t(left_x:  914   top_y:  641   width:   28   height:   35)\n",
            "motorbike: 80%\t(left_x: 1056   top_y:  683   width:   73   height:   64)\n",
            "motorbike: 39%\t(left_x: 1060   top_y:  638   width:   70   height:  101)\n",
            "person: 76%\t(left_x: 1065   top_y:  637   width:   67   height:   99)\n",
            "motorbike: 28%\t(left_x: 1160   top_y:  665   width:   45   height:   55)\n",
            "motorbike: 72%\t(left_x: 1188   top_y:  692   width:   79   height:   49)\n",
            "motorbike: 48%\t(left_x: 1191   top_y:  650   width:   74   height:   88)\n",
            "person: 63%\t(left_x: 1200   top_y:  637   width:   60   height:   85)\n",
            "car: 99%\t(left_x: 1397   top_y:  647   width:  278   height:  107)\n",
            "car: 39%\t(left_x: 1748   top_y:  600   width:  172   height:  432)\n",
            "motorbike: 30%\t(left_x: 1748   top_y:  600   width:  172   height:  432)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/30.jpg: Predicted in 54.690000 milli-seconds.\n",
            "car: 99%\t(left_x:  163   top_y:  663   width:   96   height:   59)\n",
            "car: 69%\t(left_x:  253   top_y:  663   width:   33   height:   28)\n",
            "car: 49%\t(left_x:  317   top_y:  664   width:   37   height:   32)\n",
            "motorbike: 27%\t(left_x:  318   top_y:  668   width:   31   height:   31)\n",
            "bus: 75%\t(left_x:  378   top_y:  581   width:  161   height:  135)\n",
            "person: 26%\t(left_x:  423   top_y:  647   width:   76   height:  101)\n",
            "motorbike: 90%\t(left_x:  427   top_y:  688   width:   78   height:  117)\n",
            "person: 31%\t(left_x:  429   top_y:  661   width:   71   height:  134)\n",
            "bus: 32%\t(left_x:  526   top_y:  620   width:   55   height:   77)\n",
            "car: 52%\t(left_x:  596   top_y:  663   width:   47   height:   21)\n",
            "car: 33%\t(left_x:  647   top_y:  660   width:   48   height:   19)\n",
            "car: 97%\t(left_x:  673   top_y:  652   width:  118   height:   64)\n",
            "person: 70%\t(left_x:  826   top_y:  650   width:   44   height:   52)\n",
            "motorbike: 81%\t(left_x:  826   top_y:  669   width:   42   height:   44)\n",
            "person: 86%\t(left_x:  889   top_y:  652   width:   23   height:   51)\n",
            "motorbike: 43%\t(left_x:  932   top_y:  680   width:   49   height:   56)\n",
            "person: 91%\t(left_x:  944   top_y:  647   width:   49   height:   82)\n",
            "motorbike: 71%\t(left_x: 1069   top_y:  693   width:   59   height:   44)\n",
            "bicycle: 62%\t(left_x: 1069   top_y:  692   width:   59   height:   46)\n",
            "person: 77%\t(left_x: 1071   top_y:  647   width:   63   height:   80)\n",
            "motorbike: 76%\t(left_x: 1155   top_y:  685   width:   54   height:   42)\n",
            "bicycle: 26%\t(left_x: 1157   top_y:  693   width:   53   height:   36)\n",
            "person: 77%\t(left_x: 1157   top_y:  659   width:   50   height:   64)\n",
            "car: 100%\t(left_x: 1391   top_y:  656   width:  271   height:  109)\n",
            "car: 77%\t(left_x: 1796   top_y:  613   width:  126   height:  191)\n",
            "truck: 38%\t(left_x: 1799   top_y:  611   width:  122   height:  189)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/31.jpg: Predicted in 55.192000 milli-seconds.\n",
            "car: 99%\t(left_x:  167   top_y:  668   width:   92   height:   61)\n",
            "car: 29%\t(left_x:  321   top_y:  665   width:   45   height:   28)\n",
            "car: 69%\t(left_x:  324   top_y:  669   width:   39   height:   38)\n",
            "car: 28%\t(left_x:  356   top_y:  666   width:   27   height:   23)\n",
            "bus: 95%\t(left_x:  391   top_y:  576   width:  186   height:  154)\n",
            "person: 90%\t(left_x:  496   top_y:  646   width:  104   height:  170)\n",
            "motorbike: 84%\t(left_x:  499   top_y:  708   width:   99   height:  158)\n",
            "car: 33%\t(left_x:  575   top_y:  663   width:   36   height:   32)\n",
            "motorbike: 29%\t(left_x:  579   top_y:  667   width:   31   height:   37)\n",
            "car: 94%\t(left_x:  637   top_y:  662   width:  101   height:   53)\n",
            "person: 35%\t(left_x:  737   top_y:  661   width:   21   height:   34)\n",
            "motorbike: 47%\t(left_x:  737   top_y:  674   width:   21   height:   32)\n",
            "person: 29%\t(left_x:  737   top_y:  674   width:   21   height:   32)\n",
            "person: 40%\t(left_x:  780   top_y:  671   width:   35   height:   43)\n",
            "motorbike: 94%\t(left_x:  781   top_y:  684   width:   34   height:   31)\n",
            "person: 77%\t(left_x:  782   top_y:  653   width:   30   height:   48)\n",
            "motorbike: 76%\t(left_x:  852   top_y:  683   width:   46   height:   49)\n",
            "person: 88%\t(left_x:  852   top_y:  648   width:   51   height:   77)\n",
            "motorbike: 65%\t(left_x:  926   top_y:  686   width:   29   height:   29)\n",
            "person: 29%\t(left_x:  926   top_y:  664   width:   27   height:   50)\n",
            "person: 27%\t(left_x:  928   top_y:  661   width:   22   height:   36)\n",
            "person: 66%\t(left_x:  983   top_y:  652   width:   50   height:   71)\n",
            "motorbike: 50%\t(left_x:  984   top_y:  693   width:   48   height:   40)\n",
            "motorbike: 60%\t(left_x: 1157   top_y:  693   width:   55   height:   39)\n",
            "person: 60%\t(left_x: 1158   top_y:  665   width:   48   height:   54)\n",
            "car: 99%\t(left_x: 1393   top_y:  658   width:  233   height:  101)\n",
            "car: 94%\t(left_x: 1523   top_y:  598   width:  397   height:  262)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/32.jpg: Predicted in 54.697000 milli-seconds.\n",
            "car: 99%\t(left_x:  168   top_y:  664   width:   93   height:   60)\n",
            "car: 30%\t(left_x:  254   top_y:  661   width:   37   height:   32)\n",
            "car: 66%\t(left_x:  319   top_y:  657   width:   50   height:   44)\n",
            "car: 49%\t(left_x:  354   top_y:  651   width:   32   height:   47)\n",
            "car: 64%\t(left_x:  394   top_y:  655   width:   34   height:   44)\n",
            "bus: 97%\t(left_x:  417   top_y:  555   width:  219   height:  187)\n",
            "person: 98%\t(left_x:  639   top_y:  619   width:  173   height:  279)\n",
            "motorbike: 92%\t(left_x:  640   top_y:  730   width:  174   height:  260)\n",
            "person: 80%\t(left_x:  794   top_y:  646   width:   36   height:   58)\n",
            "motorbike: 46%\t(left_x:  794   top_y:  671   width:   36   height:   43)\n",
            "person: 85%\t(left_x:  860   top_y:  655   width:   17   height:   43)\n",
            "person: 89%\t(left_x:  883   top_y:  650   width:   20   height:   50)\n",
            "person: 29%\t(left_x:  920   top_y:  660   width:   44   height:   60)\n",
            "motorbike: 78%\t(left_x:  923   top_y:  682   width:   41   height:   36)\n",
            "person: 71%\t(left_x:  926   top_y:  647   width:   41   height:   59)\n",
            "motorbike: 75%\t(left_x: 1158   top_y:  673   width:   50   height:   53)\n",
            "person: 42%\t(left_x: 1159   top_y:  659   width:   52   height:   67)\n",
            "car: 99%\t(left_x: 1190   top_y:  617   width:  435   height:  180)\n",
            "car: 84%\t(left_x: 1801   top_y:  604   width:  121   height:  194)\n",
            "truck: 30%\t(left_x: 1802   top_y:  602   width:  118   height:  195)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/33.jpg: Predicted in 54.735000 milli-seconds.\n",
            "car: 99%\t(left_x:  162   top_y:  667   width:   91   height:   61)\n",
            "car: 31%\t(left_x:  246   top_y:  659   width:   39   height:   36)\n",
            "car: 31%\t(left_x:  318   top_y:  675   width:   25   height:   33)\n",
            "car: 60%\t(left_x:  361   top_y:  667   width:   27   height:   39)\n",
            "car: 54%\t(left_x:  406   top_y:  656   width:   36   height:   47)\n",
            "bus: 100%\t(left_x:  432   top_y:  531   width:  276   height:  228)\n",
            "person: 33%\t(left_x:  615   top_y:  609   width:   47   height:   39)\n",
            "person: 33%\t(left_x:  716   top_y:  651   width:   21   height:   48)\n",
            "person: 78%\t(left_x:  732   top_y:  651   width:   32   height:   55)\n",
            "bicycle: 54%\t(left_x:  733   top_y:  683   width:   33   height:   30)\n",
            "motorbike: 36%\t(left_x:  733   top_y:  683   width:   33   height:   30)\n",
            "person: 70%\t(left_x:  856   top_y:  655   width:   24   height:   47)\n",
            "person: 34%\t(left_x:  857   top_y:  665   width:   30   height:   46)\n",
            "motorbike: 25%\t(left_x:  857   top_y:  665   width:   30   height:   46)\n",
            "motorbike: 40%\t(left_x:  864   top_y:  685   width:   32   height:   28)\n",
            "person: 39%\t(left_x:  881   top_y:  648   width:   25   height:   53)\n",
            "motorbike: 53%\t(left_x:  923   top_y:  678   width:   31   height:   31)\n",
            "person: 61%\t(left_x:  925   top_y:  654   width:   26   height:   48)\n",
            "car: 94%\t(left_x:  998   top_y:  631   width:  168   height:  120)\n",
            "person: 66%\t(left_x: 1074   top_y:  576   width:  623   height:  500)\n",
            "motorbike: 32%\t(left_x: 1099   top_y:  812   width:  705   height:  266)\n",
            "car: 100%\t(left_x: 1389   top_y:  653   width:  282   height:  106)\n",
            "car: 89%\t(left_x: 1794   top_y:  605   width:  128   height:  190)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/34.jpg: Predicted in 54.730000 milli-seconds.\n",
            "car: 96%\t(left_x:  158   top_y:  667   width:   91   height:   62)\n",
            "car: 26%\t(left_x:  240   top_y:  653   width:   38   height:   43)\n",
            "car: 33%\t(left_x:  312   top_y:  671   width:   27   height:   41)\n",
            "person: 28%\t(left_x:  312   top_y:  671   width:   27   height:   41)\n",
            "car: 63%\t(left_x:  362   top_y:  670   width:   28   height:   39)\n",
            "car: 94%\t(left_x:  413   top_y:  657   width:   56   height:   47)\n",
            "bus: 100%\t(left_x:  466   top_y:  510   width:  347   height:  273)\n",
            "person: 53%\t(left_x:  826   top_y:  654   width:   29   height:   50)\n",
            "person: 26%\t(left_x:  859   top_y:  658   width:   18   height:   36)\n",
            "car: 73%\t(left_x:  861   top_y:  636   width:  227   height:  112)\n",
            "truck: 59%\t(left_x:  867   top_y:  640   width:  222   height:  104)\n",
            "motorbike: 77%\t(left_x: 1149   top_y:  683   width:   53   height:   46)\n",
            "person: 54%\t(left_x: 1155   top_y:  663   width:   45   height:   55)\n",
            "car: 99%\t(left_x: 1385   top_y:  656   width:  242   height:  106)\n",
            "motorbike: 72%\t(left_x: 1584   top_y:  698   width:  178   height:   96)\n",
            "person: 55%\t(left_x: 1602   top_y:  651   width:   97   height:  129)\n",
            "truck: 57%\t(left_x: 1791   top_y:  610   width:  130   height:  193)\n",
            "car: 56%\t(left_x: 1791   top_y:  610   width:  130   height:  193)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/35.jpg: Predicted in 54.840000 milli-seconds.\n",
            "parking meter: 32%\t(left_x:   30   top_y:  673   width:   69   height:   68)\n",
            "person: 37%\t(left_x:  112   top_y:  668   width:   19   height:   46)\n",
            "car: 95%\t(left_x:  150   top_y:  669   width:   97   height:   60)\n",
            "car: 32%\t(left_x:  231   top_y:  675   width:   27   height:   22)\n",
            "car: 54%\t(left_x:  313   top_y:  670   width:   51   height:   42)\n",
            "car: 32%\t(left_x:  313   top_y:  673   width:   26   height:   38)\n",
            "truck: 38%\t(left_x:  419   top_y:  653   width:   79   height:   56)\n",
            "car: 84%\t(left_x:  420   top_y:  657   width:   74   height:   53)\n",
            "bus: 100%\t(left_x:  516   top_y:  463   width:  461   height:  354)\n",
            "motorbike: 74%\t(left_x: 1145   top_y:  687   width:   53   height:   42)\n",
            "person: 74%\t(left_x: 1152   top_y:  660   width:   45   height:   60)\n",
            "person: 37%\t(left_x: 1156   top_y:  660   width:   38   height:   35)\n",
            "motorbike: 48%\t(left_x: 1354   top_y:  685   width:   90   height:   83)\n",
            "person: 73%\t(left_x: 1361   top_y:  648   width:   72   height:  101)\n",
            "motorbike: 64%\t(left_x: 1402   top_y:  667   width:  197   height:  121)\n",
            "car: 57%\t(left_x: 1429   top_y:  649   width:  201   height:  118)\n",
            "person: 86%\t(left_x: 1443   top_y:  641   width:  128   height:  129)\n",
            "car: 76%\t(left_x: 1789   top_y:  608   width:  133   height:  197)\n",
            "truck: 40%\t(left_x: 1791   top_y:  607   width:  129   height:  193)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/36.jpg: Predicted in 54.764000 milli-seconds.\n",
            "parking meter: 64%\t(left_x:   26   top_y:  669   width:   77   height:   67)\n",
            "person: 30%\t(left_x:  107   top_y:  664   width:   22   height:   45)\n",
            "car: 99%\t(left_x:  152   top_y:  663   width:   97   height:   63)\n",
            "car: 34%\t(left_x:  248   top_y:  663   width:   38   height:   28)\n",
            "car: 84%\t(left_x:  275   top_y:  663   width:   34   height:   28)\n",
            "person: 56%\t(left_x:  315   top_y:  659   width:   32   height:   58)\n",
            "motorbike: 50%\t(left_x:  315   top_y:  659   width:   32   height:   58)\n",
            "car: 34%\t(left_x:  316   top_y:  658   width:   43   height:   38)\n",
            "car: 43%\t(left_x:  341   top_y:  662   width:   29   height:   29)\n",
            "motorbike: 26%\t(left_x:  370   top_y:  667   width:   29   height:   48)\n",
            "truck: 33%\t(left_x:  426   top_y:  651   width:   88   height:   57)\n",
            "car: 86%\t(left_x:  426   top_y:  651   width:   87   height:   55)\n",
            "car: 84%\t(left_x:  506   top_y:  660   width:   53   height:   37)\n",
            "car: 40%\t(left_x:  557   top_y:  674   width:   27   height:   56)\n",
            "bus: 100%\t(left_x:  569   top_y:  370   width:  747   height:  493)\n",
            "person: 38%\t(left_x: 1077   top_y:  552   width:   81   height:   76)\n",
            "car: 99%\t(left_x: 1380   top_y:  658   width:  279   height:  102)\n",
            "car: 64%\t(left_x: 1789   top_y:  606   width:  134   height:  193)\n",
            "truck: 53%\t(left_x: 1792   top_y:  602   width:  127   height:  195)\n",
            "person: 27%\t(left_x: 1858   top_y:  636   width:   60   height:   39)\n",
            "person: 31%\t(left_x: 1883   top_y:  632   width:   37   height:   38)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/37.jpg: Predicted in 54.780000 milli-seconds.\n",
            "car: 99%\t(left_x:  138   top_y:  662   width:   96   height:   60)\n",
            "car: 49%\t(left_x:  224   top_y:  647   width:   36   height:   24)\n",
            "car: 32%\t(left_x:  225   top_y:  662   width:   32   height:   27)\n",
            "car: 43%\t(left_x:  255   top_y:  660   width:   57   height:   29)\n",
            "motorbike: 50%\t(left_x:  308   top_y:  660   width:   31   height:   55)\n",
            "person: 31%\t(left_x:  308   top_y:  660   width:   31   height:   55)\n",
            "car: 40%\t(left_x:  323   top_y:  653   width:   42   height:   35)\n",
            "car: 28%\t(left_x:  330   top_y:  648   width:   32   height:   30)\n",
            "motorbike: 57%\t(left_x:  354   top_y:  662   width:   45   height:   59)\n",
            "car: 56%\t(left_x:  397   top_y:  655   width:   37   height:   31)\n",
            "car: 94%\t(left_x:  434   top_y:  647   width:   89   height:   62)\n",
            "car: 26%\t(left_x:  550   top_y:  656   width:   33   height:   36)\n",
            "person: 29%\t(left_x:  551   top_y:  656   width:   30   height:   36)\n",
            "car: 37%\t(left_x:  569   top_y:  654   width:   40   height:   44)\n",
            "car: 99%\t(left_x:  582   top_y:  649   width:  100   height:   93)\n",
            "bus: 99%\t(left_x:  667   top_y:   90   width: 1265   height:  929)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/38.jpg: Predicted in 54.818000 milli-seconds.\n",
            "stop sign: 38%\t(left_x:    8   top_y:  662   width:   80   height:   67)\n",
            "person: 40%\t(left_x:   97   top_y:  659   width:   20   height:   42)\n",
            "car: 99%\t(left_x:  135   top_y:  656   width:   98   height:   63)\n",
            "car: 30%\t(left_x:  228   top_y:  657   width:   33   height:   31)\n",
            "motorbike: 39%\t(left_x:  314   top_y:  659   width:   38   height:   57)\n",
            "motorbike: 77%\t(left_x:  364   top_y:  672   width:   45   height:   57)\n",
            "person: 25%\t(left_x:  365   top_y:  644   width:   46   height:   62)\n",
            "car: 93%\t(left_x:  451   top_y:  642   width:  102   height:   67)\n",
            "car: 46%\t(left_x:  554   top_y:  656   width:   28   height:   28)\n",
            "car: 39%\t(left_x:  579   top_y:  660   width:   19   height:   27)\n",
            "car: 26%\t(left_x:  588   top_y:  645   width:   29   height:   32)\n",
            "car: 65%\t(left_x:  602   top_y:  656   width:   30   height:   40)\n",
            "car: 66%\t(left_x:  610   top_y:  640   width:   78   height:   62)\n",
            "car: 100%\t(left_x:  635   top_y:  639   width:  184   height:  114)\n",
            "person: 79%\t(left_x:  840   top_y:  651   width:   21   height:   47)\n",
            "person: 60%\t(left_x:  864   top_y:  647   width:   24   height:   63)\n",
            "bus: 99%\t(left_x:  886   top_y:   -1   width: 1004   height: 1072)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/39.jpg: Predicted in 55.986000 milli-seconds.\n",
            "car: 98%\t(left_x:  125   top_y:  652   width:   97   height:   63)\n",
            "car: 35%\t(left_x:  217   top_y:  646   width:   35   height:   30)\n",
            "car: 34%\t(left_x:  251   top_y:  647   width:   83   height:   37)\n",
            "motorbike: 78%\t(left_x:  315   top_y:  662   width:   35   height:   57)\n",
            "person: 56%\t(left_x:  366   top_y:  635   width:   59   height:   81)\n",
            "person: 27%\t(left_x:  367   top_y:  640   width:   50   height:   45)\n",
            "motorbike: 94%\t(left_x:  371   top_y:  662   width:   54   height:   80)\n",
            "car: 60%\t(left_x:  427   top_y:  647   width:   41   height:   33)\n",
            "truck: 49%\t(left_x:  462   top_y:  632   width:  119   height:   79)\n",
            "car: 76%\t(left_x:  463   top_y:  631   width:  116   height:   79)\n",
            "car: 98%\t(left_x:  574   top_y:  638   width:   84   height:   54)\n",
            "car: 100%\t(left_x:  703   top_y:  633   width:  238   height:  135)\n",
            "person: 33%\t(left_x:  893   top_y:  640   width:   30   height:   38)\n",
            "motorbike: 74%\t(left_x: 1131   top_y:  667   width:   50   height:   50)\n",
            "person: 69%\t(left_x: 1135   top_y:  645   width:   45   height:   63)\n",
            "motorbike: 89%\t(left_x: 1209   top_y:  684   width:  136   height:   87)\n",
            "person: 85%\t(left_x: 1225   top_y:  626   width:   83   height:  136)\n",
            "car: 99%\t(left_x: 1357   top_y:  643   width:  214   height:  108)\n",
            "bus: 91%\t(left_x: 1475   top_y:   15   width:  443   height: 1057)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/40.jpg: Predicted in 54.759000 milli-seconds.\n",
            "car: 99%\t(left_x:  130   top_y:  658   width:   99   height:   63)\n",
            "car: 78%\t(left_x:  257   top_y:  657   width:   55   height:   31)\n",
            "motorbike: 68%\t(left_x:  337   top_y:  669   width:   36   height:   62)\n",
            "person: 87%\t(left_x:  398   top_y:  641   width:   71   height:   99)\n",
            "motorbike: 97%\t(left_x:  403   top_y:  676   width:   65   height:   95)\n",
            "person: 27%\t(left_x:  411   top_y:  644   width:   47   height:   28)\n",
            "car: 88%\t(left_x:  495   top_y:  632   width:  128   height:   87)\n",
            "truck: 33%\t(left_x:  496   top_y:  632   width:  125   height:   87)\n",
            "car: 37%\t(left_x:  642   top_y:  648   width:   39   height:   22)\n",
            "motorbike: 81%\t(left_x:  724   top_y:  671   width:   32   height:   28)\n",
            "person: 39%\t(left_x:  725   top_y:  650   width:   32   height:   48)\n",
            "motorbike: 47%\t(left_x:  725   top_y:  650   width:   32   height:   47)\n",
            "person: 58%\t(left_x:  725   top_y:  645   width:   29   height:   36)\n",
            "car: 100%\t(left_x:  821   top_y:  631   width:  323   height:  176)\n",
            "person: 26%\t(left_x:  828   top_y:  645   width:   24   height:   33)\n",
            "person: 48%\t(left_x: 1100   top_y:  634   width:   49   height:   83)\n",
            "motorbike: 28%\t(left_x: 1150   top_y:  664   width:   33   height:   52)\n",
            "person: 27%\t(left_x: 1150   top_y:  647   width:   31   height:   59)\n",
            "car: 100%\t(left_x: 1365   top_y:  642   width:  269   height:  108)\n",
            "truck: 49%\t(left_x: 1767   top_y:  551   width:  154   height:  247)\n",
            "car: 39%\t(left_x: 1770   top_y:  554   width:  152   height:  241)\n",
            "person: 61%\t(left_x: 1854   top_y:  664   width:   67   height:  125)\n",
            "person: 55%\t(left_x: 1857   top_y:  621   width:   42   height:   35)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/41.jpg: Predicted in 54.898000 milli-seconds.\n",
            "car: 99%\t(left_x:  133   top_y:  643   width:   96   height:   62)\n",
            "car: 26%\t(left_x:  221   top_y:  630   width:   39   height:   32)\n",
            "person: 28%\t(left_x:  248   top_y:  642   width:   21   height:   33)\n",
            "car: 83%\t(left_x:  263   top_y:  643   width:   44   height:   30)\n",
            "person: 91%\t(left_x:  342   top_y:  632   width:   54   height:   83)\n",
            "motorbike: 83%\t(left_x:  346   top_y:  655   width:   48   height:   69)\n",
            "car: 80%\t(left_x:  415   top_y:  641   width:   49   height:   28)\n",
            "motorbike: 90%\t(left_x:  456   top_y:  662   width:   84   height:  135)\n",
            "person: 77%\t(left_x:  458   top_y:  623   width:   83   height:  146)\n",
            "person: 28%\t(left_x:  479   top_y:  618   width:   39   height:   38)\n",
            "truck: 62%\t(left_x:  532   top_y:  616   width:  142   height:   97)\n",
            "car: 53%\t(left_x:  535   top_y:  615   width:  146   height:   99)\n",
            "person: 56%\t(left_x:  678   top_y:  625   width:   28   height:   52)\n",
            "motorbike: 84%\t(left_x:  679   top_y:  634   width:   27   height:   47)\n",
            "person: 51%\t(left_x:  791   top_y:  625   width:   47   height:   53)\n",
            "motorbike: 28%\t(left_x:  792   top_y:  655   width:   27   height:   30)\n",
            "person: 87%\t(left_x:  870   top_y:  622   width:   56   height:   82)\n",
            "motorbike: 72%\t(left_x:  874   top_y:  659   width:   56   height:   51)\n",
            "person: 46%\t(left_x:  994   top_y:  619   width:   48   height:   84)\n",
            "car: 100%\t(left_x: 1002   top_y:  604   width:  499   height:  248)\n",
            "person: 71%\t(left_x: 1006   top_y:  620   width:   36   height:   50)\n",
            "motorbike: 37%\t(left_x: 1380   top_y:  629   width:  243   height:  119)\n",
            "car: 69%\t(left_x: 1390   top_y:  617   width:  213   height:  115)\n",
            "person: 37%\t(left_x: 1392   top_y:  617   width:  210   height:  116)\n",
            "motorbike: 55%\t(left_x: 1460   top_y:  647   width:  141   height:  109)\n",
            "person: 75%\t(left_x: 1489   top_y:  604   width:   77   height:  136)\n",
            "truck: 74%\t(left_x: 1655   top_y:  567   width:  266   height:  269)\n",
            "car: 50%\t(left_x: 1657   top_y:  568   width:  262   height:  264)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/42.jpg: Predicted in 54.802000 milli-seconds.\n",
            "stop sign: 28%\t(left_x:    6   top_y:  655   width:   76   height:   72)\n",
            "car: 99%\t(left_x:  138   top_y:  649   width:   93   height:   61)\n",
            "person: 45%\t(left_x:  250   top_y:  647   width:   28   height:   34)\n",
            "person: 68%\t(left_x:  356   top_y:  639   width:   55   height:   75)\n",
            "motorbike: 87%\t(left_x:  357   top_y:  656   width:   55   height:   84)\n",
            "person: 41%\t(left_x:  359   top_y:  642   width:   50   height:   40)\n",
            "motorbike: 28%\t(left_x:  363   top_y:  688   width:   44   height:   54)\n",
            "car: 74%\t(left_x:  411   top_y:  643   width:   44   height:   32)\n",
            "person: 25%\t(left_x:  473   top_y:  646   width:   24   height:   30)\n",
            "car: 80%\t(left_x:  500   top_y:  638   width:   64   height:   44)\n",
            "car: 58%\t(left_x:  560   top_y:  609   width:  181   height:  120)\n",
            "person: 91%\t(left_x:  565   top_y:  616   width:  168   height:  214)\n",
            "motorbike: 78%\t(left_x:  575   top_y:  684   width:  141   height:  209)\n",
            "person: 26%\t(left_x:  758   top_y:  640   width:   24   height:   48)\n",
            "motorbike: 45%\t(left_x:  758   top_y:  654   width:   25   height:   37)\n",
            "person: 74%\t(left_x:  779   top_y:  632   width:   32   height:   57)\n",
            "motorbike: 90%\t(left_x:  779   top_y:  668   width:   38   height:   36)\n",
            "person: 61%\t(left_x:  816   top_y:  641   width:   23   height:   38)\n",
            "person: 40%\t(left_x:  850   top_y:  635   width:   21   height:   48)\n",
            "person: 64%\t(left_x:  902   top_y:  639   width:   26   height:   45)\n",
            "motorbike: 30%\t(left_x:  904   top_y:  656   width:   34   height:   35)\n",
            "motorbike: 55%\t(left_x:  918   top_y:  657   width:   52   height:   44)\n",
            "person: 83%\t(left_x:  931   top_y:  624   width:   34   height:   69)\n",
            "person: 39%\t(left_x:  933   top_y:  626   width:   29   height:   44)\n",
            "motorbike: 61%\t(left_x: 1132   top_y:  662   width:   56   height:   44)\n",
            "person: 44%\t(left_x: 1148   top_y:  635   width:   34   height:   54)\n",
            "person: 53%\t(left_x: 1225   top_y:  653   width:   36   height:   74)\n",
            "car: 76%\t(left_x: 1257   top_y:  575   width:  381   height:  198)\n",
            "car: 99%\t(left_x: 1324   top_y:  581   width:  593   height:  419)\n",
            "car: 28%\t(left_x: 1352   top_y:  576   width:  274   height:   73)\n",
            "car: 30%\t(left_x: 1841   top_y:  577   width:   80   height:  131)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/43.jpg: Predicted in 54.875000 milli-seconds.\n",
            "car: 99%\t(left_x:  124   top_y:  656   width:   98   height:   61)\n",
            "car: 31%\t(left_x:  248   top_y:  654   width:   49   height:   36)\n",
            "truck: 34%\t(left_x:  356   top_y:  628   width:   51   height:   30)\n",
            "person: 92%\t(left_x:  366   top_y:  650   width:   66   height:   99)\n",
            "motorbike: 86%\t(left_x:  369   top_y:  669   width:   61   height:   92)\n",
            "car: 53%\t(left_x:  422   top_y:  651   width:   40   height:   25)\n",
            "car: 86%\t(left_x:  464   top_y:  646   width:   69   height:   41)\n",
            "car: 27%\t(left_x:  545   top_y:  648   width:   33   height:   32)\n",
            "truck: 34%\t(left_x:  597   top_y:  618   width:  219   height:  135)\n",
            "car: 70%\t(left_x:  604   top_y:  618   width:  211   height:  134)\n",
            "motorbike: 55%\t(left_x:  858   top_y:  649   width:   44   height:   51)\n",
            "person: 58%\t(left_x:  859   top_y:  633   width:   41   height:   60)\n",
            "motorbike: 37%\t(left_x:  866   top_y:  657   width:   49   height:   43)\n",
            "motorbike: 94%\t(left_x:  932   top_y:  776   width:  468   height:  304)\n",
            "person: 37%\t(left_x:  973   top_y:  596   width:  387   height:  458)\n",
            "person: 27%\t(left_x:  982   top_y:  565   width:  228   height:  251)\n",
            "person: 55%\t(left_x:  988   top_y:  562   width:  190   height:  154)\n",
            "car: 69%\t(left_x: 1106   top_y:  605   width:  280   height:  139)\n",
            "motorbike: 40%\t(left_x: 1128   top_y:  605   width:  256   height:  169)\n",
            "car: 100%\t(left_x: 1371   top_y:  637   width:  268   height:  108)\n",
            "truck: 43%\t(left_x: 1759   top_y:  568   width:  162   height:  206)\n",
            "car: 64%\t(left_x: 1760   top_y:  568   width:  160   height:  206)\n",
            "person: 80%\t(left_x: 1841   top_y:  618   width:   49   height:   33)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/44.jpg: Predicted in 54.767000 milli-seconds.\n",
            "stop sign: 33%\t(left_x:    0   top_y:  656   width:   68   height:   66)\n",
            "car: 99%\t(left_x:  124   top_y:  649   width:   90   height:   63)\n",
            "person: 41%\t(left_x:  234   top_y:  644   width:   30   height:   34)\n",
            "person: 30%\t(left_x:  241   top_y:  648   width:   31   height:   33)\n",
            "motorbike: 26%\t(left_x:  350   top_y:  657   width:   38   height:   34)\n",
            "car: 56%\t(left_x:  364   top_y:  645   width:   48   height:   28)\n",
            "motorbike: 95%\t(left_x:  387   top_y:  675   width:   81   height:  103)\n",
            "person: 96%\t(left_x:  387   top_y:  631   width:   81   height:  121)\n",
            "car: 88%\t(left_x:  457   top_y:  641   width:   53   height:   40)\n",
            "motorbike: 60%\t(left_x:  522   top_y:  644   width:   32   height:   33)\n",
            "person: 44%\t(left_x:  522   top_y:  644   width:   32   height:   33)\n",
            "person: 58%\t(left_x:  571   top_y:  640   width:   34   height:   42)\n",
            "motorbike: 62%\t(left_x:  572   top_y:  642   width:   33   height:   39)\n",
            "person: 47%\t(left_x:  573   top_y:  635   width:   29   height:   29)\n",
            "motorbike: 75%\t(left_x:  574   top_y:  657   width:   29   height:   27)\n",
            "motorbike: 25%\t(left_x:  637   top_y:  636   width:   32   height:   53)\n",
            "person: 70%\t(left_x:  637   top_y:  636   width:   32   height:   52)\n",
            "motorbike: 71%\t(left_x:  640   top_y:  655   width:   27   height:   35)\n",
            "car: 91%\t(left_x:  666   top_y:  606   width:  270   height:  162)\n",
            "car: 74%\t(left_x:  898   top_y:  613   width:  240   height:  126)\n",
            "truck: 48%\t(left_x:  898   top_y:  613   width:  240   height:  126)\n",
            "motorbike: 61%\t(left_x: 1127   top_y:  663   width:   50   height:   43)\n",
            "bicycle: 39%\t(left_x: 1127   top_y:  663   width:   50   height:   43)\n",
            "person: 39%\t(left_x: 1127   top_y:  641   width:   46   height:   65)\n",
            "car: 100%\t(left_x: 1353   top_y:  633   width:  262   height:  109)\n",
            "truck: 44%\t(left_x: 1753   top_y:  563   width:  168   height:  216)\n",
            "car: 67%\t(left_x: 1754   top_y:  566   width:  170   height:  210)\n",
            "person: 85%\t(left_x: 1837   top_y:  612   width:   49   height:   36)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/45.jpg: Predicted in 54.814000 milli-seconds.\n",
            "person: 44%\t(left_x:   76   top_y:  649   width:   22   height:   48)\n",
            "car: 99%\t(left_x:  122   top_y:  648   width:   93   height:   62)\n",
            "person: 52%\t(left_x:  232   top_y:  642   width:   28   height:   33)\n",
            "car: 88%\t(left_x:  380   top_y:  641   width:   54   height:   43)\n",
            "person: 98%\t(left_x:  436   top_y:  629   width:   93   height:  141)\n",
            "motorbike: 81%\t(left_x:  440   top_y:  685   width:   88   height:  121)\n",
            "motorbike: 56%\t(left_x:  510   top_y:  645   width:   25   height:   27)\n",
            "person: 40%\t(left_x:  510   top_y:  645   width:   25   height:   27)\n",
            "car: 33%\t(left_x:  510   top_y:  645   width:   25   height:   27)\n",
            "motorbike: 72%\t(left_x:  550   top_y:  642   width:   23   height:   36)\n",
            "person: 61%\t(left_x:  550   top_y:  642   width:   23   height:   36)\n",
            "motorbike: 27%\t(left_x:  552   top_y:  659   width:   20   height:   22)\n",
            "person: 43%\t(left_x:  553   top_y:  637   width:   23   height:   23)\n",
            "person: 63%\t(left_x:  596   top_y:  634   width:   29   height:   51)\n",
            "motorbike: 81%\t(left_x:  596   top_y:  657   width:   27   height:   29)\n",
            "car: 40%\t(left_x:  626   top_y:  636   width:   35   height:   21)\n",
            "person: 64%\t(left_x:  649   top_y:  643   width:   22   height:   39)\n",
            "car: 99%\t(left_x:  764   top_y:  597   width:  357   height:  199)\n",
            "motorbike: 82%\t(left_x: 1121   top_y:  663   width:   55   height:   41)\n",
            "person: 72%\t(left_x: 1126   top_y:  633   width:   41   height:   55)\n",
            "person: 27%\t(left_x: 1129   top_y:  632   width:   34   height:   38)\n",
            "car: 100%\t(left_x: 1351   top_y:  629   width:  263   height:  112)\n",
            "car: 99%\t(left_x: 1645   top_y:  593   width:  276   height:  253)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/46.jpg: Predicted in 54.760000 milli-seconds.\n",
            "stop sign: 36%\t(left_x:   -0   top_y:  654   width:   70   height:   70)\n",
            "person: 59%\t(left_x:   78   top_y:  650   width:   21   height:   47)\n",
            "car: 98%\t(left_x:  123   top_y:  650   width:   89   height:   62)\n",
            "car: 42%\t(left_x:  207   top_y:  652   width:   23   height:   25)\n",
            "person: 49%\t(left_x:  231   top_y:  647   width:   30   height:   31)\n",
            "car: 50%\t(left_x:  330   top_y:  650   width:   57   height:   32)\n",
            "car: 94%\t(left_x:  389   top_y:  643   width:   60   height:   43)\n",
            "car: 93%\t(left_x:  439   top_y:  643   width:   44   height:   36)\n",
            "car: 45%\t(left_x:  504   top_y:  645   width:   32   height:   28)\n",
            "person: 99%\t(left_x:  509   top_y:  626   width:  120   height:  184)\n",
            "motorbike: 91%\t(left_x:  520   top_y:  701   width:  106   height:  156)\n",
            "car: 56%\t(left_x:  612   top_y:  641   width:   60   height:   22)\n",
            "car: 73%\t(left_x:  698   top_y:  620   width:  166   height:   90)\n",
            "truck: 55%\t(left_x:  710   top_y:  619   width:  151   height:   90)\n",
            "person: 32%\t(left_x:  894   top_y:  637   width:   26   height:   50)\n",
            "car: 100%\t(left_x:  920   top_y:  582   width:  543   height:  276)\n",
            "car: 99%\t(left_x: 1327   top_y:  615   width:  315   height:  174)\n",
            "car: 67%\t(left_x: 1754   top_y:  568   width:  167   height:  209)\n",
            "truck: 42%\t(left_x: 1755   top_y:  568   width:  166   height:  210)\n",
            "person: 55%\t(left_x: 1838   top_y:  611   width:   48   height:   36)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/47.jpg: Predicted in 54.716000 milli-seconds.\n",
            "car: 99%\t(left_x:  123   top_y:  653   width:   94   height:   63)\n",
            "car: 28%\t(left_x:  210   top_y:  658   width:   21   height:   24)\n",
            "car: 69%\t(left_x:  267   top_y:  655   width:   43   height:   31)\n",
            "car: 65%\t(left_x:  334   top_y:  638   width:   62   height:   49)\n",
            "car: 88%\t(left_x:  395   top_y:  646   width:   64   height:   47)\n",
            "car: 30%\t(left_x:  458   top_y:  650   width:   32   height:   25)\n",
            "car: 32%\t(left_x:  477   top_y:  649   width:   34   height:   28)\n",
            "motorbike: 30%\t(left_x:  511   top_y:  659   width:   23   height:   23)\n",
            "person: 81%\t(left_x:  511   top_y:  644   width:   23   height:   35)\n",
            "motorbike: 51%\t(left_x:  534   top_y:  660   width:   28   height:   27)\n",
            "person: 75%\t(left_x:  538   top_y:  643   width:   22   height:   34)\n",
            "person: 37%\t(left_x:  594   top_y:  647   width:   28   height:   27)\n",
            "motorbike: 35%\t(left_x:  596   top_y:  658   width:   20   height:   25)\n",
            "car: 28%\t(left_x:  622   top_y:  647   width:   29   height:   19)\n",
            "motorbike: 39%\t(left_x:  646   top_y:  652   width:   35   height:   48)\n",
            "person: 98%\t(left_x:  646   top_y:  624   width:  168   height:  253)\n",
            "motorbike: 98%\t(left_x:  651   top_y:  715   width:  161   height:  243)\n",
            "person: 46%\t(left_x:  780   top_y:  642   width:   30   height:   44)\n",
            "motorbike: 35%\t(left_x:  781   top_y:  654   width:   27   height:   34)\n",
            "person: 74%\t(left_x:  837   top_y:  636   width:   22   height:   55)\n",
            "person: 62%\t(left_x:  894   top_y:  640   width:   25   height:   48)\n",
            "motorbike: 33%\t(left_x:  895   top_y:  665   width:   33   height:   27)\n",
            "car: 99%\t(left_x: 1026   top_y:  628   width:  202   height:  129)\n",
            "car: 100%\t(left_x: 1200   top_y:  553   width:  703   height:  453)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/48.jpg: Predicted in 54.862000 milli-seconds.\n",
            "car: 99%\t(left_x:  127   top_y:  661   width:   92   height:   62)\n",
            "car: 34%\t(left_x:  207   top_y:  665   width:   25   height:   24)\n",
            "car: 28%\t(left_x:  226   top_y:  662   width:   29   height:   27)\n",
            "car: 55%\t(left_x:  247   top_y:  659   width:   28   height:   28)\n",
            "car: 84%\t(left_x:  273   top_y:  660   width:   48   height:   34)\n",
            "car: 37%\t(left_x:  332   top_y:  658   width:   62   height:   38)\n",
            "car: 89%\t(left_x:  400   top_y:  653   width:   78   height:   52)\n",
            "motorbike: 46%\t(left_x:  477   top_y:  658   width:   25   height:   27)\n",
            "person: 60%\t(left_x:  504   top_y:  655   width:   29   height:   35)\n",
            "motorbike: 57%\t(left_x:  504   top_y:  655   width:   29   height:   35)\n",
            "person: 36%\t(left_x:  510   top_y:  651   width:   25   height:   25)\n",
            "motorbike: 45%\t(left_x:  556   top_y:  658   width:   25   height:   26)\n",
            "car: 44%\t(left_x:  578   top_y:  659   width:   32   height:   30)\n",
            "motorbike: 40%\t(left_x:  578   top_y:  659   width:   32   height:   30)\n",
            "truck: 80%\t(left_x:  609   top_y:  636   width:  120   height:   70)\n",
            "car: 41%\t(left_x:  609   top_y:  636   width:  120   height:   70)\n",
            "person: 58%\t(left_x:  770   top_y:  658   width:   20   height:   32)\n",
            "motorbike: 27%\t(left_x:  770   top_y:  658   width:   20   height:   32)\n",
            "person: 57%\t(left_x:  785   top_y:  655   width:   26   height:   36)\n",
            "motorbike: 33%\t(left_x:  785   top_y:  655   width:   26   height:   36)\n",
            "person: 38%\t(left_x:  838   top_y:  656   width:   16   height:   42)\n",
            "car: 98%\t(left_x:  890   top_y:  640   width:  181   height:  101)\n",
            "motorbike: 99%\t(left_x:  947   top_y:  781   width:  485   height:  302)\n",
            "person: 64%\t(left_x:  977   top_y:  605   width:  335   height:  414)\n",
            "motorbike: 88%\t(left_x: 1278   top_y:  679   width:   93   height:   81)\n",
            "person: 90%\t(left_x: 1284   top_y:  633   width:   68   height:  121)\n",
            "car: 100%\t(left_x: 1327   top_y:  645   width:  299   height:  105)\n",
            "car: 40%\t(left_x: 1761   top_y:  596   width:  157   height:  154)\n",
            "car: 64%\t(left_x: 1778   top_y:  588   width:  143   height:  359)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/49.jpg: Predicted in 54.863000 milli-seconds.\n",
            "parking meter: 53%\t(left_x:    4   top_y:  664   width:   79   height:   71)\n",
            "person: 27%\t(left_x:   96   top_y:  657   width:   19   height:   46)\n",
            "car: 99%\t(left_x:  135   top_y:  659   width:   92   height:   62)\n",
            "person: 57%\t(left_x:  230   top_y:  657   width:   23   height:   32)\n",
            "person: 70%\t(left_x:  255   top_y:  656   width:   25   height:   38)\n",
            "car: 93%\t(left_x:  289   top_y:  661   width:   43   height:   32)\n",
            "car: 97%\t(left_x:  332   top_y:  654   width:   74   height:   44)\n",
            "car: 99%\t(left_x:  415   top_y:  649   width:   90   height:   57)\n",
            "car: 36%\t(left_x:  526   top_y:  654   width:   39   height:   22)\n",
            "car: 26%\t(left_x:  550   top_y:  653   width:   31   height:   25)\n",
            "car: 63%\t(left_x:  573   top_y:  639   width:  114   height:   60)\n",
            "truck: 46%\t(left_x:  573   top_y:  639   width:  115   height:   60)\n",
            "person: 46%\t(left_x:  764   top_y:  655   width:   25   height:   32)\n",
            "motorbike: 29%\t(left_x:  764   top_y:  655   width:   25   height:   32)\n",
            "car: 99%\t(left_x:  799   top_y:  638   width:  157   height:   85)\n",
            "person: 60%\t(left_x: 1106   top_y:  640   width:   62   height:   80)\n",
            "motorbike: 89%\t(left_x: 1106   top_y:  663   width:   77   height:   73)\n",
            "person: 37%\t(left_x: 1106   top_y:  663   width:   77   height:   73)\n",
            "car: 100%\t(left_x: 1367   top_y:  641   width:  277   height:  106)\n",
            "car: 68%\t(left_x: 1768   top_y:  588   width:  153   height:  203)\n",
            "truck: 39%\t(left_x: 1770   top_y:  573   width:  150   height:  202)\n",
            "person: 76%\t(left_x: 1859   top_y:  618   width:   40   height:   37)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/50.jpg: Predicted in 54.709000 milli-seconds.\n",
            "car: 98%\t(left_x:  129   top_y:  651   width:   90   height:   61)\n",
            "person: 57%\t(left_x:  221   top_y:  648   width:   22   height:   33)\n",
            "person: 43%\t(left_x:  245   top_y:  649   width:   28   height:   21)\n",
            "car: 41%\t(left_x:  245   top_y:  649   width:   28   height:   21)\n",
            "person: 27%\t(left_x:  247   top_y:  653   width:   26   height:   36)\n",
            "car: 79%\t(left_x:  283   top_y:  655   width:   46   height:   32)\n",
            "car: 30%\t(left_x:  285   top_y:  653   width:   46   height:   23)\n",
            "car: 97%\t(left_x:  323   top_y:  646   width:   74   height:   49)\n",
            "car: 85%\t(left_x:  396   top_y:  646   width:   36   height:   29)\n",
            "car: 98%\t(left_x:  427   top_y:  640   width:   91   height:   64)\n",
            "car: 87%\t(left_x:  534   top_y:  634   width:  101   height:   56)\n",
            "person: 62%\t(left_x:  641   top_y:  642   width:   28   height:   44)\n",
            "car: 94%\t(left_x:  720   top_y:  633   width:  131   height:   77)\n",
            "motorbike: 34%\t(left_x:  898   top_y:  662   width:   28   height:   31)\n",
            "person: 42%\t(left_x:  898   top_y:  639   width:   25   height:   50)\n",
            "person: 95%\t(left_x:  975   top_y:  638   width:   43   height:   75)\n",
            "motorbike: 47%\t(left_x:  978   top_y:  663   width:   44   height:   55)\n",
            "motorbike: 89%\t(left_x: 1125   top_y:  670   width:   52   height:   39)\n",
            "person: 65%\t(left_x: 1128   top_y:  640   width:   46   height:   66)\n",
            "person: 57%\t(left_x: 1132   top_y:  639   width:   36   height:   43)\n",
            "car: 100%\t(left_x: 1354   top_y:  635   width:  280   height:  107)\n",
            "truck: 34%\t(left_x: 1749   top_y:  555   width:  173   height:  283)\n",
            "car: 75%\t(left_x: 1751   top_y:  557   width:  168   height:  282)\n",
            "person: 72%\t(left_x: 1842   top_y:  612   width:   46   height:   38)\n",
            "Enter Image Path:  Detection layer: 139 - type = 28 \n",
            " Detection layer: 150 - type = 28 \n",
            " Detection layer: 161 - type = 28 \n",
            "/content/frames/VID_20210112_173920/51.jpg: Predicted in 54.846000 milli-seconds.\n",
            "stop sign: 44%\t(left_x:    0   top_y:  658   width:   72   height:   65)\n",
            "car: 98%\t(left_x:  127   top_y:  651   width:   92   height:   61)\n",
            "person: 37%\t(left_x:  221   top_y:  647   width:   25   height:   35)\n",
            "car: 56%\t(left_x:  248   top_y:  649   width:   35   height:   27)\n",
            "car: 71%\t(left_x:  284   top_y:  654   width:   46   height:   34)\n",
            "car: 98%\t(left_x:  321   top_y:  649   width:   80   height:   51)\n",
            "car: 70%\t(left_x:  393   top_y:  648   width:   37   height:   25)\n",
            "car: 97%\t(left_x:  444   top_y:  639   width:  106   height:   70)\n",
            "car: 59%\t(left_x:  535   top_y:  640   width:   72   height:   46)\n",
            "person: 27%\t(left_x:  616   top_y:  645   width:   23   height:   39)\n",
            "car: 35%\t(left_x:  627   top_y:  641   width:   48   height:   22)\n",
            "car: 80%\t(left_x:  666   top_y:  638   width:  107   height:   64)\n",
            "truck: 40%\t(left_x:  666   top_y:  637   width:  108   height:   65)\n",
            "person: 44%\t(left_x:  784   top_y:  642   width:   20   height:   42)\n",
            "person: 64%\t(left_x:  827   top_y:  640   width:   20   height:   50)\n",
            "person: 71%\t(left_x:  885   top_y:  639   width:   38   height:   67)\n",
            "motorbike: 58%\t(left_x:  888   top_y:  665   width:   38   height:   42)\n",
            "motorbike: 64%\t(left_x: 1126   top_y:  673   width:   54   height:   39)\n",
            "bicycle: 40%\t(left_x: 1126   top_y:  672   width:   53   height:   39)\n",
            "person: 65%\t(left_x: 1127   top_y:  641   width:   47   height:   66)\n",
            "person: 42%\t(left_x: 1134   top_y:  640   width:   33   height:   39)\n",
            "car: 100%\t(left_x: 1317   top_y:  622   width:  565   height:  184)\n",
            "truck: 40%\t(left_x: 1787   top_y:  564   width:  134   height:  213)\n",
            "car: 57%\t(left_x: 1788   top_y:  569   width:  133   height:  206)\n",
            "person: 28%\t(left_x: 1847   top_y:  618   width:   38   height:   33)\n",
            "Enter Image Path: /content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKd_7cadTdSm"
      },
      "source": [
        "Process result.json, save predicted bounding boxes for each image to file \\<image_path\\>.txt (in the same folder)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drGoJXNPHpQ4"
      },
      "source": [
        "import json\r\n",
        "result_json = json.load(open('result.json', 'r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4530jxgC-WZ1"
      },
      "source": [
        "names = ('car', 'bicycle', 'motorbike', 'bus', 'truck')\r\n",
        "name_dict = {name: i for i, name in enumerate(names)}\r\n",
        "def get_box(obj):\r\n",
        "    coord = obj['relative_coordinates']\r\n",
        "    return ' '.join([\r\n",
        "                str(name_dict[obj['name']]),\r\n",
        "                str(coord['center_x']),\r\n",
        "                str(coord['center_y']),\r\n",
        "                str(coord['width']),\r\n",
        "                str(coord['height'])\r\n",
        "            ])\r\n",
        "for result in result_json:\r\n",
        "    path = result['filename']\r\n",
        "    obj_list = result['objects']\r\n",
        "    vehicle_filter = filter(lambda x: x['name'] in names, obj_list)\r\n",
        "    box_iterable = map(get_box, vehicle_filter)\r\n",
        "    box_str = '\\n'.join(box_iterable)\r\n",
        "    with open(path[:-4] + '.txt', 'w') as f:\r\n",
        "        f.write(box_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRicGexUntez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0cfc06f-90a6-4706-a8b9-1854f704828f"
      },
      "source": [
        "!zip -r frames.zip frames"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: frames/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173640/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173640/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/19.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173640/15.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173640/10.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173640/16.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173640/6.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173640/1.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/7.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173640/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/23.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/17.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173640/11.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173640/5.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173640/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/22.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173640/13.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173640/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/18.txt (deflated 60%)\n",
            "  adding: frames/VID_20210112_173640/1.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173640/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/2.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173640/14.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173640/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/9.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173640/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/8.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173640/12.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173640/3.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173640/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/21.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173640/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173640/23.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173640/4.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173640/20.txt (deflated 57%)\n",
            "  adding: frames/20210112_173510/ (stored 0%)\n",
            "  adding: frames/20210112_173510/32.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/211.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/17.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/124.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/70.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/161.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/194.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/230.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/121.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/224.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/76.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/51.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/19.txt (deflated 58%)\n",
            "  adding: frames/20210112_173510/150.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/157.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/218.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/183.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/31.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/15.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/133.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/50.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/171.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/159.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/165.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/42.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/212.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/111.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/223.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/170.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/179.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/231.txt (deflated 39%)\n",
            "  adding: frames/20210112_173510/226.txt (deflated 39%)\n",
            "  adding: frames/20210112_173510/10.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/61.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/16.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/45.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/193.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/283.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/140.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/256.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/279.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/126.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/161.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/70.txt (deflated 29%)\n",
            "  adding: frames/20210112_173510/71.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/138.txt (deflated 28%)\n",
            "  adding: frames/20210112_173510/106.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/280.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/122.txt (deflated 42%)\n",
            "  adding: frames/20210112_173510/73.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/153.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/28.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/187.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/26.txt (deflated 37%)\n",
            "  adding: frames/20210112_173510/136.txt (deflated 27%)\n",
            "  adding: frames/20210112_173510/243.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/102.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/278.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/148.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/108.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/210.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/248.txt (deflated 54%)\n",
            "  adding: frames/20210112_173510/258.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/200.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/263.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/46.txt (deflated 54%)\n",
            "  adding: frames/20210112_173510/112.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/130.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/104.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/265.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/134.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/233.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/45.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/120.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/75.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/52.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/35.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/125.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/87.txt (stored 0%)\n",
            "  adding: frames/20210112_173510/89.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/200.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/151.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/6.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/1.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/264.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/6.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/116.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/163.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/241.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/259.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/194.txt (deflated 41%)\n",
            "  adding: frames/20210112_173510/53.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/63.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/208.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/145.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/102.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/167.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/123.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/24.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/169.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/195.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/216.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/7.txt (deflated 42%)\n",
            "  adding: frames/20210112_173510/210.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/110.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/214.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/174.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/277.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/116.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/72.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/203.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/80.txt (deflated 26%)\n",
            "  adding: frames/20210112_173510/40.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/177.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/157.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/286.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/34.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/99.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/239.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/80.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/186.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/56.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/60.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/242.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/85.txt (stored 0%)\n",
            "  adding: frames/20210112_173510/37.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/176.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/222.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/146.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/224.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/82.txt (deflated 11%)\n",
            "  adding: frames/20210112_173510/94.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/263.txt (deflated 54%)\n",
            "  adding: frames/20210112_173510/247.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/48.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/237.txt (deflated 40%)\n",
            "  adding: frames/20210112_173510/137.txt (deflated 25%)\n",
            "  adding: frames/20210112_173510/269.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/181.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/87.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/100.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/172.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/156.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/267.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/183.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/109.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/173.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/38.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/69.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/287.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/238.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/131.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/191.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/62.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/262.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/166.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/121.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/175.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/59.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/158.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/173.txt (deflated 54%)\n",
            "  adding: frames/20210112_173510/254.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/227.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/257.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/227.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/142.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/126.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/257.txt (deflated 57%)\n",
            "  adding: frames/20210112_173510/266.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/185.txt (deflated 54%)\n",
            "  adding: frames/20210112_173510/160.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/182.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/135.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/84.txt (deflated 14%)\n",
            "  adding: frames/20210112_173510/229.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/238.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/265.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/137.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/49.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/178.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/4.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/117.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/284.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/23.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/138.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/84.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/217.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/125.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/199.txt (deflated 27%)\n",
            "  adding: frames/20210112_173510/169.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/155.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/211.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/279.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/275.txt (deflated 54%)\n",
            "  adding: frames/20210112_173510/187.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/78.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/215.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/273.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/38.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/264.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/239.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/166.txt (deflated 54%)\n",
            "  adding: frames/20210112_173510/17.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/195.txt (deflated 27%)\n",
            "  adding: frames/20210112_173510/110.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/256.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/153.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/11.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/111.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/165.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/220.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/73.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/5.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/132.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/240.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/48.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/14.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/88.txt (stored 0%)\n",
            "  adding: frames/20210112_173510/171.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/158.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/147.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/218.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/164.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/249.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/205.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/143.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/86.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/129.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/131.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/198.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/77.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/104.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/92.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/93.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/272.txt (deflated 56%)\n",
            "  adding: frames/20210112_173510/207.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/33.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/107.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/201.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/44.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/83.txt (stored 0%)\n",
            "  adding: frames/20210112_173510/36.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/208.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/280.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/149.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/172.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/278.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/97.txt (deflated 26%)\n",
            "  adding: frames/20210112_173510/255.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/71.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/152.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/68.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/93.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/213.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/98.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/139.txt (deflated 11%)\n",
            "  adding: frames/20210112_173510/103.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/10.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/156.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/209.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/262.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/249.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/244.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/94.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/168.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/105.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/246.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/206.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/22.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/57.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/101.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/66.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/149.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/13.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/8.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/96.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/129.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/272.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/115.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/46.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/64.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/268.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/268.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/273.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/91.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/185.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/130.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/58.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/253.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/233.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/196.txt (deflated 39%)\n",
            "  adding: frames/20210112_173510/139.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/202.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/132.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/64.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/112.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/213.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/204.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/225.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/55.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/7.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/15.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/108.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/237.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/100.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/235.txt (deflated 27%)\n",
            "  adding: frames/20210112_173510/18.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/223.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/1.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/234.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/176.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/81.txt (deflated 11%)\n",
            "  adding: frames/20210112_173510/12.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/199.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/119.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/34.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/69.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/16.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/230.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/114.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/52.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/159.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/27.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/79.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/284.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/89.txt (stored 0%)\n",
            "  adding: frames/20210112_173510/2.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/122.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/197.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/189.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/198.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/188.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/184.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/170.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/234.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/163.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/60.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/78.txt (deflated 26%)\n",
            "  adding: frames/20210112_173510/59.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/51.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/236.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/2.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/179.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/106.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/248.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/120.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/217.txt (deflated 42%)\n",
            "  adding: frames/20210112_173510/251.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/282.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/58.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/274.txt (deflated 56%)\n",
            "  adding: frames/20210112_173510/271.jpg (deflated 1%)\n",
            "  adding: frames/20210112_173510/145.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/41.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/56.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/219.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/221.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/231.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/181.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/39.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/204.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/14.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/142.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/50.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/98.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/31.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/85.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/225.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/197.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/62.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/82.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/37.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/276.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/193.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/11.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/42.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/160.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/21.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/28.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/123.txt (deflated 42%)\n",
            "  adding: frames/20210112_173510/266.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/54.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/260.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/203.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/115.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/114.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/283.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/43.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/190.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/26.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/196.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/35.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/226.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/150.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/144.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/152.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/250.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/67.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/240.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/133.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/154.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/92.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/29.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/128.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/236.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/19.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/244.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/88.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/109.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/103.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/113.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/155.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/3.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/270.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/47.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/124.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/66.txt (deflated 54%)\n",
            "  adding: frames/20210112_173510/184.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/135.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/189.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/136.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/68.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/148.txt (deflated 37%)\n",
            "  adding: frames/20210112_173510/72.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/13.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/32.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/207.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/186.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/101.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/36.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/53.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/245.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/107.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/246.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/188.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/30.txt (deflated 27%)\n",
            "  adding: frames/20210112_173510/5.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/175.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/74.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/271.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/252.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/167.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/147.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/154.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/221.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/24.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/258.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/241.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/25.txt (deflated 37%)\n",
            "  adding: frames/20210112_173510/251.txt (deflated 54%)\n",
            "  adding: frames/20210112_173510/178.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/232.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/287.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/235.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/41.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/253.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/214.txt (deflated 27%)\n",
            "  adding: frames/20210112_173510/117.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/27.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/9.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/74.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/245.txt (deflated 57%)\n",
            "  adding: frames/20210112_173510/54.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/96.txt (deflated 40%)\n",
            "  adding: frames/20210112_173510/190.txt (deflated 28%)\n",
            "  adding: frames/20210112_173510/182.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/285.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/30.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/259.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/90.txt (deflated 40%)\n",
            "  adding: frames/20210112_173510/260.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/162.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/118.txt (deflated 39%)\n",
            "  adding: frames/20210112_173510/20.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/105.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/113.txt (deflated 46%)\n",
            "  adding: frames/20210112_173510/65.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/243.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/162.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/33.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/8.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/86.txt (stored 0%)\n",
            "  adding: frames/20210112_173510/255.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/282.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/222.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/254.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/215.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/90.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/95.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/29.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/180.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/40.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/127.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/192.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/134.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/95.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/174.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/99.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/177.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/261.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/57.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/77.txt (deflated 42%)\n",
            "  adding: frames/20210112_173510/12.txt (deflated 50%)\n",
            "  adding: frames/20210112_173510/43.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/220.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/168.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/118.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/274.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/3.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/65.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/286.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/269.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/47.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/97.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/146.txt (deflated 37%)\n",
            "  adding: frames/20210112_173510/128.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/250.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/261.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/61.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/9.jpg (deflated 1%)\n",
            "  adding: frames/20210112_173510/205.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/285.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/206.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/228.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/55.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/21.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/22.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/143.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/127.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/91.txt (deflated 45%)\n",
            "  adding: frames/20210112_173510/79.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/75.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/164.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/276.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/192.txt (deflated 28%)\n",
            "  adding: frames/20210112_173510/202.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/247.txt (deflated 57%)\n",
            "  adding: frames/20210112_173510/18.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/242.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/144.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/67.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/232.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/141.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/275.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/201.jpg (deflated 1%)\n",
            "  adding: frames/20210112_173510/252.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/25.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/83.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/44.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/140.txt (deflated 40%)\n",
            "  adding: frames/20210112_173510/119.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/63.jpg (deflated 1%)\n",
            "  adding: frames/20210112_173510/180.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/212.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/23.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/216.txt (deflated 40%)\n",
            "  adding: frames/20210112_173510/228.txt (deflated 44%)\n",
            "  adding: frames/20210112_173510/49.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/4.txt (deflated 43%)\n",
            "  adding: frames/20210112_173510/209.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/191.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/151.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/229.txt (deflated 31%)\n",
            "  adding: frames/20210112_173510/141.txt (deflated 47%)\n",
            "  adding: frames/20210112_173510/76.txt (deflated 38%)\n",
            "  adding: frames/20210112_173510/277.txt (deflated 51%)\n",
            "  adding: frames/20210112_173510/281.txt (deflated 52%)\n",
            "  adding: frames/20210112_173510/270.txt (deflated 48%)\n",
            "  adding: frames/20210112_173510/219.txt (deflated 49%)\n",
            "  adding: frames/20210112_173510/20.txt (deflated 55%)\n",
            "  adding: frames/20210112_173510/81.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/39.txt (deflated 53%)\n",
            "  adding: frames/20210112_173510/281.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173510/267.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173626_764/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/19.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173626_764/15.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173626_764/10.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173626_764/16.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173626_764/26.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173626_764/6.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_173626_764/1.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173626_764/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/24.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173626_764/7.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173626_764/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/23.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/17.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173626_764/11.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173626_764/5.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_173626_764/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/22.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173626_764/13.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173626_764/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/18.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173626_764/1.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173626_764/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/27.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/2.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173626_764/14.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173626_764/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/26.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/24.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/25.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173626_764/27.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173626_764/9.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173626_764/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/8.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173626_764/12.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173626_764/3.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173626_764/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/21.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173626_764/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/25.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173626_764/23.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173626_764/4.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173626_764/20.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173846_288/32.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/70.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/121.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/76.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/51.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/19.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/31.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/15.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/50.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/42.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/111.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/10.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/61.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/16.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/45.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_173846_288/70.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/71.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/106.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/73.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/28.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/26.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/102.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/108.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/46.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/112.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/104.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/45.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/120.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/75.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/52.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/35.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/87.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/89.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/6.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/1.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173846_288/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/116.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/53.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/63.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/102.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/24.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/7.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/110.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/116.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/72.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_173846_288/80.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/40.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/34.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/99.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/80.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/56.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/60.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/85.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/37.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/82.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/94.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/48.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/87.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/100.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/109.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/38.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/69.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/62.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/121.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/59.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/84.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/49.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/117.txt (deflated 52%)\n",
            "  adding: frames/VID_20210112_173846_288/23.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/84.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/78.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/38.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/17.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/110.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/11.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/111.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/73.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/5.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/48.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/88.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/86.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/77.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/104.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/92.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_173846_288/93.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/33.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/107.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/44.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/83.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/36.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/97.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173846_288/71.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/68.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/93.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/98.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/103.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/94.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/105.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/22.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/57.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/101.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/66.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/13.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/96.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/115.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/46.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/64.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/91.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/58.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/64.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/112.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/55.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/108.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/100.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/18.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/1.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173846_288/81.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/119.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/34.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/69.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/114.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/52.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/27.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/79.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/89.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/60.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/78.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/59.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/51.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/2.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/106.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/120.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_173846_288/58.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/41.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/56.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/39.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/14.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/50.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_173846_288/98.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/31.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/85.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/62.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/82.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/37.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/42.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/28.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/54.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/115.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/114.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/43.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/26.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/35.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/67.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/92.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/29.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/88.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/109.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/103.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/113.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/47.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/66.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/68.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/72.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/32.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/101.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/36.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/53.txt (deflated 52%)\n",
            "  adding: frames/VID_20210112_173846_288/107.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/30.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/74.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/24.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/25.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173846_288/41.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173846_288/117.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/27.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/9.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/74.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/54.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/96.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173846_288/30.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/90.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/118.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/105.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/113.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/65.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/33.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/8.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/86.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/90.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/95.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/29.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/40.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/95.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/99.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/57.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/77.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/12.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173846_288/43.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/118.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/3.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173846_288/65.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/47.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/97.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/61.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/55.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/21.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/91.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/79.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/75.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/67.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/25.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/83.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/44.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/119.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/63.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/23.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173846_288/49.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/4.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173846_288/76.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173846_288/20.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173846_288/81.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173846_288/39.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173920/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173920/32.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173920/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/51.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/19.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_173920/31.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/15.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173920/50.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/42.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173920/10.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/16.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/45.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/28.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/26.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/46.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/45.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/35.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/6.txt (deflated 60%)\n",
            "  adding: frames/VID_20210112_173920/1.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173920/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/24.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/7.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173920/40.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/34.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/37.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/48.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/38.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173920/49.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/23.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/38.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/17.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/11.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/5.txt (deflated 63%)\n",
            "  adding: frames/VID_20210112_173920/48.txt (deflated 61%)\n",
            "  adding: frames/VID_20210112_173920/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/33.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/44.txt (deflated 60%)\n",
            "  adding: frames/VID_20210112_173920/36.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/22.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/13.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173920/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/46.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/18.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173920/1.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/34.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/27.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/51.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/2.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/41.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/39.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/14.txt (deflated 60%)\n",
            "  adding: frames/VID_20210112_173920/50.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/31.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/37.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/42.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/28.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/43.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/26.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/35.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173920/29.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/47.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/32.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/36.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/30.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/24.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/25.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173920/41.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/27.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/9.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173920/30.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/33.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/8.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/29.txt (deflated 60%)\n",
            "  adding: frames/VID_20210112_173920/40.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/12.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173920/43.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/3.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173920/47.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/21.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173920/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/25.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/44.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173920/23.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/49.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173920/4.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173920/20.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173920/39.txt (deflated 57%)\n",
            "  adding: frames/20210112_164746/ (stored 0%)\n",
            "  adding: frames/20210112_164746/32.txt (deflated 49%)\n",
            "  adding: frames/20210112_164746/17.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/19.txt (deflated 45%)\n",
            "  adding: frames/20210112_164746/31.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/15.txt (deflated 14%)\n",
            "  adding: frames/20210112_164746/42.txt (deflated 8%)\n",
            "  adding: frames/20210112_164746/10.txt (deflated 25%)\n",
            "  adding: frames/20210112_164746/16.txt (deflated 8%)\n",
            "  adding: frames/20210112_164746/28.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/26.txt (deflated 47%)\n",
            "  adding: frames/20210112_164746/35.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/6.txt (deflated 37%)\n",
            "  adding: frames/20210112_164746/1.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/6.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/24.txt (deflated 39%)\n",
            "  adding: frames/20210112_164746/7.txt (deflated 28%)\n",
            "  adding: frames/20210112_164746/40.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/34.txt (deflated 38%)\n",
            "  adding: frames/20210112_164746/37.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/38.txt (deflated 26%)\n",
            "  adding: frames/20210112_164746/4.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/23.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/38.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/17.txt (deflated 39%)\n",
            "  adding: frames/20210112_164746/11.txt (deflated 28%)\n",
            "  adding: frames/20210112_164746/5.txt (deflated 38%)\n",
            "  adding: frames/20210112_164746/14.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/33.txt (deflated 44%)\n",
            "  adding: frames/20210112_164746/36.txt (deflated 44%)\n",
            "  adding: frames/20210112_164746/10.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/22.txt (deflated 44%)\n",
            "  adding: frames/20210112_164746/13.txt (deflated 8%)\n",
            "  adding: frames/20210112_164746/8.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/7.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/15.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/18.txt (deflated 40%)\n",
            "  adding: frames/20210112_164746/1.txt (deflated 36%)\n",
            "  adding: frames/20210112_164746/12.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/34.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/16.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/27.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/2.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/2.txt (deflated 38%)\n",
            "  adding: frames/20210112_164746/41.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/39.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/14.txt (deflated 14%)\n",
            "  adding: frames/20210112_164746/31.txt (deflated 48%)\n",
            "  adding: frames/20210112_164746/37.txt (deflated 38%)\n",
            "  adding: frames/20210112_164746/11.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/42.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/21.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/28.txt (deflated 54%)\n",
            "  adding: frames/20210112_164746/43.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/26.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/35.txt (deflated 45%)\n",
            "  adding: frames/20210112_164746/29.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/19.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/3.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/13.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/32.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/36.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/30.txt (deflated 44%)\n",
            "  adding: frames/20210112_164746/5.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/24.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/25.txt (deflated 47%)\n",
            "  adding: frames/20210112_164746/41.txt (deflated 6%)\n",
            "  adding: frames/20210112_164746/27.txt (deflated 47%)\n",
            "  adding: frames/20210112_164746/9.txt (deflated 27%)\n",
            "  adding: frames/20210112_164746/30.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/20.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/33.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/8.txt (deflated 24%)\n",
            "  adding: frames/20210112_164746/29.txt (deflated 48%)\n",
            "  adding: frames/20210112_164746/40.txt (deflated 5%)\n",
            "  adding: frames/20210112_164746/12.txt (deflated 8%)\n",
            "  adding: frames/20210112_164746/43.txt (stored 0%)\n",
            "  adding: frames/20210112_164746/3.txt (deflated 44%)\n",
            "  adding: frames/20210112_164746/9.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/21.txt (deflated 38%)\n",
            "  adding: frames/20210112_164746/22.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/18.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/25.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164746/23.txt (deflated 29%)\n",
            "  adding: frames/20210112_164746/4.txt (deflated 37%)\n",
            "  adding: frames/20210112_164746/20.txt (deflated 44%)\n",
            "  adding: frames/20210112_164746/39.txt (deflated 40%)\n",
            "  adding: frames/VID20210112173818/ (stored 0%)\n",
            "  adding: frames/VID20210112173818/17.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/19.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/15.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/10.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173818/16.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/6.txt (deflated 53%)\n",
            "  adding: frames/VID20210112173818/1.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/6.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/24.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173818/7.txt (deflated 55%)\n",
            "  adding: frames/VID20210112173818/4.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/23.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/17.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/11.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/5.txt (deflated 55%)\n",
            "  adding: frames/VID20210112173818/14.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/10.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/22.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/13.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/8.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/7.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/15.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/18.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/1.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/12.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/16.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/2.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/2.txt (deflated 6%)\n",
            "  adding: frames/VID20210112173818/14.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/11.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/21.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/19.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/3.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/13.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/5.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/24.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/25.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173818/9.txt (deflated 53%)\n",
            "  adding: frames/VID20210112173818/20.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/8.txt (deflated 54%)\n",
            "  adding: frames/VID20210112173818/12.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/3.txt (deflated 55%)\n",
            "  adding: frames/VID20210112173818/9.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/21.txt (stored 0%)\n",
            "  adding: frames/VID20210112173818/22.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/18.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173818/25.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173818/23.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173818/4.txt (deflated 54%)\n",
            "  adding: frames/VID20210112173818/20.txt (stored 0%)\n",
            "  adding: frames/VID_20210112_173654_487/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173654_487/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/19.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173654_487/15.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173654_487/10.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173654_487/16.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173654_487/6.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173654_487/1.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/7.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173654_487/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/17.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173654_487/11.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173654_487/5.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173654_487/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/13.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173654_487/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/18.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173654_487/1.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173654_487/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/2.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173654_487/14.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173654_487/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/9.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173654_487/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/8.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173654_487/12.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173654_487/3.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173654_487/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/21.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173654_487/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173654_487/4.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173654_487/20.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173733/32.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/19.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/31.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/15.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733/10.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/16.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/28.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/26.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733/35.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/6.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733/1.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173733/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/24.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/7.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/34.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/23.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/17.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733/11.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733/5.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/33.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/36.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/22.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733/13.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/18.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733/1.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/34.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173733/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/27.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/2.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733/14.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733/31.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/28.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_173733/26.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/35.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/29.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/32.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/36.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/30.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/24.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/25.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733/27.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_173733/9.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/30.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/33.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173733/8.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/29.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733/12.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/3.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/21.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/25.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733/23.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733/4.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733/20.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_174127/ (stored 0%)\n",
            "  adding: frames/VID_20210112_174127/32.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_174127/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/19.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_174127/31.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/15.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/10.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_174127/16.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_174127/28.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/26.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/6.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_174127/1.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_174127/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/24.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/7.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_174127/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/23.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/17.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_174127/11.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_174127/5.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/22.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_174127/13.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_174127/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/18.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/1.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_174127/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/27.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/2.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_174127/14.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_174127/31.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/28.txt (deflated 60%)\n",
            "  adding: frames/VID_20210112_174127/26.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/29.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/32.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/30.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_174127/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/24.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/25.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_174127/27.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/9.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/30.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/8.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/29.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_174127/12.txt (deflated 54%)\n",
            "  adding: frames/VID_20210112_174127/3.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_174127/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/21.txt (deflated 53%)\n",
            "  adding: frames/VID_20210112_174127/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/25.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_174127/23.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_174127/4.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_174127/20.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173706/32.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/19.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/31.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/15.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173706/42.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/10.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/16.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/45.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/28.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/26.txt (deflated 60%)\n",
            "  adding: frames/VID_20210112_173706/46.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173706/45.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/35.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/6.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173706/1.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/24.txt (deflated 60%)\n",
            "  adding: frames/VID_20210112_173706/7.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/40.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/34.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/37.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/48.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/38.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/49.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/23.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/38.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/17.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/11.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/5.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/48.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/33.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/44.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173706/36.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/22.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/13.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173706/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/46.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/18.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173706/1.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/34.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/27.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/2.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173706/41.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/39.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/14.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173706/31.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173706/37.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/42.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/28.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/43.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/26.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/35.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173706/29.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/47.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/32.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/36.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/30.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/24.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/25.txt (deflated 61%)\n",
            "  adding: frames/VID_20210112_173706/41.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173706/27.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/9.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/30.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/33.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/8.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/29.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173706/40.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173706/12.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/43.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173706/3.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173706/47.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173706/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/21.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173706/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/25.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/44.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173706/23.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/49.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173706/4.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/20.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173706/39.txt (deflated 59%)\n",
            "  adding: frames/VID20210112173844/ (stored 0%)\n",
            "  adding: frames/VID20210112173844/17.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173844/19.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173844/15.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173844/10.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173844/16.txt (deflated 58%)\n",
            "  adding: frames/VID20210112173844/6.txt (deflated 54%)\n",
            "  adding: frames/VID20210112173844/1.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/6.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/7.txt (deflated 58%)\n",
            "  adding: frames/VID20210112173844/4.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/17.txt (deflated 54%)\n",
            "  adding: frames/VID20210112173844/11.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173844/5.txt (deflated 55%)\n",
            "  adding: frames/VID20210112173844/14.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/10.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/13.txt (deflated 58%)\n",
            "  adding: frames/VID20210112173844/8.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/7.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173844/15.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173844/18.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173844/1.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173844/12.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/16.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/2.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/2.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173844/14.txt (deflated 58%)\n",
            "  adding: frames/VID20210112173844/11.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173844/19.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173844/3.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173844/13.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173844/5.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173844/9.txt (deflated 59%)\n",
            "  adding: frames/VID20210112173844/20.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/8.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173844/12.txt (deflated 59%)\n",
            "  adding: frames/VID20210112173844/3.txt (deflated 55%)\n",
            "  adding: frames/VID20210112173844/9.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173844/18.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173844/4.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173844/20.txt (deflated 59%)\n",
            "  adding: frames/VID20210112173653/ (stored 0%)\n",
            "  adding: frames/VID20210112173653/17.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/19.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173653/15.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173653/10.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173653/16.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173653/6.txt (deflated 55%)\n",
            "  adding: frames/VID20210112173653/1.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/6.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/7.txt (deflated 55%)\n",
            "  adding: frames/VID20210112173653/4.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/17.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173653/11.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173653/5.txt (deflated 53%)\n",
            "  adding: frames/VID20210112173653/14.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/10.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/22.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173653/13.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173653/8.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/7.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/15.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/18.txt (deflated 58%)\n",
            "  adding: frames/VID20210112173653/1.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173653/12.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/16.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/2.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/2.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173653/14.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173653/11.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/21.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/19.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/3.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/13.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/5.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/9.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173653/20.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/8.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173653/12.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173653/3.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173653/9.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173653/21.txt (deflated 58%)\n",
            "  adding: frames/VID20210112173653/22.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/18.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173653/4.txt (deflated 55%)\n",
            "  adding: frames/VID20210112173653/20.txt (deflated 57%)\n",
            "  adding: frames/20210112_164834/ (stored 0%)\n",
            "  adding: frames/20210112_164834/32.txt (deflated 55%)\n",
            "  adding: frames/20210112_164834/17.jpg (deflated 1%)\n",
            "  adding: frames/20210112_164834/51.txt (deflated 53%)\n",
            "  adding: frames/20210112_164834/19.txt (deflated 50%)\n",
            "  adding: frames/20210112_164834/31.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/15.txt (deflated 49%)\n",
            "  adding: frames/20210112_164834/50.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/42.txt (deflated 55%)\n",
            "  adding: frames/20210112_164834/10.txt (deflated 53%)\n",
            "  adding: frames/20210112_164834/61.txt (deflated 54%)\n",
            "  adding: frames/20210112_164834/16.txt (deflated 51%)\n",
            "  adding: frames/20210112_164834/45.txt (deflated 53%)\n",
            "  adding: frames/20210112_164834/28.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/26.txt (deflated 47%)\n",
            "  adding: frames/20210112_164834/46.txt (deflated 54%)\n",
            "  adding: frames/20210112_164834/45.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/52.txt (deflated 50%)\n",
            "  adding: frames/20210112_164834/35.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/6.txt (deflated 48%)\n",
            "  adding: frames/20210112_164834/1.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/6.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/53.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/63.txt (deflated 46%)\n",
            "  adding: frames/20210112_164834/24.txt (deflated 49%)\n",
            "  adding: frames/20210112_164834/7.txt (deflated 53%)\n",
            "  adding: frames/20210112_164834/40.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/34.txt (deflated 54%)\n",
            "  adding: frames/20210112_164834/56.txt (deflated 55%)\n",
            "  adding: frames/20210112_164834/60.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/37.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/48.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/38.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/62.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/59.txt (deflated 51%)\n",
            "  adding: frames/20210112_164834/49.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/4.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/23.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/38.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/17.txt (deflated 49%)\n",
            "  adding: frames/20210112_164834/11.txt (deflated 48%)\n",
            "  adding: frames/20210112_164834/5.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/48.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/14.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/33.txt (deflated 53%)\n",
            "  adding: frames/20210112_164834/44.txt (deflated 53%)\n",
            "  adding: frames/20210112_164834/36.txt (deflated 54%)\n",
            "  adding: frames/20210112_164834/10.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/22.txt (deflated 48%)\n",
            "  adding: frames/20210112_164834/57.txt (deflated 51%)\n",
            "  adding: frames/20210112_164834/13.txt (deflated 50%)\n",
            "  adding: frames/20210112_164834/8.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/46.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/64.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/58.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/64.txt (deflated 48%)\n",
            "  adding: frames/20210112_164834/55.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/7.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/15.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/18.txt (deflated 43%)\n",
            "  adding: frames/20210112_164834/1.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/12.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/34.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/16.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/52.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/27.jpg (deflated 1%)\n",
            "  adding: frames/20210112_164834/2.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/60.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/59.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/51.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/2.txt (deflated 50%)\n",
            "  adding: frames/20210112_164834/58.txt (deflated 54%)\n",
            "  adding: frames/20210112_164834/41.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/56.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/39.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/14.txt (deflated 51%)\n",
            "  adding: frames/20210112_164834/50.txt (deflated 48%)\n",
            "  adding: frames/20210112_164834/31.txt (deflated 53%)\n",
            "  adding: frames/20210112_164834/62.txt (deflated 50%)\n",
            "  adding: frames/20210112_164834/37.txt (deflated 54%)\n",
            "  adding: frames/20210112_164834/11.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/42.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/21.jpg (deflated 1%)\n",
            "  adding: frames/20210112_164834/28.txt (deflated 46%)\n",
            "  adding: frames/20210112_164834/54.txt (deflated 54%)\n",
            "  adding: frames/20210112_164834/43.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/26.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/35.txt (deflated 55%)\n",
            "  adding: frames/20210112_164834/29.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/19.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/3.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/47.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/13.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/32.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/36.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/53.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/30.txt (deflated 48%)\n",
            "  adding: frames/20210112_164834/5.jpg (deflated 1%)\n",
            "  adding: frames/20210112_164834/24.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/25.txt (deflated 50%)\n",
            "  adding: frames/20210112_164834/41.txt (deflated 56%)\n",
            "  adding: frames/20210112_164834/27.txt (deflated 49%)\n",
            "  adding: frames/20210112_164834/9.txt (deflated 47%)\n",
            "  adding: frames/20210112_164834/54.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/30.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/20.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/65.txt (deflated 54%)\n",
            "  adding: frames/20210112_164834/33.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/8.txt (deflated 40%)\n",
            "  adding: frames/20210112_164834/29.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/40.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/57.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/12.txt (deflated 53%)\n",
            "  adding: frames/20210112_164834/43.txt (deflated 49%)\n",
            "  adding: frames/20210112_164834/3.txt (deflated 47%)\n",
            "  adding: frames/20210112_164834/65.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/47.txt (deflated 50%)\n",
            "  adding: frames/20210112_164834/61.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/9.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/55.jpg (deflated 1%)\n",
            "  adding: frames/20210112_164834/21.txt (deflated 52%)\n",
            "  adding: frames/20210112_164834/22.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/18.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/25.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/44.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/63.jpg (deflated 0%)\n",
            "  adding: frames/20210112_164834/23.txt (deflated 42%)\n",
            "  adding: frames/20210112_164834/49.txt (deflated 50%)\n",
            "  adding: frames/20210112_164834/4.txt (deflated 46%)\n",
            "  adding: frames/20210112_164834/20.txt (deflated 25%)\n",
            "  adding: frames/20210112_164834/39.txt (deflated 50%)\n",
            "  adding: frames/VID_20210112_173800/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173800/32.txt (deflated 44%)\n",
            "  adding: frames/VID_20210112_173800/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/19.txt (deflated 44%)\n",
            "  adding: frames/VID_20210112_173800/31.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/15.txt (deflated 42%)\n",
            "  adding: frames/VID_20210112_173800/10.txt (deflated 28%)\n",
            "  adding: frames/VID_20210112_173800/16.txt (deflated 37%)\n",
            "  adding: frames/VID_20210112_173800/28.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/26.txt (deflated 49%)\n",
            "  adding: frames/VID_20210112_173800/35.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/6.txt (deflated 31%)\n",
            "  adding: frames/VID_20210112_173800/1.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/24.txt (deflated 50%)\n",
            "  adding: frames/VID_20210112_173800/7.txt (deflated 27%)\n",
            "  adding: frames/VID_20210112_173800/34.txt (deflated 43%)\n",
            "  adding: frames/VID_20210112_173800/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/23.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173800/17.txt (deflated 40%)\n",
            "  adding: frames/VID_20210112_173800/11.txt (deflated 27%)\n",
            "  adding: frames/VID_20210112_173800/5.txt (deflated 38%)\n",
            "  adding: frames/VID_20210112_173800/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/33.txt (deflated 49%)\n",
            "  adding: frames/VID_20210112_173800/36.txt (deflated 46%)\n",
            "  adding: frames/VID_20210112_173800/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/22.txt (deflated 27%)\n",
            "  adding: frames/VID_20210112_173800/13.txt (deflated 46%)\n",
            "  adding: frames/VID_20210112_173800/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/18.txt (deflated 43%)\n",
            "  adding: frames/VID_20210112_173800/1.txt (deflated 28%)\n",
            "  adding: frames/VID_20210112_173800/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/34.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/27.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/2.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173800/2.txt (deflated 36%)\n",
            "  adding: frames/VID_20210112_173800/14.txt (deflated 25%)\n",
            "  adding: frames/VID_20210112_173800/31.txt (deflated 46%)\n",
            "  adding: frames/VID_20210112_173800/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/28.txt (deflated 45%)\n",
            "  adding: frames/VID_20210112_173800/26.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/35.txt (deflated 38%)\n",
            "  adding: frames/VID_20210112_173800/29.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/32.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/36.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173800/30.txt (deflated 44%)\n",
            "  adding: frames/VID_20210112_173800/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/24.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/25.txt (deflated 50%)\n",
            "  adding: frames/VID_20210112_173800/27.txt (deflated 49%)\n",
            "  adding: frames/VID_20210112_173800/9.txt (deflated 26%)\n",
            "  adding: frames/VID_20210112_173800/30.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/33.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173800/8.txt (deflated 27%)\n",
            "  adding: frames/VID_20210112_173800/29.txt (deflated 48%)\n",
            "  adding: frames/VID_20210112_173800/12.txt (deflated 39%)\n",
            "  adding: frames/VID_20210112_173800/3.txt (deflated 28%)\n",
            "  adding: frames/VID_20210112_173800/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/21.txt (deflated 38%)\n",
            "  adding: frames/VID_20210112_173800/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/25.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173800/23.txt (deflated 46%)\n",
            "  adding: frames/VID_20210112_173800/4.txt (deflated 14%)\n",
            "  adding: frames/VID_20210112_173800/20.txt (deflated 45%)\n",
            "  adding: frames/VID_20210112_173733_731/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173733_731/32.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/51.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733_731/19.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/31.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/15.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/50.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/42.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/10.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/61.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/16.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/45.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/28.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/26.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/46.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/45.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/52.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/35.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/6.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/1.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/53.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/63.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/24.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/7.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173733_731/40.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/34.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733_731/56.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/60.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/37.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/48.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/38.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/62.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/59.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/49.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/23.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/38.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/17.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/11.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/5.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/48.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/33.txt (deflated 60%)\n",
            "  adding: frames/VID_20210112_173733_731/44.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/36.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/22.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/57.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/66.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/13.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173733_731/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/46.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/64.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/58.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/64.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/55.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/18.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/1.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/34.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/52.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/27.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/60.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/59.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/51.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/2.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/58.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/41.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/56.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/39.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/14.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/50.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/31.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/62.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/37.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/42.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/28.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733_731/54.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/43.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/26.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/35.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/29.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/47.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/66.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733_731/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/32.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/36.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/53.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/30.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/24.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/25.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/41.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/27.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173733_731/9.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/54.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/30.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/65.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/33.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/8.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/29.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173733_731/40.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/57.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/12.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/43.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/3.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/65.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/47.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173733_731/61.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/55.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/21.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173733_731/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/25.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/44.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/63.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173733_731/23.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/49.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/4.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/20.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173733_731/39.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173730/ (stored 0%)\n",
            "  adding: frames/VID20210112173730/17.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173730/19.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173730/15.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173730/10.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173730/16.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173730/6.txt (deflated 55%)\n",
            "  adding: frames/VID20210112173730/1.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/6.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/7.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173730/4.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/17.txt (deflated 58%)\n",
            "  adding: frames/VID20210112173730/11.txt (deflated 59%)\n",
            "  adding: frames/VID20210112173730/5.txt (deflated 61%)\n",
            "  adding: frames/VID20210112173730/14.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/10.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/13.txt (deflated 53%)\n",
            "  adding: frames/VID20210112173730/8.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/7.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173730/15.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173730/18.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173730/1.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173730/12.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/16.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/2.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/2.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173730/14.txt (deflated 59%)\n",
            "  adding: frames/VID20210112173730/11.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173730/19.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173730/3.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173730/13.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173730/5.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173730/9.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173730/20.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/8.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173730/12.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173730/3.txt (deflated 56%)\n",
            "  adding: frames/VID20210112173730/9.jpg (deflated 1%)\n",
            "  adding: frames/VID20210112173730/18.jpg (deflated 0%)\n",
            "  adding: frames/VID20210112173730/4.txt (deflated 57%)\n",
            "  adding: frames/VID20210112173730/20.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/ (stored 0%)\n",
            "  adding: frames/20210112_173758/32.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/211.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/17.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/124.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/70.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/161.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/194.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/230.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/121.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/224.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/76.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/51.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/19.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/150.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/157.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/218.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/183.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/31.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/15.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/133.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/50.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/171.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/159.txt (deflated 11%)\n",
            "  adding: frames/20210112_173758/165.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/42.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/212.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/111.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/223.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/170.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/179.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/231.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/226.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/10.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/61.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/16.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/45.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/193.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/140.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/126.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/161.txt (deflated 51%)\n",
            "  adding: frames/20210112_173758/70.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/71.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/138.txt (deflated 47%)\n",
            "  adding: frames/20210112_173758/106.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/122.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/73.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/153.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/28.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/187.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/26.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/136.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/102.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/148.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/108.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/210.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/200.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/46.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/112.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/130.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/104.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/134.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/233.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/45.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/120.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/75.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/52.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/35.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/125.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/87.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/89.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/200.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/151.txt (deflated 51%)\n",
            "  adding: frames/20210112_173758/6.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/1.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/6.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/116.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/163.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/194.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/53.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/63.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/208.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/145.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/102.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/167.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/123.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/24.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/169.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/195.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/216.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/7.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/210.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/110.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/214.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/174.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/116.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/72.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/203.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/80.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/40.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/177.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/157.txt (deflated 38%)\n",
            "  adding: frames/20210112_173758/34.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/99.txt (deflated 59%)\n",
            "  adding: frames/20210112_173758/80.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/186.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/56.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/60.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/85.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/37.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/176.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/222.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/146.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/224.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/82.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/94.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/48.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/137.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/181.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/87.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/100.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/172.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/156.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/183.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/109.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/173.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/38.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/69.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/131.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/191.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/62.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/166.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/121.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/175.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/59.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/158.txt (deflated 17%)\n",
            "  adding: frames/20210112_173758/173.txt (deflated 60%)\n",
            "  adding: frames/20210112_173758/227.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/227.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/142.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/126.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/185.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/160.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/182.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/135.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/84.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/229.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/137.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/49.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/178.txt (deflated 51%)\n",
            "  adding: frames/20210112_173758/4.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/117.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/23.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/138.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/84.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/217.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/125.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/199.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/169.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/155.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/211.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/187.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/78.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/215.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/38.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/166.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/17.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/195.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/110.txt (deflated 59%)\n",
            "  adding: frames/20210112_173758/153.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/11.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/111.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/165.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/220.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/73.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/5.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/132.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/48.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/14.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/88.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/171.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/158.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/147.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/218.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/164.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/205.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/143.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/86.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/129.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/131.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/198.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/77.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/104.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/92.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/93.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/207.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/33.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/107.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/201.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/44.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/83.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/36.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/208.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/149.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/172.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/97.txt (deflated 61%)\n",
            "  adding: frames/20210112_173758/71.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/152.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/68.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/93.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/213.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/98.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/139.txt (deflated 47%)\n",
            "  adding: frames/20210112_173758/103.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/10.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/156.txt (deflated 49%)\n",
            "  adding: frames/20210112_173758/209.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/94.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/168.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/105.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/206.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/22.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/57.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/101.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/66.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/149.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/13.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/8.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/96.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/129.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/115.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/46.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/64.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/91.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/185.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/130.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/58.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/233.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/196.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/139.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/202.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/132.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/64.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/112.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/213.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/204.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/225.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/55.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/7.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/15.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/108.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/100.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/18.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/223.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/1.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/234.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/176.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/81.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/12.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/199.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/119.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/34.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/69.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/16.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/230.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/114.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/52.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/159.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/27.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/79.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/89.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/2.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/122.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/197.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/189.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/198.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/188.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/184.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/170.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/234.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/163.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/60.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/78.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/59.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/51.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/2.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/179.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/106.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/120.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/217.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/58.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/145.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/41.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/56.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/219.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/221.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/231.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/181.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/39.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/204.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/14.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/142.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/50.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/98.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/31.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/85.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/225.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/197.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/62.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/82.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/37.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/193.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/11.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/42.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/160.txt (deflated 38%)\n",
            "  adding: frames/20210112_173758/21.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/28.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/123.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/54.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/203.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/115.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/114.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/43.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/190.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/26.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/196.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/35.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/226.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/150.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/144.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/152.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/67.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/133.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/154.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/92.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/29.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/128.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/19.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/88.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/109.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/103.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/113.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/155.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/3.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/47.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/124.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/66.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/184.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/135.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/189.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/136.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/68.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/148.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/72.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/13.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/32.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/207.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/186.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/101.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/36.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/53.txt (deflated 51%)\n",
            "  adding: frames/20210112_173758/107.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/188.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/30.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/5.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/175.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/74.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/167.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/147.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/154.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/221.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/24.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/25.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/178.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/232.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/41.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/214.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/117.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/27.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/9.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/74.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/54.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/96.txt (deflated 61%)\n",
            "  adding: frames/20210112_173758/190.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/182.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/30.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/90.txt (deflated 58%)\n",
            "  adding: frames/20210112_173758/162.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/118.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/20.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/105.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/113.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/65.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/162.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/33.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/8.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/86.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/222.txt (deflated 51%)\n",
            "  adding: frames/20210112_173758/215.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/90.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/95.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/29.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/180.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/40.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/127.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/192.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/134.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/95.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/174.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/99.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/177.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/57.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/77.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/12.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/43.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/220.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/168.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/118.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/3.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/65.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/47.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/97.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/146.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/128.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/61.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/9.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/205.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/206.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/228.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/55.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/21.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/22.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/143.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/127.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/91.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/79.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/75.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/164.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/192.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/202.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/18.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/144.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/67.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/232.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/141.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/201.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/25.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/83.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/44.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/140.txt (deflated 52%)\n",
            "  adding: frames/20210112_173758/119.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/63.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/180.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/212.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/23.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/216.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/228.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/49.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/4.txt (deflated 54%)\n",
            "  adding: frames/20210112_173758/209.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/191.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/151.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/229.txt (deflated 55%)\n",
            "  adding: frames/20210112_173758/141.txt (deflated 53%)\n",
            "  adding: frames/20210112_173758/76.txt (deflated 57%)\n",
            "  adding: frames/20210112_173758/219.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/20.txt (deflated 56%)\n",
            "  adding: frames/20210112_173758/81.jpg (deflated 0%)\n",
            "  adding: frames/20210112_173758/39.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173951/ (stored 0%)\n",
            "  adding: frames/VID_20210112_173951/32.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/17.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/19.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/31.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/15.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/42.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/10.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/16.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/28.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/26.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173951/35.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/6.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/1.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/6.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/24.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/7.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173951/40.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/34.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/37.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/38.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/4.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/23.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/38.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/17.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/11.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/5.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173951/14.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/33.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/44.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/36.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/10.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/22.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/13.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/8.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/7.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/15.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/18.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/1.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/12.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/34.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/16.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/27.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/2.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/2.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/41.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/39.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/14.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/31.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173951/37.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/11.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/42.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/21.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/28.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/43.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/26.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/35.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/29.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/19.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/3.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/13.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/32.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/36.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/30.txt (deflated 59%)\n",
            "  adding: frames/VID_20210112_173951/5.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/24.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/25.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/41.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/27.txt (deflated 55%)\n",
            "  adding: frames/VID_20210112_173951/9.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/30.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/20.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/33.jpg (deflated 1%)\n",
            "  adding: frames/VID_20210112_173951/8.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/29.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/40.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/12.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/43.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/3.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/9.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/21.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/22.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/18.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/25.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/44.jpg (deflated 0%)\n",
            "  adding: frames/VID_20210112_173951/23.txt (deflated 56%)\n",
            "  adding: frames/VID_20210112_173951/4.txt (deflated 57%)\n",
            "  adding: frames/VID_20210112_173951/20.txt (deflated 58%)\n",
            "  adding: frames/VID_20210112_173951/39.txt (deflated 55%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpUXnti6sc0c",
        "outputId": "e56e8396-010d-462a-bb19-43ce0bdae478"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E50Ti4EJudJp"
      },
      "source": [
        "!cp frames.zip 'drive/MyDrive/frames.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-l4zsUuu6bC",
        "outputId": "cb5eacef-6f54-4cae-b7c7-c699f4a767ea"
      },
      "source": [
        "name_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bicycle': 1, 'bus': 3, 'car': 0, 'motorbike': 2, 'truck': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}